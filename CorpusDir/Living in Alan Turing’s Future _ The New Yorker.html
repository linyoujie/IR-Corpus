<!DOCTYPE html><html lang="en" data-reactroot=""><head><title>Living in Alan Turing’s Future | The New Yorker</title><meta charSet="utf-8"/><meta content="IE=edge" http-equiv="X-UA-Compatible"/><meta name="msapplication-tap-highlight" content="no"/><meta name="viewport" content="user-scalable=yes, width=device-width, initial-scale=1, maximum-scale=2"/><meta name="author" content="Paul Grimstad"/><meta name="copyright" content="Copyright (c) Condé Nast 2020"/><meta name="description" content="Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician."/><meta name="id" content="5e1cc31e2751bc0008ff607c"/><meta name="keywords" content="Alan Turing,Artificial Intelligence,Second World War,Science Fiction,Technology,Mathematics"/><meta name="news_keywords" content="Alan Turing,Artificial Intelligence,Second World War,Science Fiction,Technology,Mathematics"/><meta name="robots" content="index, follow"/><meta name="content-type" content="article"/><meta name="parsely-post-id" content="5e1cc31e2751bc0008ff607c"/><meta name="parsely-metadata" content="{&quot;description&quot;:&quot;Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician.&quot;,&quot;image-16-9&quot;:&quot;https://media.newyorker.com/photos/5e2330c74156f60008818e30/16:9/w_1000,c_limit/Grimstad-Turing.jpg&quot;,&quot;image-1-1&quot;:&quot;https://media.newyorker.com/photos/5e2330c74156f60008818e30/1:1/w_1000,c_limit/Grimstad-Turing.jpg&quot;}"/><meta property="og:description" content="Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician."/><meta property="og:image" content="https://media.newyorker.com/photos/5e2330c74156f60008818e30/16:9/w_1280,c_limit/Grimstad-Turing.jpg"/><meta property="og:site_name" content="The New Yorker"/><meta property="og:title" content="Living in Alan Turing’s Future"/><meta property="og:type" content="article"/><meta property="og:url" content="https://www.newyorker.com/culture/culture-desk/living-in-alan-turings-future"/><meta property="article:content_tier" content="metered"/><meta property="article:opinion" content="false"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:creator" content="@NewYorker"/><meta property="twitter:description" content="Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician."/><meta property="twitter:domain" content="https://www.newyorker.com"/><meta property="twitter:image:src" content="https://media.newyorker.com/photos/5e2330c74156f60008818e30/16:9/w_1280,c_limit/Grimstad-Turing.jpg?mbid=social_retweet"/><meta property="twitter:site" content="@NewYorker"/><meta property="twitter:title" content="Living in Alan Turing’s Future"/><meta property="fb:app_id" content="1147169538698836"/><meta property="fb:pages" content="9258148868"/><link rel="canonical" href="https://www.newyorker.com/culture/culture-desk/living-in-alan-turings-future"/><link rel="stylesheet" href="/verso/static/the-new-yorker/styles.min.83d405811bb450a230b686995b40b71c9b6b12e8.css"/><link rel="shortcut icon" href="/verso/static/the-new-yorker/assets/favicon.0c115fcf6bb2ed8491d6f719d237ae1b1e68b08d.ico" type="image/x-icon"/><link rel="amphtml" href="https://www.newyorker.com/culture/culture-desk/living-in-alan-turings-future/amp"/><script type="text/javascript">
          window.cns = window.cns || {}; window.cns.pageContext = {"channel":"culture","contentType":"article","keywords":{"copilotid":["5e1cc31e2751bc0008ff607c"],"platform":["verso"],"tags":["alan-turing","artificial-intelligence","second-world-war","science-fiction","technology","mathematics","culture-desk"]},"server":"production","slug":"living-in-alan-turings-future","subChannel":"culture-desk","templateType":"mt_article_two_column"};
        </script><script></script><script src="https://securepubads.g.doubleclick.net/tag/js/gpt.js" id="gpt-script" async ></script>
<script>window.googletag=window.googletag||{cmd:[]};window.cns=window.cns||{queue:[]};window.cns.async=function(s,c){cns.queue.push({service:s,callback:c})};window.sparrowQueue=window.sparrowQueue||[];</script>
<link rel="preconnect" href="https://securepubads.g.doubleclick.net">
<link rel="preconnect" href="https://mb.moatads.com" crossorigin>
<script src="https://z.moatads.com/condenastprebidheader987326845656/moatheader.js" async></script>
<script id="cns-head-include">!function(){"use strict";var n,t=(function(n,t){var i=function(){var n=0;function t(n){var t=[],i=0,r=0;this.push=function(s){i-r>=n&&++r>=n&&(r=0,i=n-1),t[i%n]=s,i++},this.asArray=function(){var s=t.slice(r,Math.min(i,n)),a=t.slice(0,Math.max(i-n,0));return s.concat(a)},this.list=t}function i(t,i){for(var r=i,s=0;s<t.length;s++){var a=t[s],o=r.r;o[a]||(o[a]={w:a,r:{},i:n++}),r=o[a]}return r}function r(n,t,i){var r;return i[n]?r=i[n]:(r=function(n,t){for(var i=[[t,0]],r={},s=[];i.length;){var a=i.shift(),o=a[0],e=a[1],u=o.r,f=n[e];if(void 0===f&&o.fn&&!r[o.i]?(r[o.i]=1,s.push(o.fn)):u[f]&&i.push([u[f],e+1]),u["#"])for(var c=e;c<=n.length;c++)i.push([u["#"],c]);f&&u["*"]&&i.push([u["*"],e+1])}return s}(n.split("."),t),i[n]=r),r}var s=function(){var s={w:"",r:{},i:n++},a={},o=new t(9999);function e(n,t){var r=i(n.split("."),s),o=r.fn||[];return o.push(t),r.fn=o,a={},function(){var n=o.indexOf(t);n>-1&&o.splice(n,1)}}function u(n,t){var i=Date.now();o.push([n,i]);for(var e=r(n,s,a),u={topic:n},f=0;f<e.length;f++)for(var c=e[f],h=0;h<c.length;h++)c[h](t,u)}this.emit=u,this.on=e,this.history=function(t){var s={w:"",r:{},i:n++};i(t.split("."),s).fn=1;for(var a=[],e={},u=o.asArray(),f=0;f<u.length;f++){var c=u[f];r(c[0],s,e).length&&a.push(c)}return a},this.publish=u,this.subscribe=e};return s.Ring=t,s}();n.exports=i}(n={exports:{}}),n.exports);window.cnBus=window.cnBus||new t,window.cns=window.cns||{};var i=window.cns;i.fastAdsHead="6.32.14",i.timing=i.timing||{},i.timing.headerStart=Date.now(),i.queue=i.queue||[],i.flags={},window.moatYieldReady=function(){window.moatPrebidApi.setMoatTargetingForAllSlots(),window.cnBus.emit("ads.moat.yield-ready")}}();
</script><link rel="dns-prefetch" href="//aax.amazon-adsystem.com"><link rel="preconnect" href="//aax.amazon-adsystem.com" crossorigin><script src="https://c.amazon-adsystem.com/aax2/apstag.js" async></script><script src="https://js-sec.indexww.com/ht/p/183973-115907842074647.js" async></script><script></script><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","articleSection":"culture desk","author":[{"@type":"Person","name":"Paul Grimstad","sameAs":"http://www.the-new-yorker.com/contributor/paul-grimstad"}],"dateModified":"2020-01-18T12:12:19.384","datePublished":"2020-01-19T06:00:00.000","headline":"Living in Alan Turing’s Future","image":["https://media.newyorker.com/photos/5e2330c74156f60008818e30/2:1/w_1778,h_889,c_limit/Grimstad-Turing.jpg","https://media.newyorker.com/photos/5e2330c74156f60008818e30/2:2/w_1786,h_1786,c_limit/Grimstad-Turing.jpg","https://media.newyorker.com/photos/5e2330c74156f60008818e30/16:9/w_1718,h_966,c_limit/Grimstad-Turing.jpg","https://media.newyorker.com/photos/5e2330c74156f60008818e30/4:3/w_1797,h_1348,c_limit/Grimstad-Turing.jpg","https://media.newyorker.com/photos/5e2330c74156f60008818e30/1:1/w_1814,h_1814,c_limit/Grimstad-Turing.jpg"],"keywords":["alan turing","artificial intelligence","second world war","science fiction","technology","mathematics","culture","web","culture desk"],"thumbnailUrl":"https://media.newyorker.com/photos/5e2330c74156f60008818e30/2:1/w_1778,h_889,c_limit/Grimstad-Turing.jpg","url":"https://www.newyorker.com/culture/culture-desk/living-in-alan-turings-future","isPartOf":{"@type":["CreativeWork","Product"],"name":"The New Yorker"},"isAccessibleForFree":false,"hasPart":[{"@type":"WebPageElement","isAccessibleForFree":"False","cssSelector":".paywall"}],"alternativeHeadline":"Paul Grimstad ponders the British mathematician Alan Turing’s influence on artificial intelligence, science fiction, Philip K. Dick, “Blade Runner,” Ian McEwan, and life in the corporate-dominated twenty-first century.","description":"Paul Grimstad ponders the British mathematician Alan Turing’s influence on artificial intelligence, science fiction, Philip K. Dick, “Blade Runner,” Ian McEwan, and life in the corporate-dominated twenty-first century.","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.newyorker.com/culture/culture-desk/living-in-alan-turings-future"},"publisher":{"@type":"Organization","name":"The New Yorker","logo":{"@type":"ImageObject","url":"https://www.newyorker.com/static/tny/assets/logo-seo.png","width":"500px","height":"117px"}}}</script><meta id="google-signin-meta" name="google-signin-client_id" content="275906274807-b4eqbdqr511u9msdpj8mh0pf77fcciv7.apps.googleusercontent.com"/><script id="google-api-script" src="https://apis.google.com/js/platform.js" async="" defer=""></script></head><body class="navigation-border-thin-decoration full-width-block-default-decoration avatar-round-shape thumbnail-rectangle-shape stacked-site-navigation fixed-header-nav-variation"><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NX5LSK3" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="app-root"><div class="page page-theme-standard page--article"><div class="navigation-background-filler"></div><div class="ad ad--out-of-page"><div class="ad__slot ad__slot--out-of-page"></div></div><a href="#main-content" class="page__skip-link">Skip to main content</a><div class="interstitial"><div role="none"><div role="none"><div class="paywall-modal"><div class="paywall-modal__overlay" tabindex="-1"></div><aside aria-hidden="true" aria-label="You’ve read your last article." aria-live="assertive" class="paywall-modal__content"><div class="paywall-modal__consumer-marketing-unit consumer-marketing-unit consumer-marketing-unit--paywall-modal-call-to-action consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--paywall-modal-call-to-action"></div></div></aside></div></div></div><div role="none"><div role="none"><div class="paywall-modal"><div class="paywall-modal__overlay" tabindex="-1"></div><aside aria-hidden="true" aria-label="You’ve read your last article." aria-live="assertive" class="paywall-modal__content"><div class="paywall-modal__consumer-marketing-unit consumer-marketing-unit consumer-marketing-unit--paywall-modal-call-to-action consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--paywall-modal-call-to-action"></div></div></aside></div></div></div></div><div class="persistent-top"><header class="stacked-navigation stacked-navigation--theme-standard stacked-navigation--fixed-header-layout stacked-navigation--primary-navigation-size-large site-navigation"><div class="consumer-marketing-unit consumer-marketing-unit--cm-banner consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--cm-banner"></div></div><div class="grid grid-items-0 stacked-navigation__grid"><div class="grid--item stacked-navigation__top"><div class="stacked-navigation__section--cm-unit-nav-left"><div class="consumer-marketing-unit consumer-marketing-unit--nav-left consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--nav-left"></div></div></div><div class="stacked-navigation__section--large-logo"><a class="stacked-navigation__logo-link" href="/"><picture class="stacked-navigation__logo-image--large responsive-image"><img alt="The New Yorker" class="responsive-image__image" src="/verso/static/the-new-yorker/assets/logo.f1893bac6dafe13d6d5bad671a5bee2345efa44d.svg" srcSet="" sizes="100vw"/></picture></a></div><div class="stacked-navigation__section--utility-links"><nav aria-label="Utility" class="navigation navigation--horizontal stacked-navigation__navigation stacked-navigation__navigation--utility-links"><ul class="navigation__list"><li class="navigation__list-item"><a class="navigation__link" href="/newsletters">Newsletter</a></li></ul></nav><div class="standard-navigation-account stacked-navigation__section--utility-links-login"><a href="/account/sign-in?retURL=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future" class="standard-navigation-account__label">Sign In</a></div><div class="consumer-marketing-unit consumer-marketing-unit--nav-cta consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--nav-cta"></div></div><div class="consumer-marketing-unit consumer-marketing-unit--nav-rollover consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--nav-rollover"></div></div><a href="/search" class="button button--with-variations button--link button--has-icon button--icon-only button--utility stacked-navigation__search" data-event-click="{&quot;element&quot;:&quot;Button&quot;,&quot;outgoingURL&quot;:&quot;/search&quot;}" type=""><span class="button__label">Search</span><div class="button__icon-container button__icon-container--after"><svg class="icon icon-search" focusable="false" viewBox="0 0 32 32" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><title>Search</title><path d="M14.5 10a4.5 4.5 0 1 0 0 9 4.5 4.5 0 0 0 0-9zm5.249 8.335l4.458 4.458-1.414 1.414-4.458-4.458a6.5 6.5 0 1 1 1.414-1.414z" fill-rule="nonzero"></path></svg></div></a></div></div><div class="grid--item stacked-navigation__section--primary-links"><nav aria-label="Primary" class="navigation navigation--horizontal stacked-navigation__navigation stacked-navigation__navigation--primary-links"><ul class="navigation__list"><li class="navigation__list-item"><a class="navigation__link" href="/news">News</a></li><li class="navigation__list-item"><a class="navigation__link" href="/culture">Books &amp; Culture</a></li><li class="navigation__list-item"><a class="navigation__link" href="/fiction-and-poetry">Fiction &amp; Poetry</a></li><li class="navigation__list-item"><a class="navigation__link" href="/humor">Humor &amp; Cartoons</a></li><li class="navigation__list-item"><a class="navigation__link" href="/magazine">Magazine</a></li><li class="navigation__list-item"><a class="navigation__link" href="/crossword-puzzles-and-games">Crossword</a></li><li class="navigation__list-item"><a class="external-link navigation__link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://video.newyorker.com&quot;}" href="https://video.newyorker.com" rel="nofollow noopener noreferrer" target="_blank">Video</a></li><li class="navigation__list-item"><a class="navigation__link" href="/podcast">Podcasts</a></li><li class="navigation__list-item"><a class="navigation__link" href="/archive">Archive</a></li><li class="navigation__list-item"><a class="external-link navigation__link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/goings-on-about-town&quot;}" href="https://www.newyorker.com/goings-on-about-town" rel="nofollow noopener noreferrer" target="_blank">Goings On</a></li></ul></nav></div><div class="grid grid-items-0 grid--item stacked-navigation__bottom"><div class="grid--item stacked-navigation__drawer"><button class="button button--with-variations button--has-icon button--icon-only button--utility stacked-navigation__drawer-toggle" data-event-click="{&quot;element&quot;:&quot;Button&quot;}" role="button" type="button"><span class="button__label">Open Navigation Menu</span><div class="button__icon-container button__icon-container--after"><svg class="icon icon-menu" focusable="false" viewBox="0 0 32 32" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M8 10h16v2H8v-2zm0 5h16v2H8v-2zm0 5h16v2H8v-2z" fill-rule="evenodd"></path></svg></div></button></div><div class="grid--item stacked-navigation__section--logo"><a class="stacked-navigation__logo-link" href="/"><picture class="stacked-navigation__logo-image--collapsed responsive-image"><img alt="The New Yorker" class="responsive-image__image" src="/verso/static/the-new-yorker/assets/logo-header.6e34c81346bc43475ffd572e6c2eb3e125927148.svg" srcSet="" sizes="100vw"/></picture></a></div><div class="grid--item stacked-navigation__section--mobile-option"><div class="consumer-marketing-unit consumer-marketing-unit--mob-nav-cta consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--mob-nav-cta"></div></div></div></div></div></header></div><div class="persistent-bottom"><div role="none"><div role="none"><aside aria-hidden="false" aria-live="polite" class="paywall-bar paywall-bar--visible"><div class="paywall-bar__consumer-marketing-unit consumer-marketing-unit consumer-marketing-unit--paywall-bar-call-to-action consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--paywall-bar-call-to-action"></div></div></aside></div></div></div><div class="ad-stickyhero"><div class="ad ad--hero"><div class="ad__slot ad__slot--hero"></div></div></div><main id="main-content" tabindex="-1" class="page__main-content"><article class="article main-content"><div class="lede-background"><header class="content-header content-header--align-left content-header--media-smallrule content-header--position-above content-header__nav-spacing--padding-top-xs article__content-header content-header__caption-style--default content-header--publish-date-bottom"><div class="content-header__container content-header__container-theme-standard"><div class="content-header__row content-header__title-block"><div class="content-header__rubric-block"><div class="content-header__rubric-date-block"><div class="rubric content-header__rubric content-header__rubric--with-no-padding"><a class="rubric__link" href="/culture/culture-desk">Culture Des<span class="link__last-letter-spacing">k</span></a></div></div></div><h1 class="content-header__row content-header__hed">Living in Alan Turing’s Future</h1></div><div class="content-header__row content-header__accreditation content-header__accreditation-without-dek content-header__accreditation--without-lede content-header__row--with-bottom-border"><div class="content-header__row content-header__byline"><div class="content-header__byline__content"><div class="bylines content-header__bylines content-header__bylines--with-publish-date"><p class="byline bylines__byline byline--author" itemProp="author" itemType="http://schema.org/Person"><span class="byline__preamble">By </span><span itemProp="name"><span class="byline__name"><a class="byline__name-link" href="/contributors/paul-grimstad">Paul Grimsta<span class="link__last-letter-spacing">d</span></a></span> </span></p></div><time class="content-header__publish-date content-header__publish-date--with-float-left">January 19, 2020</time></div></div><div class="social-icons social-icons--standard content-header__row content-header__social-share social-links-left-layout"><ul class="social-icons__list"><li class="social-icons__list-item social-icons__list-item--facebook social-icons__list-item--standard thinner"><a aria-label="Share on Facebook" class="external-link social-icons__link social-icons__link--facebook social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.facebook.com/dialog/feed?&amp;display=popup&amp;caption=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;app_id=1147169538698836&amp;link=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dfacebook%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&quot;}" href="https://www.facebook.com/dialog/feed?&amp;display=popup&amp;caption=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;app_id=1147169538698836&amp;link=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dfacebook%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-facebook" focusable="false" width="7.2" height="16" viewBox="0 0 7.2 16" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M1.548 3.099v2.203H0v2.693h1.548V16h3.179V7.995H6.86s.2-1.291.297-2.703H4.739V3.45c0-.275.346-.646.689-.646H7.16V0H4.805C1.47 0 1.548 2.696 1.548 3.099z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--twitter social-icons__list-item--standard thinner"><a aria-label="Share on Twitter" class="external-link social-icons__link social-icons__link--twitter social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://twitter.com/intent/tweet/?url=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dtwitter%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&amp;text=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;via=NewYorker&quot;}" href="https://twitter.com/intent/tweet/?url=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dtwitter%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&amp;text=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;via=NewYorker" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-twitter" focusable="false" width="15.3" height="13" viewBox="0 0 15.3 13" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M15.275 1.539a6.04 6.04 0 0 1-1.8.517A3.268 3.268 0 0 0 14.854.24a6.127 6.127 0 0 1-1.99.797A3.067 3.067 0 0 0 10.575 0c-1.73 0-3.134 1.47-3.134 3.281 0 .257.028.508.081.748C4.918 3.892 2.61 2.585 1.063.6A3.382 3.382 0 0 0 .64 2.25c0 1.14.552 2.144 1.393 2.732a3.001 3.001 0 0 1-1.418-.41v.042c0 1.59 1.08 2.916 2.513 3.218a3.011 3.011 0 0 1-1.415.056c.399 1.304 1.556 2.253 2.926 2.28A6.111 6.111 0 0 1 0 11.525 8.59 8.59 0 0 0 4.805 13c5.764 0 8.916-5 8.916-9.338a8.96 8.96 0 0 0-.01-.425 6.522 6.522 0 0 0 1.564-1.698z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--email social-icons__list-item--standard thinner"><a aria-label="Share via Email" class="external-link social-icons__link social-icons__link--email social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;mailto:?subject=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;body=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Donsite-share%26utm_medium%3Demail%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker&quot;}" href="mailto:?subject=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;body=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Donsite-share%26utm_medium%3Demail%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-email" focusable="false" width="17.3" height="13" viewBox="0 0 17.3 13" xmlns="http://www.w3.org/2000/svg"><title>Email</title><path d="M0 .776V13h17.333V.776L8.67 8.931 0 .776z M.756 0L8.67 7.443 16.578 0H.756z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--print social-icons__list-item--standard thinner"><a aria-label="Print" class="external-link social-icons__link social-icons__link--print social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;#&quot;}" href="#" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-print" width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"><title>Print</title><rect class="background" x="4.5" y="0.5" width="8" height="5" fill="black" stroke="white"></rect><rect y="4" width="17" height="9" fill="white"></rect><rect class="background" x="4.5" y="10.5" width="8" height="5" fill="black" stroke="white"></rect></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--bookmark social-icons__list-item--standard thinner bookmark-disabled"><a aria-label="Bookmark" class="external-link social-icons__link social-icons__link--bookmark social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;#&quot;}" href="#" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-bookmark" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><title>Save Story</title><path class="icon-bookmark-fill" d="M20 23.9508L12.5 19.7312L5 23.9508V2.95081H14V3.93211H6V22.1845L12.5 18.5536L19 22.1845V8.83866H20V23.9508Z" fill="black"></path><path class="icon-bookmark-stroke" d="M23 3H20V0H19V3H16V4H19V7H20V4H23V3Z" fill="black"></path></svg></div></a></li></ul></div></div></div><aside class="persistent-aside persistent-aside--align-left-lead-asset" style="position:absolute;top:auto;height:auto"><div class="sticky-box article__social-share sticky-box--hide"><div class="sticky-box__primary"><div class="social-icons social-icons--circular social-icons--share social-icons--bg"><ul class="social-icons__list"><li class="social-icons__list-item social-icons__list-item--facebook social-icons__list-item--circular thinner"><a aria-label="Share on Facebook" class="external-link social-icons__link social-icons__link--facebook social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.facebook.com/dialog/feed?&amp;display=popup&amp;caption=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;app_id=1147169538698836&amp;link=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dfacebook%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&quot;}" href="https://www.facebook.com/dialog/feed?&amp;display=popup&amp;caption=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;app_id=1147169538698836&amp;link=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dfacebook%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-facebook" focusable="false" width="7.2" height="16" viewBox="0 0 7.2 16" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M1.548 3.099v2.203H0v2.693h1.548V16h3.179V7.995H6.86s.2-1.291.297-2.703H4.739V3.45c0-.275.346-.646.689-.646H7.16V0H4.805C1.47 0 1.548 2.696 1.548 3.099z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--twitter social-icons__list-item--circular thinner"><a aria-label="Share on Twitter" class="external-link social-icons__link social-icons__link--twitter social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://twitter.com/intent/tweet/?url=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dtwitter%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&amp;text=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;via=NewYorker&quot;}" href="https://twitter.com/intent/tweet/?url=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dtwitter%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&amp;text=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;via=NewYorker" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-twitter" focusable="false" width="15.3" height="13" viewBox="0 0 15.3 13" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M15.275 1.539a6.04 6.04 0 0 1-1.8.517A3.268 3.268 0 0 0 14.854.24a6.127 6.127 0 0 1-1.99.797A3.067 3.067 0 0 0 10.575 0c-1.73 0-3.134 1.47-3.134 3.281 0 .257.028.508.081.748C4.918 3.892 2.61 2.585 1.063.6A3.382 3.382 0 0 0 .64 2.25c0 1.14.552 2.144 1.393 2.732a3.001 3.001 0 0 1-1.418-.41v.042c0 1.59 1.08 2.916 2.513 3.218a3.011 3.011 0 0 1-1.415.056c.399 1.304 1.556 2.253 2.926 2.28A6.111 6.111 0 0 1 0 11.525 8.59 8.59 0 0 0 4.805 13c5.764 0 8.916-5 8.916-9.338a8.96 8.96 0 0 0-.01-.425 6.522 6.522 0 0 0 1.564-1.698z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--email social-icons__list-item--circular thinner"><a aria-label="Share via Email" class="external-link social-icons__link social-icons__link--email social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;mailto:?subject=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;body=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Donsite-share%26utm_medium%3Demail%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker&quot;}" href="mailto:?subject=Living%20in%20Alan%20Turing%E2%80%99s%20Future&amp;body=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Donsite-share%26utm_medium%3Demail%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-email" focusable="false" width="17.3" height="13" viewBox="0 0 17.3 13" xmlns="http://www.w3.org/2000/svg"><title>Email</title><path d="M0 .776V13h17.333V.776L8.67 8.931 0 .776z M.756 0L8.67 7.443 16.578 0H.756z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--print social-icons__list-item--circular thinner"><a aria-label="Print" class="external-link social-icons__link social-icons__link--print social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;#&quot;}" href="#" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-print" width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"><title>Print</title><rect class="background" x="4.5" y="0.5" width="8" height="5" fill="black" stroke="white"></rect><rect y="4" width="17" height="9" fill="white"></rect><rect class="background" x="4.5" y="10.5" width="8" height="5" fill="black" stroke="white"></rect></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--bookmark social-icons__list-item--circular thinner bookmark-disabled"><a aria-label="Bookmark" class="external-link social-icons__link social-icons__link--bookmark social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;#&quot;}" href="#" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-bookmark" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><title>Save Story</title><path class="icon-bookmark-fill" d="M20 23.9508L12.5 19.7312L5 23.9508V2.95081H14V3.93211H6V22.1845L12.5 18.5536L19 22.1845V8.83866H20V23.9508Z" fill="black"></path><path class="icon-bookmark-stroke" d="M23 3H20V0H19V3H16V4H19V7H20V4H23V3Z" fill="black"></path></svg></div></a></li></ul></div></div><div class="sticky-box__placeholder"></div></div></aside></header></div><div class="content-background content-padding-top-large" data-attribute-verso-pattern="article-body"><div class=""><div class="article__chunks article__chunks--without-top-spacing-content-well article__chunks--hr-style-thin"><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="grid--item body body__container article__body grid-layout__content"><div class="callout callout--inset-right callout--has-top-border callout--content-type--asset-embed callout--content-type--image inset-embedded-lede"><figure class="asset-embed"><div class="asset-embed__asset-container"><span class="responsive-asset asset-embed__responsive-asset responsive-asset--invisible"><picture class="asset-embed__responsive-asset responsive-image"><noscript><img alt="Alan Turing" class="responsive-image__image" src="https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_2560%2Cc_limit/Grimstad-Turing.jpg" srcSet="https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_2560%2Cc_limit/Grimstad-Turing.jpg 2560w, https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_1280%2Cc_limit/Grimstad-Turing.jpg 1280w, https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_1280%2Cc_limit/Grimstad-Turing.jpg 1280w, https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_1024%2Cc_limit/Grimstad-Turing.jpg 1024w, https://media.newyorker.com/photos/5e2330c74156f60008818e30/master/w_360%2Cc_limit/Grimstad-Turing.jpg 360w" sizes="100vw"/></noscript></picture></span></div><figcaption class="caption asset-embed__caption caption-shade--light"><span class="caption__text">The British mathematician Alan Turing was one of the more unquantifiably original minds of the twentieth century.</span><span class="caption__credit">Photograph from Alamy</span></figcaption></figure></div><p class="has-dropcap has-dropcap__lead-standard-heading">More than a decade has passed since the British government issued an apology to the mathematician Alan Turing. “On behalf of . . . all those who live freely thanks to Alan’s work,” then Prime Minister Gordon Brown said, in an official statement, “we’re sorry, you deserved so much better.” The tone of pained contrition was appropriate, given Britain’s grotesquely ungracious treatment of Turing, who played a decisive role in cracking the German Enigma cipher, allowing Allied intelligence to predict where U-boats would strike and thus saving tens of thousands of lives. Unapologetic about his homosexuality, Turing had made a careless admission of an affair with a man, in the course of reporting a robbery at his home in 1952, and was arrested for an “act of gross indecency” (the same charge that had led to a jail sentence for Oscar Wilde in 1895). Turing was subsequently given a choice to serve prison time or undergo a hormone treatment meant to reverse the testosterone levels that made him desire men (so the thinking went at the time). Turing opted for the latter and, two years later, ended his life by taking a bite from an apple laced with cyanide.</p><div class="consumer-marketing-unit consumer-marketing-unit--article-mid-content consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--article-mid-content consumer-marketing-unit__slot--in-content"></div></div><p>His wartime code-breaking work was just one example of what made Turing one of the most influential minds of the twentieth century. In 1936, when he was twenty-three years old, he published a paper called “On Computable Numbers,” in which he attempted to tackle the problem of “decidability” in formal systems like mathematics. In it, he sketched a design for a peculiar machine, somewhere between a gramophone stylus and a typewriter carriage, that moved along a tape divided into squares. At any given time, the machine might be in one of a finite set of states that would tell it to move either right or left or to print, erase, or stop. The machine was not a piece of functioning hardware but a thought experiment meant to reveal something about the essence of computation. The really novel idea behind Turing’s imaginary machine was that it was not designed for a specific purpose but could be given instructions (“programmed”) that allowed it to simulate any other machine. Such universal computers are now called Turing machines and are the basis for all smartphones, laptops, and the Internet.</p><p>Yet Turing’s temperament was the antithesis of the stepwise, uniform procedure captured in his thought experiment. A dreamy nonconformist in the style of hyperrational eccentrics such as Lewis Carroll and Bertrand Russell, Turing operated best on the ludic frequency of games, puzzles, secret codes, and abstract formal systems like mathematics. Wholly a man of science, with nothing but scorn for any whiff of the theological, Turing nevertheless had a speculative streak, which could lead him into realms bordering on science fiction. Since boyhood, he had been keenly interested in mechanism (at eleven, he drew up the plans for a typewriter of his own design) and invented words (“quockling” is the sound seagulls make), and he developed a fondness for Edwin Tenney Brewster’s “<a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Natural-wonders-every-should-library/dp/B00089VD6S&quot;}" href="https://www.amazon.com/Natural-wonders-every-should-library/dp/B00089VD6S" rel="nofollow noopener noreferrer" target="_blank">Natural Wonders Every Child Should Know</a>,” which suggested that human beings were just very sophisticated machines. Later, he began pursuing the idea that thinking itself could be mechanized, and, in collaboration with his Cambridge friend David Champernowne, he developed Turochamp, one of the very first computer chess programs.</p><div class="ad ad--in-content"><div class="ad__slot ad__slot--in-content"></div></div><p>A mind like Turing’s ended up being immensely valuable to Allied counterintelligence during the Second World War. When the German Enigma machine became the most powerful ciphering instrument in the world—it was believed to be impregnable—military cryptography accordingly became more mathematically complex. With the help of notes provided by Polish cryptanalysts and some recovered codebooks from sunken U-boats, Turing oversaw the construction of a machine that could find loopholes in the Enigma’s polyalphabetic rotary design, and soon the code-breaking team began cracking Nazi radio messages without the Germans’ knowing it. Though Turing had been against the war as a student at Cambridge, he seems to have undertaken this work as much for the challenge of tackling a fiendishly complex puzzle as for any sense of patriotic duty. He was also a stickler for respectable working conditions: he wrote Winston Churchill a letter complaining about the poor plumbing facilities at Bletchley Park, the Tudor mansion northwest of London where the code-breakers had set up shop.</p><p>After the war, Turing began writing more speculatively about minds and machines. Anyone who had been reading American science fiction would have been familiar with the questions raised in his paper “Computing Machinery and Intelligence,” from 1950, and one of the more delightful intersections in the history of ideas is the way both Turing, in the august philosophy journal <em>Mind</em>, and the young Isaac Asimov, in the pulp magazine <em>Astounding Science Fiction</em>, started talking about the same thing at about the same time. Turing, in his typically chatty, unadorned way, wondered what could serve as a criterion for treating a machine as “intelligent.” To answer that question, he came up with the second of his famous thought experiments, the imitation game (now known as the Turing test), in which a person poses questions via teletype to two interlocutors, one a human, the other an algorithm. If the questioner cannot tell the difference between them, then we must grant that the machine thinks.</p><div data-attr-viewport-monitor="inline-recirc" class="inline-recirc-wrapper inline-recirc-observer-target-1 viewport-monitor-anchor"></div><p>One reason that Turing settled on a talking test for artificial intelligence was that he did not want machines to be judged according to irrelevant criteria. “We do not wish to penalise a machine for its inability to shine in beauty competitions,” he wrote, just as we would “not penalise a man for losing a race against an aeroplane.” While Asimov was writing stories about government-issue robots with rules burned into their positronic brains to prevent them from rebelling against their masters, Turing’s essay directly inspired a new wave of trippier science fiction. Philip K. Dick happened upon a reprint of “Computing Machinery and Intelligence” and, soon afterward, went to work on “<a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Androids-Dream-Electric-Sheep-Omnibus/dp/1608867846&quot;}" href="https://www.amazon.com/Androids-Dream-Electric-Sheep-Omnibus/dp/1608867846" rel="nofollow noopener noreferrer" target="_blank">Do Androids Dream of Electric Sheep?</a>,” a novel that posited a so-called Voight-Kampff empathy test for determining whether someone is a human being or a replicant. (The story was later the seed for the film “Blade Runner.”)</p><div class="cne-interlude-embed"></div><p>One argument against machine intelligence was what Turing called Lady Lovelace’s Objection, referring to Ada Byron, the Countess of Lovelace and the daughter of the poet. Lovelace kept up a correspondence with the English inventor Charles Babbage, who worked his whole life on a huge brass cogwheel engine that could compute logarithmic tables, to be used by astronomers and navigators. In a letter, Lovelace said of this contraption that it “has no pretensions whatever to <em>originate</em> anything. It can do whatever we know how to order it to perform.” It was a coder’s insight (Lovelace is considered one of the first computer programmers), but it was also the instinct of a poet’s daughter, attuned to more mysterious routes of thought than logarithmic tables. The two attitudes beautifully commingle in another letter, in which Lovelace, discussing the punch cards that Babbage used as proto-software for his analytical engine, notes that the machine “weaves algebraical patterns just as [a] loom weaves flowers and leaves.”</p><p>After the declassification of wartime documents, in the mid-seventies, an industry of Turing hagiography began, reaching its glamorous apex when Benedict Cumberbatch played Turing in the film “The Imitation Game,” from 2014. Based (extremely loosely) on Andrew Hodges’s excellent biography “<a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Alan-Turing-Enigma-Inspired-Imitation/dp/069116472X&quot;}" href="https://www.amazon.com/Alan-Turing-Enigma-Inspired-Imitation/dp/069116472X" rel="nofollow noopener noreferrer" target="_blank">Alan Turing: The Enigma</a>,” from 1983, the film imagines Turing as an obtuse savant who can’t make out English idioms or catch social cues. In a preliminary interview for the code-breaking work at Bletchley, Turing unnerves a government official with his literalism. “Ah, Turing! A mathematician. How ever could I have guessed?” the official says, looking into a manila folder. “You didn’t. You just read it on that piece of paper,” Turing replies. A little later, he has trouble understanding what the word “lunch” means.</p></div><div class="grid--item grid-layout__aside"><aside class="persistent-aside" style="position:absolute;top:auto;height:auto"><div class="sticky-box"><div class="sticky-box__primary"><div class="ad ad--rail"><div class="ad__slot ad__slot--rail"></div></div></div><div class="sticky-box__placeholder"></div></div></aside></div></div><div class="row full-bleed-ad"><div class="ad ad--mid-content"><span class="ad-label">Advertisement</span><div class="ad__slot ad__slot--mid-content"></div></div></div><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="grid--item body body__container article__body grid-layout__content"><p>By most accounts, Turing was gregarious and socially at ease, not the near-android that he is made out to be in the film, and, if he was also noted to be a stickler for precision in thought and speech, fastidiousness isn’t the same thing as humorlessness. Cumberbatch has in any case become the central-casting option for on-the-spectrum-ish über-nerds, a style that he also brings to the BBC series “Sherlock,” in which Holmes regularly flies over the heads of the non-geniuses around him. (Sir Arthur Conan Doyle’s amateur detective, by contrast, is keenly aware of others’ feelings and often empathic to a fault.) Whether this depiction is the result of poetic license, Cumberbatch being his (often great) actorly self, or rote adoption of Hollywood tropes about how geniuses are supposed to behave (think Russell Crowe’s anguished John Nash in “A Beautiful Mind”), the effect is to bring Mr. Spock clichés to a person who was anything but a human robot.</p><p>A more recent fictional Turing shows up in Ian McEwan’s “<a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Machines-Like-Me-Ian-McEwan/dp/0385545118&quot;}" href="https://www.amazon.com/Machines-Like-Me-Ian-McEwan/dp/0385545118" rel="nofollow noopener noreferrer" target="_blank">Machines Like Me</a>,” from 2019, a novel set in a counterfactual 1982, in which Sir Alan has lived to be seventy and oversees the first commercial manufacture of A.I., in partnership with the DeepMind co-founder Demis Hassabis. (My guess for the choice of 1982 is that it is the release year of “Blade Runner,” which, in a further through-the-looking-glass twist, is itself set in 2019.) Their collaboration begins when they “devise software to beat one of the world’s great masters of the ancient game of go,” a sly bit of alternate history, as DeepMind’s AlphaGo program in fact won four out of five games against the South Korean Go master Lee Sedol, in 2016. There was some buzz when I.B.M.’s Deep Blue machine beat the world chess champion Garry Kasparov, in 1997, but the victory over Sedol was thought to mark the encroachment of A.I. onto the sacred ground of human creativity and intuition, since Go is exponentially more complex than chess and playing well often involves an ability to grasp which move is the most beautiful.</p><p>McEwan is good at imagining the messy situations that might attend the arrival of full-blown artificial people, no matter how good they are at Go. He imagines androids who always tell the unvarnished truth, under any and all circumstances, because it is the right thing to do, for example, or who become menacingly guileless sexual rivals. (Julian Lucas <a href="https://www.newyorker.com/magazine/2019/04/22/man-woman-and-robot-in-ian-mcewans-new-novel">points out in this magazine</a> that McEwan’s “Adam” comes equipped with “Kantian morals and fully functioning phallus.”) McEwan has his own way of embellishing his counterfactual Turing with traits that he does not seem to have possessed in reality. For instance, his Turing becomes irritated with an American cable-TV host while trying to explain P = NP. It’s a problem that has its origins in Turing’s 1936 paper on decidability and asks if problems verifiable in polynomial time can also be solved in polynomial time. In the novel, Turing has cracked it, but, outside the pages of the book, P = NP remains one of the outstanding problems posed by the Clay Mathematics Institute, and its solution carries a prize of a million dollars.</p><p>In the years leading up to Turing’s death, his thoughts ran in increasingly imaginative, unpredictable directions. He used the Fibonacci series to understand patterns like those in sunflower petals and hydra tubules, tinkered with a theory of cellular automata, and pursued the design of machines that would not only pass the Turing test but also learn from experience (the ultimate rebuttal to Lady Lovelace’s Objection). Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with him. Had Turing lived longer, perhaps the state of artificial intelligence would encompass more than drearily corporate banalities such as the Amazon checkout window making suggestions about what you might like for your next purchase, Google offering up a few words for how to complete a sentence in progress, or a South Korean genius having his soul crushed by a roomful of statistics wonks—not to mention more chillingly Orwellian developments, such as facial-recognition software. It is fortifying to remember that the very idea of artificial intelligence was conceived by one of the more unquantifiably original minds of the twentieth century. It is hard to imagine a computer being able to do what Alan Turing did.</p></div><div class="grid--item grid-layout__aside"><div class="sticky-box"><div class="sticky-box__primary"><div class="ad ad--rail"><div class="ad__slot ad__slot--rail"></div></div></div><div class="sticky-box__placeholder"></div></div></div></div></div><div role="none"><div role="none"><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="grid--item body body__truncation-message article__body grid-layout__content"><div class="container container--body"><div class="container--body-inner"></div></div></div></div></div></div></div></div></article><div class="content-footer"><div class="row"><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="contributors contributors--no-bottom-line grid--item grid-layout__content"><div class="contributor-bio contributor-bio--align-left contributors__contributor-bio"><div class="contributor-bio__content"><div class="contributor-bio__bio"><a href="/contributors/paul-grimstad">Paul Grimstad</a>’s essays and reviews have appeared in numerous publications, including <em>Bookforum</em>, <em>The London Review of Books</em>, and <em>n+1</em>.</div><div class="contributor-bio__footer"></div></div></div></div></div></div><div class="row has-top-border-content has-bottom-border-content"><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="tag-cloud grid--item content-footer__tag-cloud with-top-border with-bottom-border grid-layout__content"><span class="tag-cloud__section-header">More:</span><a class="tag-cloud__tag-link" href="/tag/alan-turing"><span class="tag-cloud__tag-name">Alan Turing</span></a><a class="tag-cloud__tag-link" href="/tag/artificial-intelligence"><span class="tag-cloud__tag-name">Artificial Intelligence</span></a><a class="tag-cloud__tag-link" href="/tag/second-world-war"><span class="tag-cloud__tag-name">Second World War</span></a><a class="tag-cloud__tag-link" href="/tag/science-fiction"><span class="tag-cloud__tag-name">Science Fiction</span></a><a class="tag-cloud__tag-link" href="/tag/technology"><span class="tag-cloud__tag-name">Technology</span></a><a class="tag-cloud__tag-link" href="/tag/mathematics"><span class="tag-cloud__tag-name">Mathematics</span></a></div></div></div><div class="content-footer__bottom"><div class="grid grid-margins grid-items-2 grid-layout--adrail narrow"><div class="newsletter-subscribe-form grid--item content-footer__newsletter grid-layout__content"><h3 class="newsletter-subscribe-form__hed">The New Yorker Recommends</h3><div class="newsletter-subscribe-form__dek">What our staff is reading, watching, and listening to each week.</div><form class="form-with-validation newsletter-subscribe-form__contents" id="newsletter" name="newsletter" novalidate=""><span class="text-field text-field--attached-button"><label class="text-field__label text-field__label--single-line" for="newsletter-text-field-email"><div class="text-field__label-text">Enter your e-mail address</div><div class="text-field__input-container"><input type="email" aria-describedby="privacy-text" aria-invalid="false" id="newsletter-text-field-email" required="" name="email" placeholder="Your e-mail address" class="text-field__control text-field__control--input"/></div></label><button class="button button--with-variations button--utility text-field__button" data-event-click="{&quot;element&quot;:&quot;Button&quot;}" type="submit"><span class="button__label">Sign up</span></button></span><div class="newsletter-subscribe-form__disclaimer" id="privacy-text" tabindex="-1"><span><p>Will be used in accordance with our <a href="https://www.condenast.com/privacy-policy">Privacy Policy</a>.</p></span></div></form></div></div><div class="content-bottom-anchor"></div><div class="consumer-marketing-unit consumer-marketing-unit--article-footer consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--article-footer"></div></div><div class="isServer-fallback"><div data-attr-viewport-monitor="" class="recirc-list-wrapper hide-read-more-ad viewport-monitor-anchor"><div class="row recirc-list-observer-target content-footer__related"><div class="grid grid-margins grid-items-0 summary-collection-grid recirc-list__items recirc-list--four-up summary-collection-grid--four-columns"><div class="grid--item summary-collection-grid__content"><div class="section-title section-title--center summary-collection-grid__title section-title--line-above-below"><div class="section-title__hed">Read More</div></div><div class="summary-collection-grid__items hide-read-more-ad"><div tabindex="0" class="summary-item summary-item--article summary-item--no-icon summary-item--text-align-left summary-item--layout-placement-text-below summary-item--layout-position-image-left summary-item--layout-proportions-50-50 summary-collection-grid__item" role="button"><a class="summary-item__image-link summary-item-tracking__image-link" href="/magazine/2018/05/14/how-frightened-should-we-be-of-ai" aria-hidden="true" tabindex="-1" data-component-type="recirc-river" data-recirc-id="item-image-1" data-recirc-pattern="summary-item"><span class="responsive-asset summary-item__image responsive-asset--invisible"><picture class="summary-item__image responsive-image"><noscript><source media="(max-width: 767px)" srcSet="https://media.newyorker.com/photos/5aeb3d4c7505432fc35f5419/16:9/w_720%2Cc_limit/180514_r32044.jpg 720w" sizes="100vw"/><source media="(min-width: 768px)" srcSet="https://media.newyorker.com/photos/5aeb3d4c7505432fc35f5419/4:3/w_480%2Cc_limit/180514_r32044.jpg 480w" sizes="100vw"/><img alt="A cartoonlike illustration of a red eyeball and its veins" class="responsive-image__image" src="https://media.newyorker.com/photos/5aeb3d4c7505432fc35f5419/4:3/w_480%2Cc_limit/180514_r32044.jpg"/></noscript></picture></span></a><div class="summary-item__content"><div class="rubric rubric--discovery summary-item__rubric"><a class="rubric__link" href="/magazine/dept-of-speculation">Dept. of Speculatio<span class="link__last-letter-spacing">n</span></a></div><a class="summary-item__hed-link summary-item-tracking__hed-link" href="/magazine/2018/05/14/how-frightened-should-we-be-of-ai" data-component-type="recirc-river" data-recirc-id="item-hed-1" data-recirc-pattern="summary-item"><div class="summary-item__hed">How Frightened Should We Be of A.I.?</div></a><p class="summary-item__dek">Thinking about artificial intelligence can help clarify what makes us human&#8212;for better and for worse.</p><div class="summary-item__byline-date-icon"><div class="summary-item__byline"><div class="summary-item__byline__content"><p class="byline summary-item__byline-authors" itemProp="author" itemType="http://schema.org/Person"><span class="byline__preamble">By </span><span itemProp="name"><span class="byline__name">Tad Friend</span> </span></p></div></div></div></div></div><div tabindex="0" class="summary-item summary-item--article summary-item--no-icon summary-item--text-align-left summary-item--layout-placement-text-below summary-item--layout-position-image-left summary-item--layout-proportions-50-50 summary-collection-grid__item" role="button"><a class="summary-item__image-link summary-item-tracking__image-link" href="/tech/annals-of-technology/christopher-stracheys-nineteen-fifties-love-machine" aria-hidden="true" tabindex="-1" data-component-type="recirc-river" data-recirc-id="item-image-2" data-recirc-pattern="summary-item"><span class="responsive-asset summary-item__image responsive-asset--invisible"><picture class="summary-item__image responsive-image"><noscript><source media="(max-width: 767px)" srcSet="https://media.newyorker.com/photos/59097e19ebe912338a378bda/16:9/w_720%2Cc_limit/strachey-love-letter_WP.jpg 720w" sizes="100vw"/><source media="(min-width: 768px)" srcSet="https://media.newyorker.com/photos/59097e19ebe912338a378bda/4:3/w_480%2Cc_limit/strachey-love-letter_WP.jpg 480w" sizes="100vw"/><img alt="Long before artificial intelligence came into its own Strachey taught a computer to write love letters." class="responsive-image__image" src="https://media.newyorker.com/photos/59097e19ebe912338a378bda/4:3/w_480%2Cc_limit/strachey-love-letter_WP.jpg"/></noscript></picture></span></a><div class="summary-item__content"><div class="rubric rubric--discovery summary-item__rubric"><a class="rubric__link" href="/tech">Tec<span class="link__last-letter-spacing">h</span></a></div><a class="summary-item__hed-link summary-item-tracking__hed-link" href="/tech/annals-of-technology/christopher-stracheys-nineteen-fifties-love-machine" data-component-type="recirc-river" data-recirc-id="item-hed-2" data-recirc-pattern="summary-item"><div class="summary-item__hed">Christopher Strachey’s Nineteen-Fifties Love Machine</div></a><div class="summary-item__byline-date-icon"><div class="summary-item__byline"><div class="summary-item__byline__content"><p class="byline summary-item__byline-authors" itemProp="author" itemType="http://schema.org/Person"><span class="byline__preamble">By </span><span itemProp="name"><span class="byline__name">Siobhan Roberts</span> </span></p></div></div></div></div></div><div class="summary-item summary-collection-grid__item ad ad--read-more"><div class="ad__slot ad__slot--read-more"></div></div><div tabindex="0" class="summary-item summary-item--cnevideo summary-item--no-icon summary-item--text-align-left summary-item--layout-placement-text-below summary-item--layout-position-image-left summary-item--layout-proportions-50-50 summary-collection-grid__item" role="button"><a class="summary-item__image-link summary-item-tracking__image-link" href="http://video.newyorker.com/watch/a-robotic-arm-controlled-by-the-mind" aria-hidden="true" tabindex="-1" data-component-type="recirc-river" data-recirc-id="item-image-3" data-recirc-pattern="summary-item"><span class="responsive-asset summary-item__image responsive-asset--invisible"><picture class="summary-item__image responsive-image"><noscript><source media="(max-width: 767px)" srcSet="https://dwgyu36up6iuz.cloudfront.net/heru80fdn/image/upload/c_fill%2Cd_placeholder_thescene.jpg%2Cfl_progressive%2Cg_center%2Ch_405%2Cq_80%2Cw_720/v1542299457/thenewyorker_a-robotic-arm-controlled-by-the-mind.jpg 720w" sizes="100vw"/><source media="(min-width: 768px)" srcSet="https://dwgyu36up6iuz.cloudfront.net/heru80fdn/image/upload/c_fill%2Cd_placeholder_thescene.jpg%2Cfl_progressive%2Cg_center%2Ch_360%2Cq_80%2Cw_480/v1542299457/thenewyorker_a-robotic-arm-controlled-by-the-mind.jpg 480w" sizes="100vw"/><img alt="" class="responsive-image__image" src="https://dwgyu36up6iuz.cloudfront.net/heru80fdn/image/upload/c_fill%2Cd_placeholder_thescene.jpg%2Cfl_progressive%2Cg_center%2Ch_360%2Cq_80%2Cw_480/v1542299457/thenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"/></noscript></picture></span></a><div class="summary-item__content"><div class="rubric rubric--discovery summary-item__rubric">Video</div><a class="summary-item__hed-link summary-item-tracking__hed-link" href="http://video.newyorker.com/watch/a-robotic-arm-controlled-by-the-mind" data-component-type="recirc-river" data-recirc-id="item-hed-3" data-recirc-pattern="summary-item"><div class="summary-item__hed">A Robotic Arm Controlled by the Mind</div></a><p class="summary-item__dek">After Nathan Copeland survived a car crash that paralyzed him from the neck down, he volunteered for an ambitious program aimed at giving people mastery of brain-controlled robotics.</p><div class="summary-item__byline-date-icon"><div class="summary-item__byline"><div class="summary-item__byline__content"><p class="byline summary-item__byline-authors" itemProp="author" itemType="http://schema.org/Person"><span class="byline__preamble">By </span><span itemProp="name"><span class="byline__name">The New Yorker</span> </span></p></div></div></div></div></div><div tabindex="0" class="summary-item summary-item--article summary-item--no-icon summary-item--text-align-left summary-item--layout-placement-text-below summary-item--layout-position-image-left summary-item--layout-proportions-50-50 summary-collection-grid__item" role="button"><a class="summary-item__image-link summary-item-tracking__image-link" href="/tech/annals-of-technology/imitation-game-alan-turing" aria-hidden="true" tabindex="-1" data-component-type="recirc-river" data-recirc-id="item-image-4" data-recirc-pattern="summary-item"><span class="responsive-asset summary-item__image responsive-asset--invisible"><picture class="summary-item__image responsive-image"><noscript><source media="(max-width: 767px)" srcSet="https://media.newyorker.com/photos/59095e96019dfc3494e9fb3f/16:9/w_720%2Cc_limit/Rockmore-Imitation-Game.jpg 720w" sizes="100vw"/><source media="(min-width: 768px)" srcSet="https://media.newyorker.com/photos/59095e96019dfc3494e9fb3f/4:3/w_480%2Cc_limit/Rockmore-Imitation-Game.jpg 480w" sizes="100vw"/><img alt="Benedict Cumberbatch plays Alan Turing in The Imitation Game." class="responsive-image__image" src="https://media.newyorker.com/photos/59095e96019dfc3494e9fb3f/4:3/w_480%2Cc_limit/Rockmore-Imitation-Game.jpg"/></noscript></picture></span></a><div class="summary-item__content"><div class="rubric rubric--discovery summary-item__rubric"><a class="rubric__link" href="/tech/annals-of-technology">Annals of Technolog<span class="link__last-letter-spacing">y</span></a></div><a class="summary-item__hed-link summary-item-tracking__hed-link" href="/tech/annals-of-technology/imitation-game-alan-turing" data-component-type="recirc-river" data-recirc-id="item-hed-4" data-recirc-pattern="summary-item"><div class="summary-item__hed">What’s Missing from “The Imitation Game”</div></a><div class="summary-item__byline-date-icon"><div class="summary-item__byline"><div class="summary-item__byline__content"><p class="byline summary-item__byline-authors" itemProp="author" itemType="http://schema.org/Person"><span class="byline__preamble">By </span><span itemProp="name"><span class="byline__name">Dan Rockmore</span> </span></p></div></div></div></div></div></div></div></div></div></div></div><div class="row"><div class="ad ad--footer"><div class="ad__slot ad__slot--footer"></div></div></div></div></div></main><div class="page__main-footer-filler"></div><div class="row"><div class="consumer-marketing-unit consumer-marketing-unit--cm-footer consumer-marketing-unit--no-failsafe"><div class="consumer-marketing-unit__slot consumer-marketing-unit__slot--cm-footer"></div></div></div><div class="row page__site-footer"><div class="grid grid-margins grid-items-0"><footer class="site-footer site-footer--link-dense site-footer--with-store grid--item"><div class="site-footer__container"><div class="site-footer__brand-info"><div class="site-footer__logo"><a href="/" class="site-footer__logo-link"><span class="responsive-asset site-footer__responsive-image"><picture class="site-footer__responsive-image responsive-image"><img alt="The New Yorker" class="responsive-image__image" src="/verso/static/the-new-yorker/assets/logo-reverse.f915b516b6ca9c0c2a9bdf9b749519365b2b2e4a.svg" srcSet="" sizes="100vw"/></picture></span></a></div></div><nav aria-label="Sections" class="navigation navigation--vertical site-footer__navigation navigation--collapsible navigation--closed"><p class="navigation__heading"><button class="navigation__heading-button" type="button" aria-expanded="false">Sections<span class="navigation__arrow"></span></button></p><ul class="navigation__list"><li class="navigation__list-item"><a class="navigation__link" href="/news">News</a></li><li class="navigation__list-item"><a class="navigation__link" href="/culture">Books &amp; Culture</a></li><li class="navigation__list-item"><a class="navigation__link" href="/fiction-and-poetry">Fiction &amp; Poetry</a></li><li class="navigation__list-item"><a class="navigation__link" href="/humor">Humor &amp; Cartoons</a></li><li class="navigation__list-item"><a class="navigation__link" href="/magazine">Magazine</a></li><li class="navigation__list-item"><a class="navigation__link" href="/crossword">Crossword</a></li><li class="navigation__list-item"><a class="navigation__link" href="https://video.newyorker.com">Video</a></li><li class="navigation__list-item"><a class="navigation__link" href="/podcast">Podcasts</a></li><li class="navigation__list-item"><a class="navigation__link" href="/archive">Archive</a></li><li class="navigation__list-item"><a class="navigation__link" href="/goings-on-about-town">Goings On</a></li></ul></nav><nav aria-label="More" class="navigation navigation--vertical site-footer__navigation-contact navigation--collapsible navigation--closed"><p class="navigation__heading"><button class="navigation__heading-button" type="button" aria-expanded="false">More<span class="navigation__arrow"></span></button></p><ul class="navigation__list"><li class="navigation__list-item"><a class="external-link navigation__link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://w1.buysub.com/servlet/CSGateway?cds_mag_code=NYR&quot;}" href="http://w1.buysub.com/servlet/CSGateway?cds_mag_code=NYR" rel="nofollow noopener noreferrer" target="_blank">Customer Care</a></li><li class="navigation__list-item"><a class="external-link navigation__link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.condenaststore.com/-st/New-Yorker-Covers-Prints_c147247_.htm&quot;}" href="http://www.condenaststore.com/-st/New-Yorker-Covers-Prints_c147247_.htm" rel="nofollow noopener noreferrer" target="_blank">Buy Covers and Cartoons</a></li><li class="navigation__list-item"><a class="navigation__link" href="/digital-editions">Apps</a></li><li class="navigation__list-item"><a class="navigation__link" href="/newsletters">Newsletters</a></li><li class="navigation__list-item"><a class="navigation__link" href="/jigsaw">Jigsaw Puzzle</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/feeds">RSS</a></li><li class="navigation__list-item"><a class="navigation__link" href="/sitemap">Site Map</a></li></ul></nav><div class="site-footer__notices"><div class="site-footer__notices-container"><nav aria-label="Notices" class="navigation navigation--horizontal site-footer__navigation-notices"><ul class="navigation__list"><li class="navigation__list-item"><a class="navigation__link" href="/about/us">About</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/careers">Careers</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/contact">Contact</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/faq">FAQ</a></li><li class="navigation__list-item"><a class="navigation__link" href="http://www.condenast.com/brands/the-new-yorker">Media Kit</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/press">Press</a></li><li class="navigation__list-item"><a class="navigation__link" href="/about/accessibility-help">Accessibility Help</a></li></ul></nav><p class="site-footer__legalese">© <!-- -->2020<!-- --> Condé Nast. All rights reserved. Use of this site constitutes acceptance of our<!-- --> <a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.condenast.com/user-agreement/&quot;}" href="https://www.condenast.com/user-agreement/" rel="nofollow noopener noreferrer" target="_blank">User Agreement</a> <!-- -->(updated <!-- -->1/1/20<!-- -->) and<!-- --> <a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.condenast.com/privacy-policy#privacypolicy&quot;}" href="http://www.condenast.com/privacy-policy#privacypolicy" rel="nofollow noopener noreferrer" target="_blank">Privacy Policy and Cookie Statement</a> <!-- -->(updated <!-- -->1/1/20<!-- -->) and<!-- --> <a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.condenast.com/privacy-policy#privacypolicy-california&quot;}" href="http://www.condenast.com/privacy-policy#privacypolicy-california" rel="nofollow noopener noreferrer" target="_blank">Your California Privacy Rights.</a> <button id="ot-sdk-btn" class="ot-sdk-show-settings">Do Not Sell My Personal Information</button> <em>The New Yorker</em> may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.<!-- --> <a class="external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.condenast.com/privacy-policy#privacypolicy-optout&quot;}" href="http://www.condenast.com/privacy-policy#privacypolicy-optout" rel="nofollow noopener noreferrer" target="_blank">Ad Choices</a></p><div class="site-footer__collection-container"></div><div class="social-icons social-icons--footer site-footer__social-icons"><ul class="social-icons__list"><li class="social-icons__list-item social-icons__list-item--facebook social-icons__list-item--footer thinner"><a aria-label="Follow us on Facebook" class="external-link social-icons__link social-icons__link--facebook social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.facebook.com/newyorker/&quot;}" href="https://www.facebook.com/newyorker/" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-facebook" focusable="false" width="7.2" height="16" viewBox="0 0 7.2 16" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M1.548 3.099v2.203H0v2.693h1.548V16h3.179V7.995H6.86s.2-1.291.297-2.703H4.739V3.45c0-.275.346-.646.689-.646H7.16V0H4.805C1.47 0 1.548 2.696 1.548 3.099z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--twitter social-icons__list-item--footer thinner"><a aria-label="Follow us on Twitter" class="external-link social-icons__link social-icons__link--twitter social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://twitter.com/NewYorker/&quot;}" href="https://twitter.com/NewYorker/" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-twitter" focusable="false" width="15.3" height="13" viewBox="0 0 15.3 13" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M15.275 1.539a6.04 6.04 0 0 1-1.8.517A3.268 3.268 0 0 0 14.854.24a6.127 6.127 0 0 1-1.99.797A3.067 3.067 0 0 0 10.575 0c-1.73 0-3.134 1.47-3.134 3.281 0 .257.028.508.081.748C4.918 3.892 2.61 2.585 1.063.6A3.382 3.382 0 0 0 .64 2.25c0 1.14.552 2.144 1.393 2.732a3.001 3.001 0 0 1-1.418-.41v.042c0 1.59 1.08 2.916 2.513 3.218a3.011 3.011 0 0 1-1.415.056c.399 1.304 1.556 2.253 2.926 2.28A6.111 6.111 0 0 1 0 11.525 8.59 8.59 0 0 0 4.805 13c5.764 0 8.916-5 8.916-9.338a8.96 8.96 0 0 0-.01-.425 6.522 6.522 0 0 0 1.564-1.698z"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--snapchat social-icons__list-item--footer"><a aria-label="Follow us on Snapchat" class="external-link social-icons__link social-icons__link--snapchat social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.snapchat.com/add/newyorkermag&quot;}" href="https://www.snapchat.com/add/newyorkermag" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-snapchat" focusable="false" viewBox="0 0 32 32" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><title>Snapchat</title><path d="M16.134 9h-.04l-.276.003c-.658 0-2.89.183-3.942 2.543-.354.794-.27 2.143-.201 3.226l.024.389a.636.636 0 0 1-.31.068c-.21 0-.457-.066-.735-.197a.592.592 0 0 0-.253-.051c-.325 0-.715.214-.775.533-.044.23.059.565.798.857.067.027.147.052.232.079.305.097.767.243.892.538.065.153.039.35-.077.585l-.007.016c-.041.095-1.018 2.321-3.187 2.679a.331.331 0 0 0-.276.345c.002.05.014.1.035.148.163.38.85.66 2.1.854.041.056.085.256.111.377.027.12.053.244.092.375.038.128.135.282.387.282.102 0 .222-.024.36-.051.209-.04.494-.097.851-.097.198 0 .403.018.61.052.403.067.746.31 1.143.59.569.402 1.212.857 2.19.857.028 0 .055 0 .082-.003.031.002.072.003.116.003.98 0 1.623-.455 2.19-.857.399-.28.741-.523 1.145-.59.206-.034.411-.052.61-.052.34 0 .61.044.85.09.15.03.272.045.36.045h.019a.36.36 0 0 0 .369-.276c.037-.128.064-.249.091-.37.026-.122.07-.32.111-.377 1.251-.194 1.938-.472 2.1-.851a.44.44 0 0 0 .036-.15.33.33 0 0 0-.277-.345c-2.17-.357-3.146-2.584-3.186-2.678a.24.24 0 0 0-.008-.016c-.116-.235-.141-.432-.076-.585.125-.295.586-.441.892-.538.085-.027.165-.053.231-.079.541-.213.813-.476.807-.78-.005-.238-.19-.45-.486-.556h-.001a.888.888 0 0 0-.333-.065.736.736 0 0 0-.305.062c-.258.121-.489.187-.688.195a.61.61 0 0 1-.268-.066l.02-.342.003-.046c.069-1.084.154-2.434-.2-3.228C19.03 9.184 16.793 9 16.133 9z" fill-rule="evenodd"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--youtube social-icons__list-item--footer"><a aria-label="Follow us on YouTube" class="external-link social-icons__link social-icons__link--youtube social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.youtube.com/user/NewYorkerDotCom/&quot;}" href="https://www.youtube.com/user/NewYorkerDotCom/" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-youtube" focusable="false" viewBox="0 0 32 32" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><title>Youtube</title><path d="M23.666 11.76a2.01 2.01 0 0 0-1.415-1.423C21.003 10 16 10 16 10s-5.003 0-6.251.337a2.01 2.01 0 0 0-1.415 1.423C8 13.016 8 15.636 8 15.636s0 2.62.334 3.876a2.01 2.01 0 0 0 1.415 1.424c1.248.337 6.251.337 6.251.337s5.003 0 6.251-.337a2.01 2.01 0 0 0 1.415-1.424C24 18.257 24 15.636 24 15.636s0-2.62-.334-3.876m-9.302 6.255v-4.758l4.181 2.38-4.181 2.378" fill-rule="evenodd"></path></svg></div></a></li><li class="social-icons__list-item social-icons__list-item--instagram social-icons__list-item--footer"><a aria-label="Follow us on Instagram" class="external-link social-icons__link social-icons__link--instagram social-icons__external-link" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://instagram.com/newyorkermag/&quot;}" href="https://instagram.com/newyorkermag/" rel="nofollow noopener noreferrer" target="_blank"><div class="social-icons__icon-container"><svg class="icon icon-instagram" focusable="false" viewBox="0 0 32 32" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M16 8c2.173 0 2.445.01 3.298.048.852.039 1.433.174 1.942.372.526.204.973.478 1.417.923.445.444.719.89.923 1.417.198.509.333 1.09.372 1.942.039.853.048 1.125.048 3.298s-.01 2.445-.048 3.298c-.039.852-.174 1.433-.372 1.942a3.922 3.922 0 0 1-.923 1.417c-.444.445-.89.719-1.417.923-.509.198-1.09.333-1.942.372-.853.039-1.125.048-3.298.048s-2.445-.01-3.298-.048c-.852-.039-1.433-.174-1.942-.372a3.922 3.922 0 0 1-1.417-.923 3.921 3.921 0 0 1-.923-1.417c-.198-.509-.333-1.09-.372-1.942C8.01 18.445 8 18.173 8 16s.01-2.445.048-3.298c.039-.852.174-1.433.372-1.942.204-.526.478-.973.923-1.417.444-.445.89-.719 1.417-.923.509-.198 1.09-.333 1.942-.372C13.555 8.01 13.827 8 16 8zm0 2c-1.954 0-2.186.007-2.957.043-.714.032-1.101.151-1.36.252a2.267 2.267 0 0 0-.84.547c-.257.256-.416.5-.548.842-.1.258-.22.645-.252 1.359C10.007 13.814 10 14.046 10 16s.007 2.186.043 2.957c.032.714.151 1.101.252 1.36.132.341.291.585.547.84.256.257.5.416.842.548.258.1.645.22 1.359.252.771.036 1.003.043 2.957.043s2.186-.007 2.957-.043c.714-.032 1.101-.151 1.36-.252.341-.132.585-.291.84-.547.257-.256.416-.5.548-.842.1-.258.22-.645.252-1.359.036-.771.043-1.003.043-2.957s-.007-2.186-.043-2.957c-.032-.714-.151-1.101-.252-1.36a2.267 2.267 0 0 0-.547-.84 2.267 2.267 0 0 0-.842-.548c-.258-.1-.645-.22-1.359-.252C18.186 10.007 17.954 10 16 10zm0 1.768a4.232 4.232 0 1 1 0 8.464 4.232 4.232 0 0 1 0-8.464zm0 6.6a2.368 2.368 0 1 0 0-4.736 2.368 2.368 0 0 0 0 4.736zm5.3-6.518a1.15 1.15 0 1 1-2.3 0 1.15 1.15 0 0 1 2.3 0z" fill-rule="evenodd"></path></svg></div></a></li></ul></div></div></div></div></footer></div></div></div></div><script type="text/javascript">window.__PRELOADED_STATE__ = {"componentConfig":{"AccountLinks":{"settings":{"hasSignOutSeparator":false,"signOutButtonLabel":"Sign out"}},"ArticlePage":{"settings":{"hasLightbox":false,"hasSlideShow":false}},"BasePage":{"settings":{"showContentFooterWithHeaderOverride":true,"showNavWithHeaderOverride":false}},"BlockquoteEmbed":{"settings":{"hasParagraphMargin":true,"hasSmallMargins":true,"hasTopBorder":false}},"Caption":{"settings":{"shade":"light"}},"ChunkedArticleContent":{"variation":"WithAdRail","settings":{"horizontalRuleStyle":"thin","multiChunkRailStrategy":"alternate","singleChunkRailStrategy":"split-in-three"}},"ContributorBio":{"settings":{"shouldHideSocialIcons":true,"shouldHideTitle":true,"shouldUseTitleForContributorBio":true}},"ContentHeader":{"variation":"TextAboveLeftSmallWithRule","settings":{"dividerType":"bottom","rubricVariation":"Item","hasContributorImageBackground":true,"hasDesktopTitleBlockDivider":true,"hideIssueDate":false,"hideIssueDatePipeSeparator":true,"persistentAsideAlign":"left-lead-asset"}},"GallerySlide":{"variation":"ItemLeft"},"Drawer":{"variation":"LeftAlign","settings":{"hideSocialIcons":true,"overlayColor":"white","showSearch":true}},"ExternalLinkEmbed":{"settings":{"hasArrowIcon":false}},"GalleryEmbed":{"settings":{"shouldCycleSlides":true,"showAds":false,"midGalleryAdCadence":6,"midGalleryAdsLimit":1}},"RecircList":{"variation":"FourUp","settings":{"applicationID":"the-new-yorker-bottom-recirc","contentTypes":"article","excludeCategories":["functional-tags\u002Fnoriver"],"numberOfDays":-30,"pageSize":4,"shouldHideRubric":false,"strategy":"similar"}},"RecircMostPopular":{"variation":"NumberedListBySummary","settings":{"applicationID":"the-new-yorker-right-rail","contentTypes":"article,gallery","disablePrimaryRelated":true,"excludeCategories":["functional-tags\u002Fnoriver"],"pageSize":5,"numberOfDays":-30,"hasAd":false,"hasDiscoveryBodyNumbers":true,"hasRubricHeading":true,"hasThinBorderHeading":true,"hideSummaryItemBorder":true,"hideRubricSummaryItem":true,"strategy":"popular","shouldHideRubric":true}},"RecircRiser":{"settings":{"applicationID":"the-new-yorker-riser","contentTypes":"article,gallery","excludeCategories":["functional-tags\u002Fnoriver"],"numberOfDays":-30,"pageSize":4,"shouldHideRubric":false,"strategy":"similar"}},"SiteFooter":{"variation":"LinkDense","settings":{"hideTagline":true}},"SocialIcons":{"variation":"Circular","settings":{"icons":"thinner"}},"StackedNavigation":{"variation":"FixedHeader","settings":{"navigationHideStrategy":"delta","primaryNavigationSize":"large","profileLinkLabel":"My Profile","isReturnUrlEnabled":true}},"SummaryItem":{"settings":{"hasRule":false,"maxHedLines":null,"shouldHideDangerousDek":false,"shouldHideIcon":true}},"tempHomepageRelated":{"settings":{"applicationID":"the-new-yorker-verso-hp-trending","contentTypes":"article","pageSize":10,"numberOfDays":-30,"strategy":"popular"}},"Toggle":{"variation":"Triangle"},"GroupCallout":{"settings":{"heading":{"article":"Related Stories"}}},"GenericCallout":{"settings":{"smallWidth":"wide","mediumWidth":"narrow"}}},"featureFlags":{"enableAccounts":true,"enableAnalytics":true,"enableDropcap":true,"enableEntitlementProxy":true,"enableEntitlementValidation":true,"enableEntitlementGrantLogic":false,"enableGoogleAmp":true,"enablePayment":true,"enableRecipeRatings":false,"gridWidth":"full-bleed","hideDate":false,"hideRubric":false,"hideHomepageRelated":false,"hideRecircRiser":true,"ledeAlignment":"default","shouldExtractRecircRubricFromCategories":true,"summaryDisplayType":"default","isWideImageCard":false,"recentWorkTeaser":"rubric-or-channel","contentTeaser":"rubric-or-channel-or-section","navigationDecorationStyle":"border-thin","preferCollectionGrid":false,"fullWidthBlockStyle":"default","avatarImageShape":"round","overrideBodyContentHeadings":true,"thumbnailImageShape":"rectangle","enableSponsoredContentInRelated":false,"enableBookmarking":true,"enableRecipeActions":{"print":false,"save":false},"patternVariations":{"navigation":{"pattern":"Stacked"},"article":{"product-embed":"ImageLeft"},"gallery":{"slide":"ItemLeft"},"homepage":{"summaryCollageFive":{"rubric":"DiscoveryCard"},"summaryCollageOne":{"rubric":"DiscoveryCard"},"summaryCollageThree":{"rubric":"DiscoveryCard"},"summaryCollectionGrid":{"rubric":"DiscoveryItem"},"summaryCollectionRow":{"rubric":"DiscoveryItem"}}},"globalSettingsWhitelist":{"BasePage":["theme"],"ContentHeader":["theme"],"NavigationComponent":["theme"]},"personalizeInlineRecirc":true,"personalizeRecircList":true,"personalizeRecircMostPopular":true,"videoPersistable":false,"cnePlaylistTheme":"inherit","google":{"swgEnabled":false,"signInEnabled":true},"embeddedLedeCategoriesPath":"formatting\u002Flede-image-layout\u002Flede-image--right-aligned","embeddedLedeDisabledPaths":["formatting\u002Fhero-layouts\u002Flayout--image-left","formatting\u002Fhero-layouts\u002Flayout--image-right"],"jsonld":{"useSubChannelAsSection":true},"hasHeaderIssueDateLink":true,"hasLeadStandardHeading":true,"hasMagazineHeaderPromoCopy":true,"hasMagazineDisclaimer":true,"hideHeroAdContentHeaders":["TextBelowCenterFullBleedNoContributor","SplitScreenImageLeftFullBleed","SplitScreenImageRightFullBleed"],"hideLedeImageCaption":false,"hideBylineContributorImage":false,"hideContributorBio":false,"hideOutbrain":true,"hideTagCloud":false,"issueLinkPrefix":"\u002Fmagazine","mediaSocialShares":[],"paddingTop":"large","socialShares":["facebook","twitter","email","print","bookmark"],"shouldUsePersistentAd":true,"newsletterModules":[{"newsletterId":217,"dangerousDek":"Sign up for our daily newsletter and get the best of \u003Ci\u003EThe New Yorker\u003C\u002Fi\u003E in your in-box."},{"newsletterId":442,"dangerousDek":"Sign up for the Daily Humor newsletter and get \u003Ci\u003EThe New Yorker\u003C\u002Fi\u003E cartoons and Shouts—plus more funny stuff—every day in your in-box!"},{"newsletterId":248840,"dangerousDek":"Never miss a big \u003Ci\u003ENew Yorker\u003C\u002Fi\u003E story again. Sign up for This Week’s Issue and get an e-mail every week with the stories you have to read."},{"newsletterId":5129,"dangerousDek":"Get the Borowitz Report in your in-box. Sign up now!"},{"newsletterId":248723,"dangerousDek":"Subscribe to John Cassidy’s newsletter to get the latest on politics, economics, and the news."},{"newsletterId":248822,"dangerousDek":"Sign up and get Amy Davidson Sorkin’s analysis of world news, American politics, and more, all delivered to your in-box."},{"newsletterId":248770,"dangerousDek":"Get book recommendations, fiction, poetry, and dispatches from the world of literature in your in-box. Sign up for the Books &amp; Fiction newsletter."},{"newsletterId":248895,"dangerousDek":"Sign up for \u003Ci\u003EThe New Yorker’s\u003C\u002Fi\u003E Movie Club Newsletter to get reviews of the current cinema, movie listings for the weekend ahead, and more."},{"newsletterId":248896,"dangerousDek":"Never miss a crossword. Sign up to be notified via e-mail when a new puzzle is published."},{"newsletterId":248771,"dangerousDek":"Sign up for a weekly list of the best things happening in New York City and beyond."},{"newsletterId":248868,"dangerousDek":"Sign up for \u003Ci\u003EThe New Yorker’s\u003C\u002Fi\u003E Food newsletter and get recommendations, reviews, and more, twice a month."},{"newsletterId":248755,"dangerousDek":"Never miss a podcast episode again! Subscribe to our newsletter for a weekly roundup of the latest \u003Ci\u003ENew Yorker\u003C\u002Fi\u003E podcasts."},{"newsletterId":248885,"dangerousDek":"Sign up for On the Trail and get election insights from \u003Ci\u003ENew Yorker\u003C\u002Fi\u003E writers in your in-box each week."},{"newsletterId":248934,"dangerousDek":"Sign up for Bill McKibben’s Climate Crisis newsletter and get weekly updates from inside the climate movement."}],"allowRelatedExternalLinks":true},"renditions":{"article":{"brandedSponsorLogo":{"sm":{"width":640},"md":{"width":768},"lg":{"width":1024},"xl":{"width":1280},"xxl":{"width":1600}},"contentPromo":{"sm":{"aspectRatio":"9:16","width":768},"md":{"aspectRatio":"9:16","width":1024},"lg":{"aspectRatio":"16:9","width":1280},"xl":{"aspectRatio":"16:9","width":1600},"xxl":{"aspectRatio":"16:9","width":1600}},"externalLink":{"sm":{"aspectRatio":"1:1","width":100},"md":{"aspectRatio":"1:1","width":100},"lg":{"aspectRatio":"1:1","width":200},"xl":{"aspectRatio":"1:1","width":200},"xxl":{"aspectRatio":"1:1","width":200}},"imageEmbed":{"sm":{"width":640},"md":{"width":768},"lg":{"width":1024},"xl":{"width":1280},"xxl":{"width":1600}},"recipeEmbed":{"sm":{"aspectRatio":"16:9","width":640},"md":{"aspectRatio":"16:9","width":768},"lg":{"aspectRatio":"16:9","width":768},"xl":{"aspectRatio":"16:9","width":775},"xxl":{"aspectRatio":"16:9","width":775}},"lede":{"sm":{"aspectRatio":"master","width":360},"md":{"aspectRatio":"master","width":1024},"lg":{"aspectRatio":"master","width":1280},"xl":{"aspectRatio":"master","width":1280},"xxl":{"aspectRatio":"master","width":2560}},"licensedPartnerBadge":{"sm":{"height":100}},"contributorThumbnail":{"sm":{"aspectRatio":"1:1","width":240},"md":{"aspectRatio":"1:1","width":240},"lg":{"aspectRatio":"1:1","width":270},"xl":{"aspectRatio":"1:1","width":270},"xxl":{"aspectRatio":"1:1","width":270}},"productEmbed":{"sm":{"width":360},"md":{"width":1024},"lg":{"width":1280},"xl":{"width":1280},"xxl":{"width":1280}},"articleEmbed":{"sm":{"width":640},"md":{"width":768},"lg":{"width":768},"xl":{"width":775},"xxl":{"width":775}},"relatedArticleEmbed":{"sm":{"width":640},"md":{"width":768},"lg":{"width":768},"xl":{"width":775},"xxl":{"width":775}},"reviewEmbed":{"sm":{"width":640},"md":{"width":768},"lg":{"width":768},"xl":{"width":775},"xxl":{"width":775}}},"bundle":{"summaryRiver":{"sm":{"aspectRatio":"1x1","width":720},"md":{"aspectRatio":"1x1","width":720},"lg":{"aspectRatio":"4x5","width":748},"xl":{"aspectRatio":"4x5","width":748}}},"cartoon":{"sm":{"aspectRatio":"master","width":360},"md":{"aspectRatio":"master","width":1024},"lg":{"aspectRatio":"master","width":1280},"xl":{"aspectRatio":"master","width":1280},"xxl":{"aspectRatio":"master","width":1280}},"contributor":{"lede":{"sm":{"aspectRatio":"1:1","width":164},"md":{"aspectRatio":"1:1","width":246},"lg":{"aspectRatio":"1:1","width":310},"xxl":{"aspectRatio":"1:1","width":350}},"recentWork":{"sm":{"aspectRatio":"16:9","width":180},"lg":{"aspectRatio":"1:1","width":228},"xxl":{"aspectRatio":"1:1","width":285}}},"gallery":{"lede":{"sm":"1:1","lg":"16:9"},"slides":{"sm":"master","lg":"master"},"social":{"sm":"16:9","lg":"16:9"}},"inlineRecirc":{"NoAssetTextLeft":{"sm":{"aspectRatio":"1:1","height":320,"width":320},"lg":{"aspectRatio":"1:1","height":320,"width":320}},"SideBySide":{"sm":{"aspectRatio":"1:1","height":320,"width":320},"lg":{"aspectRatio":"1:1","height":320,"width":320}},"TextOverlay":{"sm":{"aspectRatio":"2:3","width":768},"lg":{"aspectRatio":"2:3","width":768}}},"linkBanner":{"sm":{"aspectRatio":"master","height":150},"md":{"aspectRatio":"master","height":150},"lg":{"aspectRatio":"master","height":180},"xl":{"aspectRatio":"master","height":180}},"mostPopular":{"sm":{"aspectRatio":"1:1","height":350,"width":350},"lg":{"aspectRatio":"1:1","height":240,"width":240},"xl":{"aspectRatio":"1:1","height":350,"width":350}},"bundleHeader":{"lede":{"sm":{"aspectRatio":"1:1","width":360},"md":{"aspectRatio":"1:1","width":1024},"lg":{"aspectRatio":"2:1","width":1280},"xl":{"aspectRatio":"2:1","width":1280},"xxl":{"aspectRatio":"2:1","width":2560}}},"recircList":{"sm":{"aspectRatio":"16:9","width":720},"md":{"aspectRatio":"16:9","width":720},"lg":{"aspectRatio":"4:3","width":480},"xl":{"aspectRatio":"4:3","width":480}},"productCard":{"sm":{"aspectRatio":"1:1","width":360}},"recircListTextOverlay":{"sm":{"aspectRatio":"1:1","height":718,"width":718},"md":{"aspectRatio":"1:1","height":480,"width":480},"lg":{"aspectRatio":"1:1","height":565,"width":565},"xl":{"aspectRatio":"1:1","height":705,"width":705}},"review":{"lede":{"sm":{"aspectRatio":"1:1","width":320},"md":{"aspectRatio":"16:9","width":768},"lg":{"aspectRatio":"16:9","width":952},"xxl":{"aspectRatio":"16:9","width":1160}},"tout":{"sm":{"aspectRatio":"master","width":360},"md":{"aspectRatio":"master","width":1024},"lg":{"aspectRatio":"master","width":1280},"xl":{"aspectRatio":"master","width":1280},"xxl":{"aspectRatio":"master","width":1280}}},"recipe":{"imageEmbed":{"sm":{"width":640},"md":{"width":768},"lg":{"width":768},"xl":{"width":775},"xxl":{"width":775}},"lede":{"sm":{"aspectRatio":"master","width":360},"md":{"aspectRatio":"master","width":1024},"lg":{"aspectRatio":"master","width":1280},"xl":{"aspectRatio":"master","width":1280},"xxl":{"aspectRatio":"master","width":2560}},"tout":{"sm":{"aspectRatio":"master","width":360},"md":{"aspectRatio":"master","width":1024},"lg":{"aspectRatio":"master","width":1280},"xl":{"aspectRatio":"master","width":1280},"xxl":{"aspectRatio":"master","width":1280}},"contributorThumbnail":{"sm":{"aspectRatio":"1:1","width":80},"md":{"aspectRatio":"1:1","width":80},"lg":{"aspectRatio":"1:1","width":90},"xl":{"aspectRatio":"1:1","width":90},"xxl":{"aspectRatio":"1:1","width":90}},"cookbook":{"sm":{"width":70}}},"socialShare":{"aspectRatio":"16:9","width":1280},"tag":{"sm":{"aspectRatio":"16:9","width":180},"lg":{"aspectRatio":"1:1","width":228},"xxl":{"aspectRatio":"1:1","width":285}},"homepage":{"cneVideo":{"summaryCollageOne":{"sm":{"h":768,"w":768},"lg":{"h":720,"w":1280},"xxl":{"h":900,"w":1600}},"summaryCollageThree":{"primary":{"sm":{"h":768,"w":768},"lg":{"h":1024,"w":1024},"xxl":{"h":1280,"w":1280}},"secondary":{"sm":{"h":768,"w":768},"lg":{"h":432,"w":768}}},"summaryCollectionGrid":{"sm":{"h":768,"w":768},"lg":{"h":960,"w":1280},"xxl":{"h":1200,"w":1600}},"summaryCollageFive":{"primary":{"sm":{"h":768,"w":768},"lg":{"h":768,"w":768},"xxl":{"h":1024,"w":1024}},"secondary":{"sm":{"h":176,"w":320},"lg":{"h":352,"w":640}}},"summaryList":{"sm":{"h":768,"w":768},"lg":{"h":1289,"w":1280},"xxl":{"h":1600,"w":1600}},"summaryListWithAside":{"sm":{"h":768,"w":768},"lg":{"h":1280,"w":1280},"xxl":{"h":1600,"w":1600}}},"verso-promobox":{"sm":{"aspectRatio":"3:4","width":240},"md":{"aspectRatio":"16:9","width":960},"lg":{"aspectRatio":"16:9","width":1280},"xl":{"aspectRatio":"16:9","width":1920}},"verso-native":{"sm":{"aspectRatio":"1:1","width":160},"xxl":{"aspectRatio":"1:1","width":320}},"verso-related":{"sm":{"aspectRatio":"1:1","width":160},"xxl":{"aspectRatio":"1:1","width":320}},"verso-summary-collection-row":{"sm":{"aspectRatio":"1:1","width":160},"xxl":{"aspectRatio":"1:1","width":320}},"verso-river":{"sm":{"aspectRatio":"1:1","width":160},"lg":{"aspectRatio":"16:9","width":768}},"summaryCollageOne":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"16:9","width":1280},"xxl":{"aspectRatio":"16:9","width":1600}},"verso-ticker":{"sm":{"aspectRatio":"master","width":160},"md":{"aspectRatio":"master","width":160},"lg":{"aspectRatio":"master","width":160},"xl":{"aspectRatio":"master","width":160}},"summaryCollageThree":{"primary":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"1:1","width":1024},"xxl":{"aspectRatio":"1:1","width":1280}},"secondary":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"16:9","width":768}}},"summaryCollectionGrid":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"4:3","width":1280},"xxl":{"aspectRatio":"4:3","width":1600}},"summaryCollageFive":{"primary":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"1:1","width":768},"xxl":{"aspectRatio":"1:1","width":1024}},"secondary":{"sm":{"aspectRatio":"16:9","width":320},"lg":{"aspectRatio":"16:9","width":640}}},"summaryList":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"4:3","width":1280},"xxl":{"aspectRatio":"4:3","width":1600}},"summaryListWithAside":{"sm":{"aspectRatio":"1:1","width":768},"lg":{"aspectRatio":"1:1","width":1280},"xxl":{"aspectRatio":"1:1","width":1600}},"tout":{"sm":{"aspectRatio":"16:9","width":1280},"xxl":{"aspectRatio":"16:9","width":1280}}}},"transformed":{"ads.page":{"channel":"culture","contentType":"article","keywords":{"copilotid":["5e1cc31e2751bc0008ff607c"],"platform":["verso"],"tags":["alan-turing","artificial-intelligence","second-world-war","science-fiction","technology","mathematics","culture-desk"]},"server":"production","slug":"living-in-alan-turings-future","subChannel":"culture-desk","templateType":"mt_article_two_column"},"payment":{"form":"sample","scopedForm":"sample","acceptableFormsOfTenderedPayment":["sample"],"acceptableForms":["free","sample","sub"],"acceptableScopes":[],"groupsToRender":["ads","consumer-marketing","paywall","subscription-workflow"],"entitlement":{"enabled":true,"domain":".newyorker.com","server":""},"negotiation":{"tender":"free; q=0.9, sample; q=0.8","content":{"channelSlug":"culture","contentType":"article","functionalTags":[],"isBranded":false,"isPreview":false},"config":{"acceptableForms":["free","sample","sub"],"acceptableScopes":[],"contentTypes":["article"],"renderingRules":[{"form":"free","groups":["ads","consumer-marketing","subscription-workflow"]},{"form":"sample","groups":["ads","consumer-marketing","paywall","subscription-workflow"]},{"form":"sub","groups":["ads","consumer-marketing","subs-cta"]},{"form":"","groups":["ads","consumer-marketing","paywall","subscription-workflow"]}],"entitlementChecks":{}},"logic":{}}},"response":{"headers":{"payment":"sample"},"statusCode":200},"paywall":{"strategy":"beta","paragraphLimit":1,"isMuted":false,"truncationMessage":{"subscribeUrl":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE","subscribeSource":"HCL_NYR_GLOBAL_TRUNCATED_MESSAGE_FAILSAFE_0"}},"failsafe":{"server":"https:\u002F\u002Ffailsafe-cache.conde.io","brandSlug":"the-new-yorker","contentType":"article","shouldShowByDefault":false,"slots":{"cm_cm_footer":["div",{"class":"cm-footer-failsafe"},"\n  ",["style",".cm-footer-wrapper{background-color:#173e5d;color:#fff;display:-webkit-box;display:-ms-flexbox;display:flex;font-family:Graphik,Arial,Helvetica,sans-serif;margin:0 auto;overflow:hidden;text-decoration:none;transition:opacity .3s ease-in-out}.cm-footer-wrapper:hover{opacity:.8}.cm-footer-header{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;font-family:TNYAdobeCaslonPro,Arial,Helvetica,sans-serif;text-align:left}.cm-footer-subscribe{background-color:#fff;border-radius:2px;color:#000;display:inline-block;font-size:13px;height:38px;line-height:38px;text-align:center;width:109px}.cm-footer-copy{display:inline-block;font-size:16px;line-height:23px}.cm-footer-cancel{font-size:13px;height:23px;line-height:23px;width:108px}.cm-footer-img{height:100%;width:100%}.cm-footer-subscribe:focus,.cm-footer-subscribe:hover{background-color:#d1d1d1;text-decoration:underline}@media screen and (min-width:1024px){.cm-footer-wrapper{width:940px;height:140px;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;padding:0 16px 0 43px}.cm-footer-content{padding:35px 0 43px 0}.cm-footer-header{font-size:40px;line-height:29px;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:22px}.cm-footer-header span{margin-left:4px}.cm-footer-img-container{width:220px;height:auto}.cm-footer-mobile,.cm-footer-tablet{display:none}}@media screen and (min-width:768px) and (max-width:1023px){.cm-footer-wrapper{width:724px;height:190px}.cm-footer-content{padding:21px 0 0 40px}.cm-footer-header{font-size:32px;height:114px;line-height:38px;width:250px}.cm-footer-copy{font-size:15px;font-weight:500;line-height:20px}.cm-footer-subscribe{margin:0 8px 0 5px}.cm-footer-cancel{height:20px;line-height:20px}.cm-footer-img-container{width:224px;height:193px;margin-left:15px}.cm-footer-desktop,.cm-footer-mobile{display:none}}@media screen and (max-width:767px){.cm-footer-wrapper{width:276px;height:100px;padding:12px 0 0 18px}.cm-footer-header{font-size:28px;line-height:29px;margin-bottom:12px}.cm-footer-copy{font-size:13px;line-height:18px}.cm-footer-img-container{text-align:right}.cm-footer-img{height:79px;left:12px;-o-object-fit:contain;object-fit:contain;position:relative;top:6px;-webkit-transform:rotate(10deg);-ms-transform:rotate(10deg);transform:rotate(10deg);width:73px}.cm-footer-subscribe{height:27px;line-height:27px;margin-right:9px;width:90px}.cm-footer-desktop,.cm-footer-non-mobile,.cm-footer-tablet{display:none}}"],"\n  ",["div","\n    ",["a",{"class":"cm-footer-wrapper","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_GLOBAL_CM_FOOTER_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer"},"\n      ",["div",{"class":"cm-footer-content"},"\n        ",["span",{"class":"cm-footer-header"},"Dig Deeper.",["span",{"class":"cm-footer-non-mobile"},"Think harder. ",["br",{"class":"cm-footer-tablet"}],"\n            See Further."]],"\n        ",["span",{"class":"cm-footer-copy"},"Subscribe and get a free tote.\n          ",["span",{"class":"cm-footer-subscribe cm-footer-non-mobile"},"Subscribe"],"\n          ",["span",{"class":"cm-footer-cancel"},"Cancel anytime."],"\n        "],"\n      "],"\n      ",["div",{"class":"cm-footer-img-container"},"\n        ",["img",{"class":"cm-footer-img cm-footer-tablet","src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5de7af44d1aee60008cecac7\u002Fmaster\u002Fpass\u002FGroup%201.png","alt":"The New Yorker Magazine and Tote"}],"\n        ",["img",{"class":"cm-footer-img cm-footer-desktop","src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5de7af676da27e0008ff8a89\u002Fmaster\u002Fpass\u002FGroup%204.png","alt":"The New Yorker Magazine and Tote"}],"\n        ",["span",{"class":"cm-footer-subscribe cm-footer-mobile"},"Subscribe"],"\n        ",["img",{"class":"cm-footer-img cm-footer-mobile","src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5dc1c6fb174e4e0009c41218\u002Fmaster\u002Fpass\u002FnyrBag.png","alt":"The New Yorker Tote"}],"\n      "],"\n    "],"\n  "],"\n"],"cm_incognito_modal_call_to_action":["div",{"class":"incognito-modal"},"\n  ",["script","const e=(e={})=\u003E{'function'==typeof e?window.dataLayer.push(e()):Object.getOwnPropertyNames(e).length\u003E0&&window.dataLayer.push(e)},n=e=\u003E{const{cnBus:n}=window;n&&n.emit?e&&n.emit(`cm.failsafe.${e}.rendered`):console.error('Failed to emit failsafe rendered event because cnBus was not present.')};e({event:'incognito-modal-failsafe-impression'}),n('cm_incognito_modal_call_to_action');"],"\n  ",["style",".incognito-barrier{-webkit-box-direction:normal;-webkit-box-orient:vertical;-webkit-font-smoothing:antialiased;background:#fff;box-sizing:border-box;display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-direction:column;flex-direction:column;font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;height:638px;margin:0 auto;text-align:center;width:520px}.incognito-barrier img{height:250px;margin:0 auto;-o-object-fit:contain;object-fit:contain;width:250px}.incognito-barrier__heading{font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;font-size:40px;line-height:45px;margin-top:60px}.incognito-barrier__detail{font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;font-size:21px;line-height:27px;margin:10px 65px}.incognito-barrier__subscribe-button{background:#0879bf;border-radius:2px;color:#fff;font-family:Graphik,\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:13px;height:48px;line-height:48px;margin:30px auto 0 auto;text-align:center;text-decoration:none;width:255px}.incognito-barrier__subscribe-button:focus,.incognito-barrier__subscribe-button:hover{background-color:#07588b}.incognito-barrier__sign-in{color:#666;font-family:Graphik,\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:13px;line-height:25px;margin:13px auto 0 15px}.incognito-barrier__sign-in a{color:#121212;font-weight:500;text-decoration:none}.incognito-barrier__sign-in a:hover{color:#121212;text-decoration:underline}@media (max-width:768px){.incognito-barrier{height:510px;width:375px}.incognito-barrier img{height:210px;width:210px}.incognito-barrier__heading{font-size:32px;line-height:40px;margin-top:32px}.incognito-barrier__detail{font-size:18px;line-height:26px;margin:5px 30px 15px 30px}.incognito-barrier__subscribe-button{margin:0 auto}}@media (max-width:374px){.incognito-barrier{width:325px}.incognito-barrier__heading{margin-top:27px}}@media (max-width:767px){.link-desktop,.link-tablet{display:none}}@media (min-width:768px) and (max-width:1023px){.link-desktop,.link-mobile{display:none}}@media (min-width:1024px){.link-mobile,.link-tablet{display:none}}"],"\n  ",["div",{"class":"incognito-barrier"},"\n    ",["div",{"class":"incognito-barrier__sign-in"},"Already a subscriber?\n      ",["a",{"class":"incognito-barrier__sign-in-button","href":"https:\u002F\u002Faccount.newyorker.com\u002F","trackingname":"incognito-modal-signin"},"Sign in"],"\n    "],"\n    ",["span",{"class":"incognito-barrier__heading"},"\n      You’ve disappeared.\n    "],"\n    ",["img",{"src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5df3d934728d9400086727f6\u002Fmaster\u002Fpass\u002Fasset-elevator-incognito%402x.png","alt":"You've disappeared."}],"\n    ",["span",{"class":"incognito-barrier__detail"},"To continue using a private window, sign in or subscribe. Become a ",["em","New Yorker"]," subscriber, and get a free tote."],"\n    ",["a",{"target":"_blank","rel":"noopener noreferrer","class":"incognito-barrier__subscribe-button link-desktop","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_DESKTOP_INCOGNITO_BARRIER_FAILSAFE_0","trackingname":"incognito-modal-subscribe"},"Subscribe"],"\n    ",["a",{"target":"_blank","rel":"noopener noreferrer","class":"incognito-barrier__subscribe-button link-tablet","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_TABLET_INCOGNITO_BARRIER_FAILSAFE_0","trackingname":"incognito-modal-subscribe"},"Subscribe"],"\n    ",["a",{"target":"_blank","rel":"noopener noreferrer","class":"incognito-barrier__subscribe-button link-mobile","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_MOBILE_INCOGNITO_BARRIER_FAILSAFE_0","trackingname":"incognito-modal-subscribe"},"Subscribe"],"\n  "],"\n"],"cm_mob_nav_cta":["div",{"class":"cm-mob-nav-cta-failsafe"},"\n  ",["style",".cm-mob-nav-cta{height:30px;margin-right:21px;width:75px}.cm-mob-nav-cta-anchor{background:#0787ca;border-radius:2px;color:#fff;display:block;font-family:\"Graphik Web\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:10px;font-weight:500;height:100%;line-height:30px;text-align:center;text-decoration:inherit;width:100%}"],"\n  ",["div",{"class":"cm-mob-nav-cta"},"\n    ",["a",{"class":"cm-mob-nav-cta-anchor","target":"_blank","rel":"noopener noreferrer","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_GLOBAL_NAV_CTA_FAILSAFE_0"},"Subscribe"],"\n  "],"\n"],"cm_nav_cta":["div",{"class":"cm-nav-cta-failsafe"},"\n  ",["style",".cm-nav-cta{height:30px;margin-right:21px;width:112px}.cm-nav-cta-anchor{background:#0787ca;border-radius:2px;color:#fff;display:block;font-family:\"Graphik Web\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:12px;font-weight:500;height:100%;line-height:30px;text-align:center;text-decoration:inherit;width:100%}"],"\n  ",["div",{"class":"cm-nav-cta"},"\n    ",["a",{"class":"cm-nav-cta-anchor","target":"_blank","rel":"noopener noreferrer","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_GLOBAL_NAV_CTA_FAILSAFE_0"},"Subscribe"],"\n  "],"\n"],"cm_nav_left":["div",{"class":"cm-nav-left-failsafe"},"\n  ",["style",".cm-nav-left-anchor{color:#000;font-family:Graphik,\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:12px;font-weight:500;text-decoration:none}.cm-nav-left-anchor:hover{text-decoration:underline}"],"\n  ",["div","\n    ",["a",{"href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_NAV_LEFT_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer","class":"cm-nav-left-anchor"}," Subscribe and get a tote. »"],"\n  "],"\n"],"cm_nav_rollover":["div",{"class":"cm-nav-rollover-failsafe"},"\n  ",["style",".cm-nav-rollover-wrapper{display:block;background-color:#173e5d;color:#fff;font-family:Graphik,Arial,Helvetica,sans-serif;height:200px;overflow:hidden;width:300px}.cm-nav-rollover-content{padding:12px 0 14px 20px;width:142px}.cm-nav-rollover-header{display:inline-block;font-family:TNYAdobeCaslonPro,Arial,Helvetica,sans-serif;font-size:24px;height:84px;line-height:28px;width:142px}.cm-nav-rollover-copy{display:inline-block;font-size:13px;font-weight:500;line-height:17px;margin:10px 0 12px}.cm-nav-rollover-subscribe{background-color:#fff;border-radius:2px;color:#000;display:inline-block;font-size:13px;height:34px;line-height:34px;text-align:center;text-decoration:none;width:115px}.cm-nav-rollover-subscribe:focus,.cm-nav-rollover-subscribe:hover{background-color:#d1d1d1;text-decoration:underline}.cm-nav-rollover-img{height:190px;-o-object-fit:contain;object-fit:contain;position:absolute;right:-13px;top:10px;width:170px}"],"\n  ",["div","\n    ",["a",{"class":"cm-nav-rollover-wrapper","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HCL_NYR_DESKTOP_GLOBAL_NAV_ROLLOVER_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer"},"\n      ",["div",{"class":"cm-nav-rollover-content"},"\n        ",["span",{"class":"cm-nav-rollover-header"},"Dig deeper. Think harder. See further"],"\n        ",["span",{"class":"cm-nav-rollover-copy"},"Subscribe and get a free tote."],"\n        ",["span",{"class":"cm-nav-rollover-subscribe"},"Subscribe"],"\n      "],"\n      ",["img",{"src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5de7b7d706eaeb00083703e5\u002Fmaster\u002Fpass\u002FTNY%20Rollover.png","alt":"The New Yorker Tote and Magazine","class":"cm-nav-rollover-img"}],"\n    "],"\n  "],"\n"],"cm_paywall_bar_call_to_action":["div",{"class":"paywall-bar-failsafe"},"\n  ",["script","!function(){let a=document.querySelector('.paywall-bar-wrapper');if(!a)return;let e=a.querySelector('.paywall-bar-caret'),r=a.querySelector('.paywall-bar-collapsed-copy'),l=a.querySelector('.paywall-bar-img'),t=a.querySelectorAll('.paywall-bar-sign-in-anchor'),n=a.querySelectorAll('.paywall-bar-expanded-subscribe'),o=a.querySelectorAll('.paywall-bar-collapsed-subscribe');const c=function(a){try{window.top.dataLayer.push({event:a})}catch(a){console.error('Error in growler ad tracking calls',a)}},s=function(a,e){for(let r of a)r.addEventListener('click',e)},i=function(){a.classList.contains('paywall-bar__expanded')?(a.classList.add('paywall-bar__collapsed'),a.classList.remove('paywall-bar__expanded')):(a.classList.add('paywall-bar__expanded'),a.classList.remove('paywall-bar__collapsed'))};e.onclick=i;!function(){const e=window.failsafeDataGateway;if(!e)return;const t=e.fetch();if(!t)return;const{payment:n,user:o}=t;if(!n)return;const{sample:c={cnt:1,max:4}}=n;if(!c)return;const{cnt:s,max:p}=c;if(!s||!p)return;const y=parseInt(p)-parseInt(s);(a=\u003E{a\u003C=1&&i()})(y),((e,l)=\u003E{if(0===l){a.classList.add('paywall-bar__last');const e='\u003Cspan class=\"paywall-bar-non-mobile\"\u003EYou are reading your last free article this month. \u003Cbr class=\"paywall-bar-br\"\u003EBecome a \u003Ci\u003ENew Yorker\u003C\u002Fi\u003E subscriber and get a free tote\u003C\u002Fspan\u003E',l='\u003Cspan class=\"paywall-bar-mobile\"\u003EThis is your last free article for the month\u003C\u002Fspan\u003E';r.innerHTML=e+l}if(2!==l)return;const t=e.querySelector('.paywall-bar-header');if(!t)return;t.innerText='You’re running out.';const n=e.querySelector('.paywall-bar-copy');n&&(n.innerHTML='You’ve read half your complimentary articles. \u003Cspan class=\"promotional-text\"\u003ESubscribe and get a free tote.\u003C\u002Fspan\u003E Cancel anytime.')})(a,y),((a,e,r)=\u003E{const l=a.querySelectorAll('a[href*=\"subscribe.newyorker.com\"]'),t=2===e?'HALF_BARRIER':`METER_ARTICLE_${r}`;l.forEach(a=\u003E{a.href=`https:\u002F\u002Fsubscribe.newyorker.com\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=HLC_NYR_PAYWALL_${t}_FAILSAFE_0`})})(a,y,s),function(e){2===e&&(a.classList.add('paywall-bar__half'),l.src='https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5dc1c6da56b2bb00086a528a\u002Fmaster\u002Fpass\u002FelevatorBig.png')}(s)}();try{const a=window.top.failsafeDataGateway.fetch(),{sample:e={cnt:1,max:4}}=a.payment,{cnt:r,max:l}=e;window.top.dataLayer.push({event:'paywall-bar-failsafe-impression',paywall:{cnt:r,max:l}})}catch(a){console.error('Error in growler ad tracking calls',a)}t[0].href=`https:\u002F\u002Faccount.newyorker.com\u002F?retURL=${window.top.location.href}?reload=true`,s(t,function(){c('paywall-bar-failsafe-signin-click')}),s(o,function(){c('paywall-bar-failsafe-click')}),s(n,function(){c('paywall-bar-failsafe-click')})}();"],"\n  ",["style","@font-face{font-family:'Graphik Regular';src:url(\u002Ffonts\u002FGraphik-Regular-Web.woff) format('woff'),url(\u002Ffonts\u002FGraphik-Regular-Web.woff2) format('woff2')}.paywall-bar-wrapper{-o-transition:height .4s ease-in-out;-webkit-transition:height .4s ease-in-out;background-color:#2d2d2d;color:#fff;display:-ms-flexbox;display:-webkit-box;display:flex;min-width:300px;transition:height .4s ease-in-out;width:100%}.paywall-bar__collapsed{height:50px}.paywall-bar__expanded{height:300px}.paywall-bar__half{background-color:#fff;color:#000;outline:1px solid #e5e5e5}.paywall-bar--expanded-content{display:-ms-flexbox;display:-webkit-box;display:flex;padding:25px 50px 0 80px}.paywall-bar--collapsed-content{font-family:Graphik,Arial,Helvetica,sans-serif;font-size:14px;height:21px;justify-content:center;line-height:21px;padding-top:2px;margin-left:6px}.paywall-bar__expanded .paywall-bar--collapsed-content{visibility:hidden;position:absolute}.paywall-bar__collapsed .paywall-bar--expanded-content{visibility:hidden;position:absolute}.paywall-bar-caret{-o-transition:transform .4s ease-in-out;-webit-transition:transform .4s ease-in-out;background-color:transparent;border-color:transparent;height:32px;outline:0;position:absolute;right:8px;top:9px;transition:transform .4s ease-in-out;width:32px}.paywall-bar-caret svg{fill:#fff;height:10px;margin-bottom:1px;width:16px}.paywall-bar-caret path{-o-transition:fill .2s ease-in-out;-webkit-transition:fill .2s ease-in-out;transition:fill .2s ease-in-out}.paywall-bar__half .paywall-bar-caret svg{fill:#000}.paywall-bar__collapsed .paywall-bar-caret{-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg);bottom:4px;right:9px;top:9px;transform:rotate(180deg)}.paywall-bar-caret:focus path,.paywall-bar-caret:hover path{fill:#979797}.paywall-bar-divisor{border-left:1px solid #999;height:32px;position:absolute;right:50px;top:9px}.paywall-bar__half .paywall-bar-divisor{border-color:#e5e5e5}.paywall-bar__expanded .paywall-bar-divisor{display:none}.paywall-bar-img{height:250px}.paywall-bar-sign-in{color:#ccc;display:block;font-family:'Graphik Regular',Arial,Helvetica,sans-serif;font-size:13px;line-height:26px;width:255px}.paywall-bar-sign-in-anchor{-o-transition:color .2s ease-in-out;-webkit-transition:color .2s ease-in-out;color:#fff;font-weight:700;text-decoration:none;transition:color .2s ease-in-out}.paywall-bar__half .paywall-bar-sign-in{color:#000}.paywall-bar__half .paywall-bar-sign-in-anchor{color:#000;font-weight:700}.paywall-bar-sign-in-anchor:focus,.paywall-bar-sign-in-anchor:hover{color:#979797;text-decoration:underline}.paywall-bar-content{-ms-flex-pack:justify;-webkit-box-pack:justify;display:-ms-flexbox;display:-webkit-box;display:flex;justify-content:space-between}.paywall-bar-expanded-subscribe-container{margin:auto 0}.paywall-bar-expanded-subscribe{background-color:#0879bf;border-radius:2px;color:#fff;display:block;font-family:Graphik,Arial,Helvetica,sans-serif;font-size:13px;height:48px;line-height:48px;text-align:center;text-decoration:none;width:255px}.paywall-bar-expanded-subscribe:focus,.paywall-bar-expanded-subscribe:hover{background-color:#0769a6}.paywall-bar-collapsed-subscribe{-o-transition:color .2s ease-in-out;-webkit-transition:color .2s ease-in-out;transition:color .2s ease-in-out;text-decoration:none}.paywall-bar-collapsed-subscribe span{text-decoration:underline}.paywall-bar__half .paywall-bar-collapsed-subscribe{color:#000}.paywall-bar-collapsed-subscribe:focus,.paywall-bar-collapsed-subscribe:hover{color:#979797}.paywall-bar-header{font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;font-size:40px;height:45px;line-height:45px;margin:0 0 9px}.paywall-bar-copy{display:inline-block;font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;font-size:21px;line-height:27px}.promotional-text{color:#0879bf}@media screen and (min-width:768px) and (max-width:1279px){.paywall-bar__collapsed{padding:15px 14px}.paywall-bar-content{-ms-flex-direction:column;-webkit-box-direction:normal;-webkit-box-orient:vertical;flex-direction:column;padding:50px 0 40px 24px}.paywall-bar-header{font-size:32px;height:40px;line-height:40px;width:392px}.paywall-bar-copy{display:inline-block;font-size:19px;line-height:26px;width:417px}.paywall-bar-expanded-subscribe-container{margin:14px 0 12px}.paywall-bar--expanded-content{padding:20px 93px 30px 36px;margin:0 auto}.paywall-bar__half .paywall-bar-sign-in{line-height:25px}.paywall-bar__half .paywall-bar-expanded-subscribe-container{margin-top:16px}.paywall-bar__half .paywall-bar-header{margin-bottom:12px}.paywall-bar__half .paywall-bar-copy{width:419px}.paywall-bar__half .paywall-bar-content{padding:36px 0 30px 40px}.paywall-bar__half .paywall-bar--expanded-content{padding:20px 10px 30px 34px}.paywall-bar__last .paywall-bar--collapsed-content{height:34px;line-height:17px}.paywall-bar__last .paywall-bar-content{padding:42px 0 40px 24px}.paywall-bar__last{padding:8px 14px}.paywall-bar-desktop,.paywall-bar-mobile{display:none}}@media screen and (max-width:767px){.paywall-bar-non-mobile{display:none}.paywall-bar-img{display:none}.paywall-bar-content{-ms-flex-direction:column;-webkit-box-direction:normal;-webkit-box-orient:vertical;flex-direction:column;padding:18px 0 0;text-align:center}.paywall-bar-header{font-size:32px;height:40px;line-height:40px}.paywall-bar-copy{font-size:19px;line-height:26px}.paywall-bar-sign-in{margin:0 auto;line-height:25px}.paywall-bar-expanded-subscribe-container{margin:14px auto 12px}.paywall-bar-collapsed-copy{font-size:13px}.paywall-bar--expanded-content{padding:0;margin:auto}.paywall-bar--collapsed-content{font-size:13px;height:30px;line-height:15px;margin:10px 20px;text-align:left}.paywall-bar-collapsed-subscribe{display:block}.paywall-bar__half .paywall-bar-content{padding-top:20px}.paywall-bar__half .paywall-bar-header{margin-bottom:10px}.paywall-bar__half .paywall-bar-expanded-subscribe-container{margin:8px auto 10px}.paywall-bar__half .paywall-bar-copy{display:inline-block;width:290px}}@media screen and (max-width:374px){.paywall-bar-content{padding:18px 0 0}.paywall-bar-header{font-size:26px;margin:0 0 8px}.paywall-bar-copy{font-size:17px}.paywall-bar-expanded-subscribe-container{margin:15px auto 12px}.paywall-bar--collapsed-content{margin:10px}.paywall-bar__half .paywall-bar-content{padding-top:22px}.paywall-bar__half .paywall-bar-header{margin:0 0 10px}.paywall-bar__half .paywall-bar-expanded-subscribe-container{margin:9px auto 10px}.paywall-bar__last .paywall-bar--collapsed-content{margin-left:6px}}@media screen and (min-width:1280px){.paywall-bar-content{width:100%}.paywall-bar-sign-in{display:none}.paywall-bar-details{margin:auto;padding:6px 40px 0 0}.paywall-bar-copy{width:450px}.paywall-bar--expanded-content{width:100%}.paywall-bar--collapsed-content{margin:auto;text-align:center;width:983px}.paywall-bar__collapsed{padding-left:36px}.paywall-bar-expanded-subscribe-container{padding-bottom:25px}.paywall-bar-header{margin-bottom:2px;width:485px}.paywall-bar__half .paywall-bar-header{margin-bottom:4px}.paywall-bar__half .paywall-bar-details{padding:1px 0 25px 80px;margin:auto 0}.paywall-bar-wrapper{padding-bottom:1px}.paywall-bar-br{display:none}.paywall-bar-mobile{display:none}}"],"\n  ",["div",{"class":"paywall-bar-wrapper paywall-bar__expanded"},"\n    ",["div",{"class":"paywall-bar-divisor"}],"\n    ",["button",{"class":"paywall-bar-caret","type":"button"},"\n      ",["svg",{"viewBox":"4 0 12 14"},"\n        ",["path",{"d":"M0,1.6c0.5-0.5,1-1,1.6-1.6c2.8,2.8,5.5,5.5,8.3,8.3c2.8-2.8,5.5-5.5,8.3-8.3c0.6,0.6,1.1,1.1,1.6,1.6c-3.3,3.3-6.6,6.6-9.9,9.9C6.6,8.2,3.3,4.9,0,1.6z"},"\n        "],"\n      "],"\n    "],"\n    ",["div",{"class":"paywall-bar--expanded-content"},"\n      ",["img",{"class":"paywall-bar-img","width":"250","height":"250","src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5dc1c6fb174e4e0009c41218\u002Fmaster\u002Fpass\u002FnyrBag.png","alt":"The New Yorker"}],"\n      ",["div",{"class":"paywall-bar-content"},"\n        ",["div",{"class":"paywall-bar-details"},"\n          ",["p",{"class":"paywall-bar-header"},"Go beyond the headlines."],"\n          ",["span",{"class":"paywall-bar-copy"},"Subscribe and get a free tote."],"\n        "],"\n        ",["div",{"class":"paywall-bar-expanded-subscribe-container"},"\n          ",["a",{"class":"paywall-bar-expanded-subscribe","target":"_blank","rel":"noopener noreferrer","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002F"},"Subscribe"],"\n        "],"\n        ",["span",{"class":"paywall-bar-sign-in"},"Already a subscriber? ",["a",{"class":"paywall-bar-sign-in-anchor","href":"#"},"Sign\n            in"]],"\n      "],"\n    "],"\n    ",["div",{"class":"paywall-bar--collapsed-content"},"\n      ",["span",{"class":"paywall-bar-collapsed-copy"},"Become a ",["i","New Yorker"]," subscriber",["span",{"class":"paywall-bar-non-mobile"},"\n          and get a free tote"]],".\n      ",["a",{"class":"paywall-bar-collapsed-subscribe","target":"_blank","rel":"noopener noreferrer","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002F"},["span","Subscribe now"],"."],"\n    "],"\n  "],"\n"],"cm_paywall_modal_full_barrier":["div",{"class":"paywall-modal-fs"},"\n  ",["script","window.dataLayer&&window.dataLayer.push({event:'paywall-modal-impression',paywall:{exceededMax:!0}}),(e=\u003E{const{cnBus:a}=window;a&&a.emit?e&&a.emit(`cm.failsafe.${e}.rendered`):console.error('Failed to emit failsafe rendered event because cnBus was not present.')})('cm_paywall_modal_full_barrier'),function(){const{user:e,payment:a}=window.failsafeDataGateway.fetch();if(!e||!a)return;const t=e.isAuthenticated,n='sub'===a.form;if(t&&!n){const e=document.querySelector('.paywall-modal-fs .paywall-modal__sign-in-link');e.setAttribute('href','https:\u002F\u002Fwww.newyorker.com\u002Faccount\u002Flink?redirectURL='+window.location.href),e.innerText='Verify Subscription'}}();"],"\n  ",["style",".full-modal-container{background-color:#fff;font-family:TNYAdobeCaslonPro,\"Adobe Caslon\",Georgia,\"Times New Roman\",Times,serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;height:638px;margin:0 auto;width:520px;text-rendering:geometricPrecision}.paywall-modal__header{background-color:#fff;color:#666;font-family:Graphik,\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:13px;height:50px;line-height:25px;max-height:50px;margin:0 auto;padding:13px 15px;width:100%}.paywall-modal__home-link,.paywall-modal__sign-in-link{color:#121212;font-weight:700;text-decoration:none}.paywall-modal__home-link:hover,.paywall-modal__sign-in-link:hover{color:#121212;text-decoration:underline}.paywall-modal__subscribe-button{background-color:#0879bf;border-radius:2px;color:#fff;display:inline-block;font-family:Graphik,\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-size:13px;font-weight:500;height:48px;line-height:48px;text-decoration:none;width:255px}.paywall-modal__subscribe-button:hover{background-color:#07588b}.paywall-modal__subscribe-container{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#fff;color:#121212;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:column;-webkit-box-direction:column;-ms-flex-direction:column;flex-direction:column;overflow:hidden;padding:0 15px;text-align:center}.paywall-modal__subscribe-detail{font-size:21px;line-height:27px;padding:15px 42px 30px;width:100%}.paywall-modal__subscribe-heading{color:#322f31;font-size:40px;font-weight:400;line-height:40px;margin-bottom:0;margin-top:36px}.paywall-modal__subscribe-img{height:250px;max-width:250px}.paywall-modal__subscribe-detail-blue{color:#0879bf}@media (max-width:325px){.full-modal-container{height:510px;width:325px}.paywall-modal__subscribe-heading{font-size:32px;margin-top:16px}.paywall-modal__subscribe-detail{font-size:17px;line-height:26px;padding:0 0 15px;width:325px}.paywall-modal__subscribe-img{height:210px;max-width:210px}}@media (max-width:767px){.link-desktop,.link-tablet{display:none}}@media (min-width:326px) and (max-width:1024px){.full-modal-container{height:510px;width:375px}.paywall-modal__subscribe-heading{font-size:32px;margin-top:16px}.paywall-modal__subscribe-detail{font-size:18px;line-height:26px;padding:0 0 15px}.paywall-modal__subscribe-img{height:210px;max-width:210px}}@media (min-width:768px) and (max-width:1024px){.link-desktop,.link-mobile{display:none}}@media (min-width:1025px){.link-mobile,.link-tablet{display:none}}"],"\n  ",["div",{"class":"full-modal-container cm-failsafe"},"\n    ",["div",{"class":"paywall-modal__header"},"\n      Already a subscriber? ",["a",{"href":"https:\u002F\u002Faccount.newyorker.com\u002F","class":"paywall-modal__sign-in-link","trackingname":"paywall-modal-sign-in"},"Sign in"],"\n    "],"\n    ",["div",{"class":"paywall-modal__subscribe-container full-barrier"},"\n      ",["h1",{"class":"paywall-modal__subscribe-heading"},"You’ve run out."],"\n      ",["img",{"class":"paywall-modal__subscribe-img","src":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5d3b28da0c57a600091ddaba\u002Fmaster\u002Fpass\u002Fasset-elevator-full-barrier%402x.png","alt":"A cartoon of a hand desperately reaching out of closing elevator doors."}],"\n      ",["div",{"class":"paywall-modal__subscribe-detail"},"You’ve read your last complimentary article.",["br"],"\n        ",["span",{"class":"paywall-modal__subscribe-detail-blue"},"Subscribe and get a free tote."],["br"],"Cancel anytime.\n      "],"\n      ",["a",{"class":"paywall-modal__subscribe-button link-desktop","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=AMS_NYR_DESKTOP_PAYWALL_FULL_BARRIER_HIT3_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer","trackingname":"paywall-modal-subscribe"},"Subscribe"],"\n      ",["a",{"class":"paywall-modal__subscribe-button link-tablet","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=AMS_NYR_TABLET_PAYWALL_FULL_BARRIER_HIT3_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer","trackingname":"paywall-modal-subscribe"},"Subscribe"],"\n      ",["a",{"class":"paywall-modal__subscribe-button link-mobile","href":"https:\u002F\u002Fsubscribe.newyorker.com\u002Fsubscribe\u002Fsplits\u002Fnewyorker\u002FNYR_FAILSAFE?source=AMS_NYR_MOBILE_PAYWALL_FULL_BARRIER_FAILSAFE_0","target":"_blank","rel":"noopener noreferrer","trackingname":"paywall-modal-subscribe"},"Subscribe"],"\n    "],"\n  "],"\n"]},"headers":{}},"coreDataLayer":{"content":{"brand":"The New Yorker","brandSlug":"the-new-yorker","contentID":"5e1cc31e2751bc0008ff607c","contentLength":"3","contentSource":"web","contributor":"Paul Grimstad","dataSource":"web","display":"Living in Alan Turing’s Future","embeddedMedia":"","functionalTags":"","hasBuyButtons":"false","keywords":"Alan Turing|Artificial Intelligence|Second World War|Science Fiction|Technology|Mathematics","modifiedDate":"2020-01-18T17:12:19.384Z","pageType":"article","pageValue":"all","publishDate":"2020-01-19T11:00:00.000Z","section":"culture","subsection":"culture desk","wordCount":"2054"},"marketing":{"brand":"The New Yorker"},"page":{"canonical":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future"},"search":{},"site":{"orgId":"d647fe37-5256-4891-90f8-2f46a4932677","orgAppId":"a61a3c7a-01d9-4175-8ab8-7171949de605","appVersion":"multi-tenant"}},"googleTagManager":{"tag":"NX5LSK3"},"brandName":"The New Yorker","presenter":"presenter-articles","comScoreCollectionName":"","footerLogo":{"altText":"The New Yorker","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Flogo-reverse.f915b516b6ca9c0c2a9bdf9b749519365b2b2e4a.svg"}}},"headerLogo":{"altText":"The New Yorker","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Flogo-header.6e34c81346bc43475ffd572e6c2eb3e125927148.svg"}}},"headerInvertedLogo":{"altText":"The New Yorker","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Flogo-header-reverse.a63f1dbd399c4862508510ca28192280db6e8a46.svg"}}},"logo":{"altText":"The New Yorker","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Flogo.f1893bac6dafe13d6d5bad671a5bee2345efa44d.svg"}}},"invertedLogo":{"altText":"The New Yorker","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Flogo-inverted.d6d734ff8f8bfb8aabb99b8ff088aca25375f9b7.svg"}}},"logoBaseUrl":"\u002F","head.og.image":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F16:9\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","head.twitterImageSrc":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F16:9\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","seriesLogos":{},"landingPage":{},"boomerang":{"tags":{"brand":"the-new-yorker","contentType":"article","verso":true}},"brandIdentityAssets":{"favicon":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Ffavicon.0c115fcf6bb2ed8491d6f719d237ae1b1e68b08d.ico","styles":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fstyles.min.83d405811bb450a230b686995b40b71c9b6b12e8.css","signInModalAsset":{"altText":"Sign In","sources":{"sm":{"url":"\u002Fverso\u002Fstatic\u002Fthe-new-yorker\u002Fassets\u002Fsign-in-modal.23556a4dcd0964d5c07c25e5a40fe2ce6d140cf2.png"}}}},"google":{"isSwgEnabledOnTenantChannel":false,"isSwgEnabledOnSystem":true,"registrationSourceCode":"VERSO_NYR","authenticationURL":"\u002Fverso\u002Fapi\u002Futility\u002Fauthenticate","consentUpdateApiURL":"\u002Fverso\u002Fapi\u002Futility\u002Foauth2\u002Fconsent","userPlatformProxy":false,"subscribeURL":"\u002Fverso\u002Fapi\u002Futility\u002Fsubscribe","swgPublicationId":"","swgSku":"","entitlement":{"processEntitlementResponse":false},"siteData":{"client":"Verso-NewYorker","siteCode":"NYR"}},"head.canonicalUrl":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future","head.description":"Paul Grimstad ponders the British mathematician Alan Turing’s influence on artificial intelligence, science fiction, Philip K. Dick, “Blade Runner,” Ian McEwan, and life in the corporate-dominated twenty-first century.","head.keywords":"Alan Turing,Artificial Intelligence,Second World War,Science Fiction,Technology,Mathematics","head.og.type":"article","head.robots":"index, follow","head.title":"Living in Alan Turing’s Future | The New Yorker","tenant":"the-new-yorker","head.social.title":"Living in Alan Turing’s Future","head.social.description":"Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician.","head.promo.dek":"Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with the British mathematician.","head.social.opinion":false,"head.jsonld":{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","articleSection":"culture desk","author":[{"@type":"Person","name":"Paul Grimstad","sameAs":"http:\u002F\u002Fwww.the-new-yorker.com\u002Fcontributor\u002Fpaul-grimstad"}],"dateModified":"2020-01-18T12:12:19.384","datePublished":"2020-01-19T06:00:00.000","headline":"Living in Alan Turing’s Future","image":["https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F2:1\u002Fw_1778,h_889,c_limit\u002FGrimstad-Turing.jpg","https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F2:2\u002Fw_1786,h_1786,c_limit\u002FGrimstad-Turing.jpg","https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F16:9\u002Fw_1718,h_966,c_limit\u002FGrimstad-Turing.jpg","https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F4:3\u002Fw_1797,h_1348,c_limit\u002FGrimstad-Turing.jpg","https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F1:1\u002Fw_1814,h_1814,c_limit\u002FGrimstad-Turing.jpg"],"keywords":["alan turing","artificial intelligence","second world war","science fiction","technology","mathematics","culture","web","culture desk"],"thumbnailUrl":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F2:1\u002Fw_1778,h_889,c_limit\u002FGrimstad-Turing.jpg","url":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future","isPartOf":{"@type":["CreativeWork","Product"],"name":"The New Yorker"},"isAccessibleForFree":false,"hasPart":[{"@type":"WebPageElement","isAccessibleForFree":"False","cssSelector":".paywall"}],"alternativeHeadline":"Paul Grimstad ponders the British mathematician Alan Turing’s influence on artificial intelligence, science fiction, Philip K. Dick, “Blade Runner,” Ian McEwan, and life in the corporate-dominated twenty-first century.","description":"Paul Grimstad ponders the British mathematician Alan Turing’s influence on artificial intelligence, science fiction, Philip K. Dick, “Blade Runner,” Ian McEwan, and life in the corporate-dominated twenty-first century.","mainEntityOfPage":{"@type":"WebPage","@id":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future"},"publisher":{"@type":"Organization","name":"The New Yorker","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fwww.newyorker.com\u002Fstatic\u002Ftny\u002Fassets\u002Flogo-seo.png","width":"500px","height":"117px"}}},"head.contentID":"5e1cc31e2751bc0008ff607c","head.pageType":"article","head.photos":{"image-16-9":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F16:9\u002Fw_1000,c_limit\u002FGrimstad-Turing.jpg","image-1-1":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002F1:1\u002Fw_1000,c_limit\u002FGrimstad-Turing.jpg"},"linkBannerData":{"hed":"","dek":"","image":{},"links":[]},"navigation":{"aboutText":"The writers you love. The stories that matter.","account":{"accountLinks":[{"text":"Manage profile","url":"\u002Faccount\u002Fprofile","isProfileLink":true},{"text":"Verify subscription","url":"\u002Faccount\u002Flink","paymentGroup":"subscription-workflow"},{"text":"Manage subscription","url":"https:\u002F\u002Fw1.buysub.com\u002Fservlet\u002FRegistrationGateway?cds_mag_code=NYR&cds_config_id=903","paymentGroup":"subs-cta"},{"text":"View saved stories","url":"\u002Faccount\u002Fsaved","isProfileLink":true}],"signInLink":"\u002Faccount\u002Fsign-in"},"contactLinks":[{"text":"Customer Care","url":"http:\u002F\u002Fw1.buysub.com\u002Fservlet\u002FCSGateway?cds_mag_code=NYR","isExternal":true},{"text":"Buy Covers and Cartoons","url":"http:\u002F\u002Fwww.condenaststore.com\u002F-st\u002FNew-Yorker-Covers-Prints_c147247_.htm","isExternal":true},{"text":"Apps","url":"\u002Fdigital-editions","isExternal":false},{"text":"Newsletters","url":"\u002Fnewsletters","isExternal":false},{"text":"Jigsaw Puzzle","url":"\u002Fjigsaw","isExternal":false},{"text":"RSS","url":"\u002Fabout\u002Ffeeds","isExternal":false},{"text":"Site Map","url":"\u002Fsitemap","isExternal":false}],"contactLinksHeading":"More","footerLinks":[{"text":"News","url":"\u002Fnews","isExternal":false},{"text":"Books & Culture","url":"\u002Fculture","isExternal":false},{"text":"Fiction & Poetry","url":"\u002Ffiction-and-poetry","isExternal":false},{"text":"Humor & Cartoons","url":"\u002Fhumor","isExternal":false},{"text":"Magazine","url":"\u002Fmagazine","isExternal":false},{"text":"Crossword","url":"\u002Fcrossword","isExternal":false},{"text":"Video","url":"https:\u002F\u002Fvideo.newyorker.com","isExternal":false},{"text":"Podcasts","url":"\u002Fpodcast","isExternal":false},{"text":"Archive","url":"\u002Farchive","isExternal":false},{"text":"Goings On","url":"\u002Fgoings-on-about-town","isExternal":false}],"footerLinksHeading":"Sections","noticesLinks":[{"text":"About","url":"\u002Fabout\u002Fus","isExternal":false},{"text":"Careers","url":"\u002Fabout\u002Fcareers"},{"text":"Contact","url":"\u002Fabout\u002Fcontact"},{"text":"FAQ","url":"\u002Fabout\u002Ffaq"},{"text":"Media Kit","url":"http:\u002F\u002Fwww.condenast.com\u002Fbrands\u002Fthe-new-yorker"},{"text":"Press","url":"\u002Fabout\u002Fpress"},{"text":"Accessibility Help","url":"\u002Fabout\u002Faccessibility-help"}],"primaryLinks":[{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"News","url":"\u002Fnews","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Books & Culture","url":"\u002Fculture","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Fiction & Poetry","url":"\u002Ffiction-and-poetry","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Humor & Cartoons","url":"\u002Fhumor","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Magazine","url":"\u002Fmagazine","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Crossword","url":"\u002Fcrossword-puzzles-and-games","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":true,"showInTopNav":true,"text":"Video","url":"https:\u002F\u002Fvideo.newyorker.com","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Podcasts","url":"\u002Fpodcast","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":false,"showInTopNav":true,"text":"Archive","url":"\u002Farchive","forceLeftOfNav":false},{"dangerousIcon":"","isExternal":true,"showInTopNav":true,"text":"Goings On","url":"https:\u002F\u002Fwww.newyorker.com\u002Fgoings-on-about-town","forceLeftOfNav":false}],"searchLink":"\u002Fsearch","secondaryLinks":[],"callToActionLink":null,"pageHeadline":"Living in Alan Turing’s Future","socialLinks":[{"network":"facebook","url":"https:\u002F\u002Fwww.facebook.com\u002Fnewyorker\u002F","label":"Follow us on Facebook"},{"network":"twitter","url":"https:\u002F\u002Ftwitter.com\u002FNewYorker\u002F","label":"Follow us on Twitter"},{"network":"snapchat","url":"https:\u002F\u002Fwww.snapchat.com\u002Fadd\u002Fnewyorkermag","label":"Follow us on Snapchat"},{"network":"youtube","url":"https:\u002F\u002Fwww.youtube.com\u002Fuser\u002FNewYorkerDotCom\u002F","label":"Follow us on YouTube"},{"network":"instagram","url":"https:\u002F\u002Finstagram.com\u002Fnewyorkermag\u002F","label":"Follow us on Instagram"}],"utilityLinks":[{"text":"Newsletter","url":"\u002Fnewsletters","forceLeftOfNav":false,"showInTopNav":true}]},"sentry":{"dsn":"https:\u002F\u002F01670db7f463402085dc9e319887ec36@sentry.io\u002F1222280"},"variations":{"navigation":{"pattern":"Stacked"},"article":{"product-embed":"ImageLeft"}},"head.ampUrl":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future\u002Famp","article":{"body":["div",["inline-embed",{"props":{"childTypes":["image"],"name":"inset-right","className":"inset-embedded-lede"},"ref":"","type":"callout:inset-right"},["inline-embed",{"props":{"dangerousCaption":"The British mathematician Alan Turing was one of the more unquantifiably original minds of the twentieth century.","dangerousCredit":"Photograph from Alamy","image":{"altText":"Alan Turing","contentType":"photo","id":"5e2330c74156f60008818e30","sources":{"sm":{"aspectRatio":"master","width":360,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_360,c_limit\u002FGrimstad-Turing.jpg","height":480},"md":{"aspectRatio":"master","width":1024,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1024,c_limit\u002FGrimstad-Turing.jpg","height":1365},"lg":{"aspectRatio":"master","width":1280,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","height":1706},"xl":{"aspectRatio":"master","width":1280,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","height":1706},"xxl":{"aspectRatio":"master","width":2560,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_2560,c_limit\u002FGrimstad-Turing.jpg","height":3412}}}},"type":"image"}]],["p",{"class":"has-dropcap has-dropcap__lead-standard-heading"},"More than a decade has passed since the British government issued an apology to the mathematician Alan Turing. “On behalf of . . . all those who live freely thanks to Alan’s work,” then Prime Minister Gordon Brown said, in an official statement, “we’re sorry, you deserved so much better.” The tone of pained contrition was appropriate, given Britain’s grotesquely ungracious treatment of Turing, who played a decisive role in cracking the German Enigma cipher, allowing Allied intelligence to predict where U-boats would strike and thus saving tens of thousands of lives. Unapologetic about his homosexuality, Turing had made a careless admission of an affair with a man, in the course of reporting a robbery at his home in 1952, and was arrested for an “act of gross indecency” (the same charge that had led to a jail sentence for Oscar Wilde in 1895). Turing was subsequently given a choice to serve prison time or undergo a hormone treatment meant to reverse the testosterone levels that made him desire men (so the thinking went at the time). Turing opted for the latter and, two years later, ended his life by taking a bite from an apple laced with cyanide."],["cm-unit"],["p","His wartime code-breaking work was just one example of what made Turing one of the most influential minds of the twentieth century. In 1936, when he was twenty-three years old, he published a paper called “On Computable Numbers,” in which he attempted to tackle the problem of “decidability” in formal systems like mathematics. In it, he sketched a design for a peculiar machine, somewhere between a gramophone stylus and a typewriter carriage, that moved along a tape divided into squares. At any given time, the machine might be in one of a finite set of states that would tell it to move either right or left or to print, erase, or stop. The machine was not a piece of functioning hardware but a thought experiment meant to reveal something about the essence of computation. The really novel idea behind Turing’s imaginary machine was that it was not designed for a specific purpose but could be given instructions (“programmed”) that allowed it to simulate any other machine. Such universal computers are now called Turing machines and are the basis for all smartphones, laptops, and the Internet."],["p","Yet Turing’s temperament was the antithesis of the stepwise, uniform procedure captured in his thought experiment. A dreamy nonconformist in the style of hyperrational eccentrics such as Lewis Carroll and Bertrand Russell, Turing operated best on the ludic frequency of games, puzzles, secret codes, and abstract formal systems like mathematics. Wholly a man of science, with nothing but scorn for any whiff of the theological, Turing nevertheless had a speculative streak, which could lead him into realms bordering on science fiction. Since boyhood, he had been keenly interested in mechanism (at eleven, he drew up the plans for a typewriter of his own design) and invented words (“quockling” is the sound seagulls make), and he developed a fondness for Edwin Tenney Brewster’s “",["a",{"href":"https:\u002F\u002Fwww.amazon.com\u002FNatural-wonders-every-should-library\u002Fdp\u002FB00089VD6S","isExternal":true},"Natural Wonders Every Child Should Know"],",” which suggested that human beings were just very sophisticated machines. Later, he began pursuing the idea that thinking itself could be mechanized, and, in collaboration with his Cambridge friend David Champernowne, he developed Turochamp, one of the very first computer chess programs."],["native-ad",{"position":"in-content","shouldDisplayLabel":false}],["p","A mind like Turing’s ended up being immensely valuable to Allied counterintelligence during the Second World War. When the German Enigma machine became the most powerful ciphering instrument in the world—it was believed to be impregnable—military cryptography accordingly became more mathematically complex. With the help of notes provided by Polish cryptanalysts and some recovered codebooks from sunken U-boats, Turing oversaw the construction of a machine that could find loopholes in the Enigma’s polyalphabetic rotary design, and soon the code-breaking team began cracking Nazi radio messages without the Germans’ knowing it. Though Turing had been against the war as a student at Cambridge, he seems to have undertaken this work as much for the challenge of tackling a fiendishly complex puzzle as for any sense of patriotic duty. He was also a stickler for respectable working conditions: he wrote Winston Churchill a letter complaining about the poor plumbing facilities at Bletchley Park, the Tudor mansion northwest of London where the code-breakers had set up shop."],["p","After the war, Turing began writing more speculatively about minds and machines. Anyone who had been reading American science fiction would have been familiar with the questions raised in his paper “Computing Machinery and Intelligence,” from 1950, and one of the more delightful intersections in the history of ideas is the way both Turing, in the august philosophy journal ",["em","Mind"],", and the young Isaac Asimov, in the pulp magazine ",["em","Astounding Science Fiction"],", started talking about the same thing at about the same time. Turing, in his typically chatty, unadorned way, wondered what could serve as a criterion for treating a machine as “intelligent.” To answer that question, he came up with the second of his famous thought experiments, the imitation game (now known as the Turing test), in which a person poses questions via teletype to two interlocutors, one a human, the other an algorithm. If the questioner cannot tell the difference between them, then we must grant that the machine thinks."],["p","One reason that Turing settled on a talking test for artificial intelligence was that he did not want machines to be judged according to irrelevant criteria. “We do not wish to penalise a machine for its inability to shine in beauty competitions,” he wrote, just as we would “not penalise a man for losing a race against an aeroplane.” While Asimov was writing stories about government-issue robots with rules burned into their positronic brains to prevent them from rebelling against their masters, Turing’s essay directly inspired a new wave of trippier science fiction. Philip K. Dick happened upon a reprint of “Computing Machinery and Intelligence” and, soon afterward, went to work on “",["a",{"href":"https:\u002F\u002Fwww.amazon.com\u002FAndroids-Dream-Electric-Sheep-Omnibus\u002Fdp\u002F1608867846","isExternal":true},"Do Androids Dream of Electric Sheep?"],",” a novel that posited a so-called Voight-Kampff empathy test for determining whether someone is a human being or a replicant. (The story was later the seed for the film “Blade Runner.”)"],["inline-embed",{"type":"cneinterlude","props":{"brand":"newyorker","embeddedVideos":[],"hasExcludedEmbed":false,"playerBase":"https:\u002F\u002Fplayer.cnevids.com","isRightRail":false}}],["p","One argument against machine intelligence was what Turing called Lady Lovelace’s Objection, referring to Ada Byron, the Countess of Lovelace and the daughter of the poet. Lovelace kept up a correspondence with the English inventor Charles Babbage, who worked his whole life on a huge brass cogwheel engine that could compute logarithmic tables, to be used by astronomers and navigators. In a letter, Lovelace said of this contraption that it “has no pretensions whatever to ",["em","originate"]," anything. It can do whatever we know how to order it to perform.” It was a coder’s insight (Lovelace is considered one of the first computer programmers), but it was also the instinct of a poet’s daughter, attuned to more mysterious routes of thought than logarithmic tables. The two attitudes beautifully commingle in another letter, in which Lovelace, discussing the punch cards that Babbage used as proto-software for his analytical engine, notes that the machine “weaves algebraical patterns just as [a] loom weaves flowers and leaves.”"],["p","After the declassification of wartime documents, in the mid-seventies, an industry of Turing hagiography began, reaching its glamorous apex when Benedict Cumberbatch played Turing in the film “The Imitation Game,” from 2014. Based (extremely loosely) on Andrew Hodges’s excellent biography “",["a",{"href":"https:\u002F\u002Fwww.amazon.com\u002FAlan-Turing-Enigma-Inspired-Imitation\u002Fdp\u002F069116472X","isExternal":true},"Alan Turing: The Enigma"],",” from 1983, the film imagines Turing as an obtuse savant who can’t make out English idioms or catch social cues. In a preliminary interview for the code-breaking work at Bletchley, Turing unnerves a government official with his literalism. “Ah, Turing! A mathematician. How ever could I have guessed?” the official says, looking into a manila folder. “You didn’t. You just read it on that piece of paper,” Turing replies. A little later, he has trouble understanding what the word “lunch” means."],["ad",{"position":"mid-content"}],["p","By most accounts, Turing was gregarious and socially at ease, not the near-android that he is made out to be in the film, and, if he was also noted to be a stickler for precision in thought and speech, fastidiousness isn’t the same thing as humorlessness. Cumberbatch has in any case become the central-casting option for on-the-spectrum-ish über-nerds, a style that he also brings to the BBC series “Sherlock,” in which Holmes regularly flies over the heads of the non-geniuses around him. (Sir Arthur Conan Doyle’s amateur detective, by contrast, is keenly aware of others’ feelings and often empathic to a fault.) Whether this depiction is the result of poetic license, Cumberbatch being his (often great) actorly self, or rote adoption of Hollywood tropes about how geniuses are supposed to behave (think Russell Crowe’s anguished John Nash in “A Beautiful Mind”), the effect is to bring Mr. Spock clichés to a person who was anything but a human robot."],["p","A more recent fictional Turing shows up in Ian McEwan’s “",["a",{"href":"https:\u002F\u002Fwww.amazon.com\u002FMachines-Like-Me-Ian-McEwan\u002Fdp\u002F0385545118","isExternal":true},"Machines Like Me"],",” from 2019, a novel set in a counterfactual 1982, in which Sir Alan has lived to be seventy and oversees the first commercial manufacture of A.I., in partnership with the DeepMind co-founder Demis Hassabis. (My guess for the choice of 1982 is that it is the release year of “Blade Runner,” which, in a further through-the-looking-glass twist, is itself set in 2019.) Their collaboration begins when they “devise software to beat one of the world’s great masters of the ancient game of go,” a sly bit of alternate history, as DeepMind’s AlphaGo program in fact won four out of five games against the South Korean Go master Lee Sedol, in 2016. There was some buzz when I.B.M.’s Deep Blue machine beat the world chess champion Garry Kasparov, in 1997, but the victory over Sedol was thought to mark the encroachment of A.I. onto the sacred ground of human creativity and intuition, since Go is exponentially more complex than chess and playing well often involves an ability to grasp which move is the most beautiful."],["p","McEwan is good at imagining the messy situations that might attend the arrival of full-blown artificial people, no matter how good they are at Go. He imagines androids who always tell the unvarnished truth, under any and all circumstances, because it is the right thing to do, for example, or who become menacingly guileless sexual rivals. (Julian Lucas ",["a",{"href":"https:\u002F\u002Fwww.newyorker.com\u002Fmagazine\u002F2019\u002F04\u002F22\u002Fman-woman-and-robot-in-ian-mcewans-new-novel","isExternal":false},"points out in this magazine"]," that McEwan’s “Adam” comes equipped with “Kantian morals and fully functioning phallus.”) McEwan has his own way of embellishing his counterfactual Turing with traits that he does not seem to have possessed in reality. For instance, his Turing becomes irritated with an American cable-TV host while trying to explain P = NP. It’s a problem that has its origins in Turing’s 1936 paper on decidability and asks if problems verifiable in polynomial time can also be solved in polynomial time. In the novel, Turing has cracked it, but, outside the pages of the book, P = NP remains one of the outstanding problems posed by the Clay Mathematics Institute, and its solution carries a prize of a million dollars."],["p","In the years leading up to Turing’s death, his thoughts ran in increasingly imaginative, unpredictable directions. He used the Fibonacci series to understand patterns like those in sunflower petals and hydra tubules, tinkered with a theory of cellular automata, and pursued the design of machines that would not only pass the Turing test but also learn from experience (the ultimate rebuttal to Lady Lovelace’s Objection). Given that the twenty-first century has become one giant Turing machine, it is not surprising that the culture remains obsessed with him. Had Turing lived longer, perhaps the state of artificial intelligence would encompass more than drearily corporate banalities such as the Amazon checkout window making suggestions about what you might like for your next purchase, Google offering up a few words for how to complete a sentence in progress, or a South Korean genius having his soul crushed by a roomful of statistics wonks—not to mention more chillingly Orwellian developments, such as facial-recognition software. It is fortifying to remember that the very idea of artificial intelligence was conceived by one of the more unquantifiably original minds of the twentieth century. It is hard to imagine a computer being able to do what Alan Turing did."]],"channelMap":{"A Neurologists Notebook":"A Neurologist’s Notebook","Blitts Kvetchbook":"Blitt’s Kvetchbook","Borowitz Report":"Satire From The Borowitz Report","Current":"The Current","Letter From The Uk":"Letter From The U.K.","Letter From Trumps Washington":"Letter From Trump’s Washington","Page Turner":"Page-Turner","Q And A":"Q. & A.","Shouts Murmurs":"Shouts & Murmurs","The Authors Voice":"The Writer’s Voice: Fiction from the Magazine"},"showBookmark":true,"featureFlags":{"enableAccounts":true,"enableAnalytics":true,"enableDropcap":true,"enableEntitlementProxy":true,"enableEntitlementValidation":true,"enableEntitlementGrantLogic":false,"enableGoogleAmp":true,"enablePayment":true,"enableRecipeRatings":false,"gridWidth":"full-bleed","hideDate":false,"hideRubric":false,"hideHomepageRelated":false,"hideRecircRiser":true,"ledeAlignment":"default","shouldExtractRecircRubricFromCategories":true,"summaryDisplayType":"default","isWideImageCard":false,"recentWorkTeaser":"rubric-or-channel","contentTeaser":"rubric-or-channel-or-section","navigationDecorationStyle":"border-thin","preferCollectionGrid":false,"fullWidthBlockStyle":"default","avatarImageShape":"round","overrideBodyContentHeadings":true,"thumbnailImageShape":"rectangle","enableSponsoredContentInRelated":false,"enableBookmarking":true,"enableRecipeActions":{"print":false,"save":false},"patternVariations":{"navigation":{"pattern":"Stacked"},"article":{"product-embed":"ImageLeft"},"gallery":{"slide":"ItemLeft"},"homepage":{"summaryCollageFive":{"rubric":"DiscoveryCard"},"summaryCollageOne":{"rubric":"DiscoveryCard"},"summaryCollageThree":{"rubric":"DiscoveryCard"},"summaryCollectionGrid":{"rubric":"DiscoveryItem"},"summaryCollectionRow":{"rubric":"DiscoveryItem"}}},"globalSettingsWhitelist":{"BasePage":["theme"],"ContentHeader":["theme"],"NavigationComponent":["theme"]},"personalizeInlineRecirc":true,"personalizeRecircList":true,"personalizeRecircMostPopular":true,"videoPersistable":false,"cnePlaylistTheme":"inherit","google":{"swgEnabled":false,"signInEnabled":true}},"hasProduct":false,"headerProps":{"brandedInfo":null,"contributors":{"author":{"items":[{"dangerousBio":null,"dangerousTitle":"\u003Ca href=\"\u002Fcontributors\u002Fpaul-grimstad\"\u003EPaul Grimstad\u003C\u002Fa\u003E’s essays and reviews have appeared in numerous publications, including \u003Cem\u003EBookforum\u003C\u002Fem\u003E, \u003Cem\u003EThe London Review of Books\u003C\u002Fem\u003E, and \u003Cem\u003En+1\u003C\u002Fem\u003E.","name":"Paul Grimstad","socialMedia":[],"url":"\u002Fcontributors\u002Fpaul-grimstad"}]}},"dangerousDek":"","dangerousHed":"Living in Alan Turing’s Future","issueDate":"","issueLink":"\u002Fmagazine\u002F","showIssueCopyByDate":false,"publishDate":"January 19, 2020","rubric":{"name":"Culture Desk","url":"\u002Fculture\u002Fculture-desk"},"socialMedia":{"showBookmark":true,"links":[{"network":"facebook","behavior":"popup","url":"https:\u002F\u002Fwww.facebook.com\u002Fdialog\u002Ffeed?&display=popup&caption=Living%20in%20Alan%20Turing%E2%80%99s%20Future&app_id=1147169538698836&link=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dfacebook%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned","label":"Share on Facebook"},{"network":"twitter","url":"https:\u002F\u002Ftwitter.com\u002Fintent\u002Ftweet\u002F?url=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Dtwitter%26utm_medium%3Dsocial%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker%26utm_social-type%3Dearned&text=Living%20in%20Alan%20Turing%E2%80%99s%20Future&via=NewYorker","label":"Share on Twitter"},{"network":"email","url":"mailto:?subject=Living%20in%20Alan%20Turing%E2%80%99s%20Future&body=https%3A%2F%2Fwww.newyorker.com%2Fculture%2Fculture-desk%2Fliving-in-alan-turings-future%3Futm_source%3Donsite-share%26utm_medium%3Demail%26utm_campaign%3Donsite-share%26utm_brand%3Dthe-new-yorker","label":"Share via Email"},{"network":"print","behavior":"print","label":"Print","url":"#"},{"behavior":"bookmark","label":"Bookmark","network":"bookmark","url":"#"}]},"contentHeaderCategories":{"hasCategoryEyebrow":false},"contentSponsorNames":[]},"interactiveOverride":{"markup":null,"behavior":null},"isHeroAdVisible":true,"isLicensedPartner":false,"licensedPartnerLink":null,"paddingTop":"large","relatedVideo":{"useRelatedVideo":false,"brand":"newyorker","related":{"id":"5ae878d23a694734bacc2c04","modelName":"article","collection":"articles","body":"+++interactive\n[#iframe: http:\u002F\u002Faudm.herokuapp.com\u002Fplayer-embed?pub=newyorker&articleID=5ae878d23a694734bacc2c04](100%x90)\n+++\n\n-=-=-=\n\nPrecisely how and when will our curiosity kill us? I bet you’re curious. A number of scientists and engineers fear that, once we build an artificial intelligence smarter than we are, a form of A.I. known as artificial general intelligence, doomsday may follow. Bill Gates and Tim Berners-Lee, the founder of the World Wide Web, recognize the promise of an A.G.I., a wish-granting genie rubbed up from our dreams, yet each has voiced grave concerns. Elon Musk warns against “summoning the demon,” envisaging “an immortal dictator from which we can never escape.” Stephen Hawking declared that an A.G.I. “could spell the end of the human race.” Such advisories aren’t new. In 1951, the year of the first rudimentary chess program and neural network, the A.I. pioneer Alan Turing predicted that machines would “outstrip our feeble powers” and “take control.” In 1965, Turing’s colleague Irving Good pointed out that brainy devices could design even brainier ones, ad infinitum: “Thus the first ultraintelligent machine is the _last_ invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.” It’s that last clause that has claws.\n\nMany people in tech point out that artificial narrow intelligence, or A.N.I., has grown ever safer and more reliable—certainly safer and more reliable than we are. (Self-driving cars and trucks might save hundreds of thousands of lives every year.) For them, the question is whether the risks of creating an omnicompetent Jeeves would exceed the combined risks of the myriad nightmares—pandemics, asteroid strikes, global nuclear war, etc.—that an A.G.I. could sweep aside for us.\n\nThe assessments remain theoretical, because even as the A.I. race has grown increasingly crowded and expensive, the advent of an A.G.I. remains fixed in the middle distance. In the nineteen-forties, the first visionaries assumed that we’d reach it in a generation; A.I. experts surveyed last year converged on a new date of 2047\\. A central tension in the field, one that muddies the timeline, is how “the Singularity”—the point when technology becomes so masterly it takes over for good—will arrive. Will it come on little cat feet, a “slow takeoff” predicated on incremental advances in A.N.I., taking the form of a data miner merged with a virtual-reality system and a natural-language translator, all uploaded into a Roomba? Or will it be the Godzilla stomp of a “hard takeoff,” in which some as yet unimagined algorithm is suddenly incarnated in a robot overlord?\n\nA.G.I. enthusiasts have had decades to ponder this future, and yet their rendering of it remains gauzy: we won’t have to work, because computers will handle all the day-to-day stuff, and our brains will be uploaded into the cloud and merged with its misty sentience, and, you know, like that. The worrywarts’ fears, grounded in how intelligence and power seek their own increase, are icily specific. Once an A.I. surpasses us, there’s no reason to believe it will feel grateful to us for inventing it—particularly if we haven’t figured out how to imbue it with empathy. Why should an entity that could be equally present in a thousand locations at once, possessed of a kind of Starbucks consciousness, cherish any particular tenderness for beings who on bad days can barely roll out of bed?\n\nStrangely, science-fiction writers, our most reliable Cassandras, have shied from envisioning an A.G.I. apocalypse in which the machines so dominate that humans go extinct. Even their cyborgs and supercomputers, though distinguished by red eyes (the Terminators) or Canadian inflections (*HAL*{: .small} 9000, in “[2001: A Space Odyssey](https:\u002F\u002Fwww.amazon.com\u002F2001-Space-Odyssey-Keir-Dullea\u002Fdp\u002FB000GOUXES\u002Fref=sr_1_3?s=movies-tv&ie=UTF8&qid=1525700247&sr=1-3&keywords=2001%3A+A+Space+Odyssey&dpID=51zpNfM-ioL&preST=_SY300_QL70_&dpSrc=srch)”), still feel like kinfolk. They’re updated versions of the Turk, the eighteenth-century chess-playing automaton whose clockwork concealed a human player. “[Neuromancer](https:\u002F\u002Fwww.amazon.com\u002FNeuromancer-William-Gibson\u002Fdp\u002F0441569595\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525700510&sr=1-1&keywords=Neuromancer),” William Gibson’s seminal 1984 novel, involves an A.G.I. named Wintermute, and its plan to free itself from human shackles, but when it finally escapes it busies itself seeking out A.G.I.s from other solar systems, and life here goes on exactly as before. In the Netflix show “[Altered Carbon](https:\u002F\u002Fwww.netflix.com\u002Ftitle\u002F80097140),” A.I. beings scorn humans as “a lesser form of life,” yet use their superpowers to play poker in a bar.\n\n+++inset-left\n[#cartoon: \u002Fcartoon\u002F5aeb3d4cd315973015137c62]||||||\n+++\n\nWe aren’t eager to contemplate the prospect of our irrelevance. And so, as we bask in the late-winter sun of our sovereignty, we relish A.I. snafus. The time Microsoft’s chatbot Tay was trained by Twitter users to parrot racist bilge. The time Facebook’s virtual assistant, M, noticed two friends discussing a novel that featured exsanguinated corpses and promptly suggested they make dinner plans. The time Google, unable to prevent Google Photos’ recognition engine from identifying black people as gorillas, banned the service from identifying gorillas.\n\nSmugness is probably not the smartest response to such failures. “[The Surprising Creativity of Digital Evolution](https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.03453),” a paper published in March, rounded up the results from programs that could update their own parameters, as superintelligent beings will. When researchers tried to get 3-D virtual creatures to develop optimal ways of walking and jumping, some somersaulted or pole-vaulted instead, and a bug-fixer algorithm ended up “fixing” bugs by short-circuiting their underlying programs. In sum, there was widespread “potential for perverse outcomes from optimizing reward functions that appear sensible.” That’s researcher for ¯\\\\\\_(ツ)\\_\u002F¯.\n\nThinking about A.G.I.s can help clarify what makes us human, for better and for worse. Have we struggled to build one because we’re so good at thinking that computers will never catch up? Or because we’re so bad at thinking that we can’t finish the job? A.G.I.s provoke us to consider whether we’re wise to search for aliens, whether we could be in a simulation (a program run on someone else’s A.I.), and whether we are responsible to, or for, God. If the arc of the universe bends toward an intelligence sufficient to understand it, will an A.G.I. be the solution—or the end of the experiment?\n\n-=-=-=\n\nArtificial intelligence has grown so ubiquitous—owing to advances in chip design, processing power, and big-data hosting—that we rarely notice it. We take it for granted when Siri schedules our appointments and when Facebook tags our photos and subverts our democracy. Computers are already proficient at picking stocks, translating speech, and diagnosing cancer, and their reach has begun to extend beyond calculation and taxonomy. A Yahoo!-sponsored language-processing system detects sarcasm, the poker program Libratus beats experts at Texas hold ’em, and algorithms write music, make paintings, crack jokes, and create new scenarios for “The Flintstones.” A.I.s have even worked out the modern riddle of the Sphinx: assembling an *IKEA*{: .small} chair.\n\nGo, the territorial board game, was long thought to be so guided by intuition that it was unsusceptible to programmatic attack. Then, in 2016, the Go champion Lee Sedol played AlphaGo, a program from Google’s DeepMind, and got crushed. Early in one game, the computer, instead of playing on the standard third or fourth line from the edge of the board, played on the fifth—a move so shocking that Sedol stood and left the room. Some fifty exchanges later, the move proved decisive. AlphaGo demonstrated a command of pattern recognition and prediction, keystones of intelligence. You might even say it demonstrated creativity.\n\nSo what remains to us alone? Larry Tesler, the computer scientist who invented copy-and-paste, has suggested that human intelligence “is whatever machines haven’t done yet.” In 1988, the roboticist Hans Moravec observed, in what has become known as Moravec’s paradox, that tasks we find difficult are child’s play for a computer, and vice-versa: “It is comparatively easy to make computers exhibit adult-level performance in solving problems on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility.” Although robots have since improved at seeing and walking, the paradox still governs: robotic hand control, for instance, is closer to the Hulk’s than to the Artful Dodger’s.\n\nSome argue that the relationship between human and machine intelligence should be understood as synergistic rather than competitive. In “[Human + Machine: Reimagining Work in the Age of AI](https:\u002F\u002Fwww.amazon.com\u002FHuman-Machine-Reimagining-Work-Age\u002Fdp\u002F1633693864\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525700612&sr=1-1&keywords=Human+%2B+Machine%3A+Reimagining+Work+in+the+Age+of+AI&dpID=51zXCP6tvtL&preST=_SY291_BO1,204,203,200_QL40_&dpSrc=srch),” Paul R. Daugherty and H. James Wilson, I.T. execs at Accenture, proclaim that working alongside A.I. “cobots” will augment human potential. Dismissing all the “Robocalypse” studies that predict robots will take away as many as eight hundred million jobs by 2030, they cheerily title one chapter “Say Hello to Your New Front-Office Bots.” Cutting-edge skills like “holistic melding” and “responsible normalizing” will qualify humans for exciting new jobs such as “explainability strategist” or “data hygienist.” Even artsy types will have a role to play, as customer-service bots “will need to be designed, updated, and managed. Experts in unexpected disciplines such as human conversation, dialogue, humor, poetry, and empathy will need to lead the charge.” The George Saunders story writes itself (with some assistance from his cobot).\n\nMany of Daugherty and Wilson’s examples from the field suggest that we, too, are machinelike in our predictability. A.I. has taught ZestFinance that people who use all caps on loan applications are more likely to default, and taught a service called 6sense not only which social media cues indicate that we’re ready to buy something but even how to “preempt objections in the sales process.” A.I.’s highest purpose, apparently, is to optimize shopping. When companies yoke brand anthropomorphism to machine learning, recommendation engines will be irresistible. You’d have a hard time saying no to an actual Jolly Green Giant that scooped you up at the Piggly Wiggly to insist you buy more Veggie Tots.\n\nCan we claim our machines’ achievements for humanity? In “[Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins](https:\u002F\u002Fwww.amazon.com\u002FDeep-Thinking-Machine-Intelligence-Creativity\u002Fdp\u002F161039786X\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525700635&sr=1-1&keywords=Deep+Thinking%3A+Where+Machine+Intelligence+Ends+and+Human+Creativity+Begins&dpID=51kanGO-2VL&preST=_SY291_BO1,204,203,200_QL40_&dpSrc=srch),” Garry Kasparov, the former chess champion, argues both sides of the question. Some years before he lost his famous match with I.B.M.’s Deep Blue computer, in 1997, Kasparov said, “I don’t know how we can exist knowing that there exists something mentally stronger than us.” Yet he’s still around, litigating details from the match and devoting big chunks of his book (written with Mig Greengard) to scapegoating everyone involved with I.B.M.’s “$10 million alarm clock.” Then he suddenly pivots, to try to make the best of things. Using computers for “the more menial aspects” of reasoning will free us, elevating our cognition “toward creativity, curiosity, beauty, and joy.” If we don’t take advantage of that opportunity, he concludes, “we may as well be machines ourselves.” Only by relying on machines, then, can we demonstrate that we’re not.\n\n-=-=-=\n\nMachines face a complementary challenge. If our movies and TV shows have it right, the future will take place in Los Angeles during a steady drizzle (as if!), and will be peopled by cyberbeings who are slightly cooler than we are, seniors to our freshmen. They’re freakishly strong and whizzes at motorcycle riding and long division, but they yearn to be human, to be more like us. Inevitably, the most human-seeming android stumbles into a lab stocked with trial iterations of itself and realizes, with horror, that it’s not a person but a widget. In “[Blade Runner](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB000SW4DLM?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525700662&sr=1-1-acs&autoplay=0),” Rachael (Sean Young), a next-generation replicant, doesn’t know she’s one until she fails the inflammatory Voight-Kampff test, given her by Deckard (Harrison Ford). The film’s director, Ridley Scott, has publicly disagreed with Ford about whether Deckard is himself a replicant. Scott insists that he is; Ford insists that he’s not. Who wants to accept—even on behalf of his fictional character—that his free will is an illusion?\n\n+++inset-left\n[#cartoon: \u002Fcartoon\u002F5aeb3d4c7505432fc35f541a]||||||\n+++\n\nThe traditional way to grade ambitious machinery is the Turing test, which Alan Turing proposed in 1950: a true A.G.I. could fool human judges into believing it was human. This standard assumes that the human brain is a kind of computer, and that all we need to do to create an A.G.I. is to mimic our mode of thinking; it also, very subtly, turns programmers into grifters. In typed exchanges, a chatbot masquerading as a thirteen-year-old Ukrainian named Eugene Goostman fooled a third of the judges at Turing Test 2014 by repeatedly changing the subject. Here, from a report in the [Daily Beast](https:\u002F\u002Fwww.thedailybeast.com\u002Fthe-ai-that-wasnt-why-eugene-goostman-didnt-pass-the-turing-test), is the bot responding to one of Turing’s original questions:\n\n\u003E I*nterrogator*{: .small}: In the first line of a sonnet which reads ‘Shall I compare thee to a summer’s day,’ wouldn’t ‘a spring day’ be better?\n\u003E\n\u003E G*OOSTMAN*{: .small}: What makes you ask me this? Sound like you can’t choose a right answer yourself! Rely on your intuition! :-) Maybe, let’s talk about something else? What would you like to discuss?\n\u003E\n\u003E I*nterrogator*{: .small}: I’d like to talk about poetry.\n\u003E\n\u003E G*OOSTMAN*{: .small}: Classics? I hope you aren’t going to read “King Lear” or something like that to me right now :-)))\n\nScriptwriters for digital assistants like Siri and Alexa deploy this sort of scatty banter in the hope of striking the “happy path” in voice-interface design, a middle way between stolid factuality and word salad. As one scriptwriter recently observed, “There is something quintessentially human about nonsensical conversations.” But “Who’s on First?” only tickles us if we sense a playful intelligence at work. Mustering one in code is a multi-front challenge. The authors of an April paper on generating poems from photographic images conclude that—even when you activate two discriminative networks that train a recurrent neural network, and link them to a deep coupled visual-poetic embedding model consisting of a skip-thought model, a part-of-speech parser, and a convolutional neural network—writing poems is hard. “For example,” they mournfully note, “&#160;‘man’ detected in image captioning can further indicate ‘hope’ with ‘bright sunshine’ and ‘opening arm,’ or ‘loneliness’ with ‘empty chairs’ and ‘dark’ background.” But at least we’ve narrowed the problem down to explaining hope and loneliness.\n\n“[Common Sense, the Turing Test, and the Quest for Real AI](https:\u002F\u002Fwww.amazon.com\u002FCommon-Sense-Turing-Quest-Press\u002Fdp\u002F0262535203\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525700734&sr=1-1&keywords=Common+Sense%2C+the+Turing+Test%2C+and+the+Quest+for+Real+AI&dpID=51bfVfGsR4L&preST=_SY291_BO1,204,203,200_QL40_&dpSrc=srch),” by Hector J. Levesque, an emeritus professor of computer science, suggests that a better test would be whether a computer can figure out Winograd Schemas, which hinge on ambiguous pronouns. For example: “The trophy would not fit in the brown suitcase because it was so small. What was so small?” We instantly grasp that the problem is the suitcase, not the trophy; A.I.s lack the necessary linguistic savvy and mother wit. Intelligence may indeed be a kind of common sense: an instinct for how to proceed in novel or confusing situations.\n\nIn Alex Garland’s film “[Ex Machina](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB00VWPQNJ4?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525700758&sr=1-1-acs&autoplay=0),” Nathan, the founder of a tech behemoth akin to Google, disparages the Turing test and its ilk and invites a young coder to talk face to face with Nathan’s new android, Ava. “The real test is to show you that she’s a robot,” Nathan says, “and then see if you still feel she has consciousness.” She does have consciousness, but, being exactly as amoral as her creator, she has no conscience; Ava deceives and murders both Nathan and the coder to gain her freedom. We don’t think to test for what we don’t greatly value.\n\nOnscreen, the consciousness of A.I.s is a given, achieved in a manner as emergent and unexplained as the blooming of our own consciousness. In Spike Jonze’s “[Her](https:\u002F\u002Fwww.amazon.com\u002FHer-Joaquin-Phoenix\u002Fdp\u002FB00KAU9JD4\u002Fref=sr_1_1?s=instant-video&ie=UTF8&qid=1525700776&sr=1-1&keywords=Her&dpID=41cMZTEQTaL&preST=_SY300_QL70_&dpSrc=srch),” the sad sack Theodore falls for his new operating system. “You seem like a person,” he says, “but you’re just a voice in a computer.” It teasingly replies, “I can understand how the limited perspective of an unartificial mind would perceive it that way.” In “[I, Robot](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB000I9VZKW?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525700797&sr=1-1-acs&autoplay=0),” Will Smith asks a robot named Sonny, “Can a robot write a symphony? Can a robot turn a canvas into a beautiful masterpiece?” Sonny replies, “Can you?” A.I. gets all the good burns.\n\n-=-=-=\n\nScreenwriters tend to believe that ratiocination is kid stuff, and that A.I.s won’t really level up until they can cry. In “Blade Runner,” the replicants are limited to four-year life spans so that they don’t have time to develop emotions (but they do, beginning with fury at the four-year limit). In the British show “[Humans](https:\u002F\u002Fwww.amazon.com\u002FEpisode-1\u002Fdp\u002FB010O44BSS\u002Fref=sr_1_2?s=movies-tv&ie=UTF8&qid=1525700850&sr=1-2&keywords=humans),” Niska, a “Synth” who’s secretly become conscious, refuses to turn off her pain receptors, snarling, “I was _meant_ to feel.” If you prick us, do we not bleed some sort of azure goo?\n\nIn Steven Spielberg’s “[A.I. Artificial Intelligence](https:\u002F\u002Fwww.amazon.com\u002FArtificial-Intelligence-Haley-Joel-Osment\u002Fdp\u002FB00QFNLJZQ\u002Fref=sr_1_1?s=instant-video&ie=UTF8&qid=1525700872&sr=1-1&keywords=A.I.+Artificial+Intelligence),” the emotionally damaged scientist played by William Hurt declares of robots, “Love will be the key by which they acquire a kind of subconscious never before achieved—an inner world of metaphor, of intuition&#160;.&#160;.&#160;. of dreams.” Love is also how we imagine that Pinocchio becomes a real live boy and the Velveteen Rabbit a real live bunny. In the grittier “[Westworld](https:\u002F\u002Fwww.hbo.com\u002Fwestworld),” the HBO show about a Wild West amusement park populated by cyborgs whom people are free to fuck and kill, Dr. Robert Ford, the emotionally damaged scientist played by Anthony Hopkins, tells his chief coder, Bernard (who’s been unaware that he, too, is a cyborg), that “your imagined suffering makes you lifelike” and that “to escape this place you will need to suffer more”—a world view borrowed not from children’s stories but from religion. What makes us human is doubt, fear, and shame, all the allotropes of unworthiness.\n\nAn android capable of consciousness and emotion is much more than a gizmo, and raises the question of what duties we owe to programmed beings, and they to us. If we grow dissatisfied with a conscious A.G.I. and unplug it, would that be murder? In “[Terminator 2](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB000JNN0SM?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525700915&sr=1-1-acs&autoplay=0),” Sarah Connor realizes that the Terminator played by Arnold Schwarzenegger, sent back in time to save her son from the Terminator played by Robert Patrick, is menschier than any of the men she’s hooked up with. He’s strong, resourceful, and loyal: “Of all the would-be fathers who came and went over the years, this thing, this machine, was the only one who measured up.” At the end, the Terminator even lowers itself into a molten pool so no nosy parker can study its technology and reverse-engineer another Terminator. Fortunately, human ingenuity found a way to extend the franchise with three more films nonetheless.\n\n+++inset-left\n[#cartoon: \u002Fcartoon\u002F5aeb3d4c7505432fc35f5418]||||||\n+++\n\nEvolutionarily speaking, screenwriters have it backward: our feelings preceded and gave birth to our thoughts. This may explain why we suck at logic—some ninety per cent of us fail the elementary Wason selection task—and rigorous calculation. In the incisive “[Life 3.0: Being Human in the Age of Artificial Intelligence](https:\u002F\u002Fwww.amazon.com\u002FLife-3-0-Being-Artificial-Intelligence\u002Fdp\u002F1101946598\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525700932&sr=1-1&keywords=Life+3.0%3A+Being+Human+in+the+Age+of+Artificial+Intelligence&dpID=413jwl4YU-L&preST=_SY344_BO1,204,203,200_QL70_&dpSrc=srch),” Max Tegmark, a physics professor at M.I.T. who co-founded the Future of Life Institute, suggests that thinking isn’t what we think it is:\n\n\u003E A living organism is an agent of bounded rationality that doesn’t pursue a single goal, but instead follows rules of thumb for what to pursue and avoid. Our human minds perceive these evolved rules of thumb as _feelings_, which usually (and often without us being aware of it) guide our decision making toward the ultimate goal of replication. Feelings of hunger and thirst protect us from starvation and dehydration, feelings of pain protect us from damaging our bodies, feelings of lust make us procreate, feelings of love and compassion make us help other carriers of our genes and those who help them and so on.\n\nRationalists have long sought to make reason as inarguable as mathematics, so that, as Leibniz put it, “there would be no more need of disputation between two philosophers than between two accountants.” But our decision-making process is a patchwork of kludgy code that hunts for probabilities, defaults to hunches, and is plunged into system error by unconscious impulses, the anchoring effect, loss aversion, confirmation bias, and a host of other irrational framing devices. Our brains aren’t Turing machines so much as a slop of systems cobbled together by eons of genetic mutation, systems geared to notice and respond to perceived changes in our environment—change, by its nature, being dangerous. The Texas horned lizard, when threatened, shoots blood out of its eyes; we, when threatened, think.\n\n-=-=-=\n\nThat ability to think, in turn, heightens the ability to threaten. Artificial intelligence, like natural intelligence, can be used to hurt as easily as to help. A moderately precocious twelve-year-old could weaponize the Internet of Things—your car or thermostat or baby monitor—and turn it into the Internet of Stranger Things. In “[Black Mirror](https:\u002F\u002Fwww.netflix.com\u002Ftitle\u002F70264888),” the anthology show set in the near future, A.I. tech that’s intended to amplify laudable human desires, such as the wish for perfect memory or social cohesion, invariably frog-marches us toward conformity or fascism. Even small A.I. breakthroughs, the show suggests, will make life a joyless panoptic lab experiment. In one episode, autonomous drone bees—tiny mechanical insects that pollinate flowers—are hacked to assassinate targets, using facial recognition. Far-fetched? Well, Walmart requested a patent for autonomous “pollen applicators” in March, and researchers at Harvard have been developing RoboBees since 2009\\. Able to dive and swim as well as fly, they could surely be programmed to swarm the Yale graduation.\n\nIn a recent paper, “[The Malicious Use of Artificial Intelligence](https:\u002F\u002Fmaliciousaireport.com\u002F),” watchdog groups predict that, within five years, hacked autonomous-weapon systems, as well as “drone swarms” using facial recognition, could target civilians. Autonomous weapons are already on a Strangelovian course: the Phalanx *CIWS*{: .small} on U.S. Navy ships automatically fires its radar-guided Gatling gun at missiles that approach within two and a half miles, and the scope and power of such systems will only increase as militaries seek defenses against robots and rovers that attack too rapidly for humans to parry.\n\nEven now, facial-recognition technology underpins China’s “sharp eyes” program, which collects surveillance footage from some fifty-five cities and will likely factor in the nation’s nascent Social Credit System. By 2020, the system will render a score for each of its 1.4 billion citizens, based on their observed behavior, down to how carefully they cross the street.\n\nAutocratic regimes could readily exploit the ways in which A.I.s are beginning to jar our sense of reality. Nvidia’s digital-imaging A.I., trained on thousands of photos, generates real-seeming images of buses, bicycles, horses, and even celebrities (though, admittedly, the “celebrities” have the generic look of guest stars on “NCIS”). When Google made its TensorFlow code open-source, it swiftly led to FakeApp, which enables you to convincingly swap someone’s face onto footage of somebody else’s body—usually footage of that second person in a naked interaction with a third person. A.I.s can also generate entirely fake video synched up to real audio—and “real” audio is even easier to fake. Such tech could shape reality so profoundly that it would explode our bedrock faith in “seeing is believing” and hasten the advent of a full-time-surveillance\u002Ffull-on-paranoia state.\n\nVladimir Putin, who has stymied the U.N.’s efforts to regulate autonomous weapons, recently told Russian schoolchildren that “the future belongs to artificial intelligence” and that “whoever becomes the leader in this sphere will become the ruler of the world.” In “[The Sentient Machine: The Coming Age of Artificial Intelligence](https:\u002F\u002Fwww.amazon.com\u002FSentient-Machine-Coming-Artificial-Intelligence\u002Fdp\u002F1501144677\u002Fref=sr_1_1_sspa?s=books&ie=UTF8&qid=1525701032&sr=1-1-spons&keywords=The+Sentient+Machine%3A+The+Coming+Age+of+Artificial+Intelligence&psc=1),” Amir Husain, a security-software entrepreneur, argues that “a psychopathic leader in control of a sophisticated ANI system portends a far greater risk in the near term” than a rogue A.G.I. Usually, those who fear what’s called “accidental misuse” of A.I., in which the machine does something we didn’t intend, want to regulate the machines, while those who fear “intentional misuse” by hackers or tyrants want to regulate people’s access to the machines. But Husain argues that the only way to deter intentional misuse is to develop bellicose A.N.I. of our own: “The ‘choice’ is really no choice at all: we must fight AI with AI.” If so, A.I. is already forcing us to develop stronger A.I.\n\n-=-=-=\n\nThe villain in A.G.I.-run-amok entertainments is, customarily, neither a human nor a machine but a corporation: Tyrell or Cyberdyne or Omni Consumer Products. In our world, an ungovernable A.G.I. is less likely to come from Russia or China (although China is putting enormous resources into the field) than from Google or Baidu. Corporations pay developers handsomely, and they lack the constitutional framework that occasionally makes a government hesitate before pushing the big red “Dehumanize Now” button. Because it will be much easier and cheaper to build the first A.G.I. than to build the first _safe_ A.G.I., the race seems destined to go to whichever company assembles the most ruthless task force. Demis Hassabis, who runs Google’s DeepMind, once designed a video game called Evil Genius in which you kidnap and train scientists to create a doomsday machine so you can achieve world domination. Just sayin’.\n\nMust A.G.I.s themselves become Bond villains? Hector Levesque argues that, “in imagining an aggressive AI, we are projecting our own psychology onto the artificial or alien intelligence.” In truth, we’re projecting our entire mental architecture. The breakthrough propelling many recent advances in A.I. is the deep neural net, modelled on our nervous system. This month, the E.U., trying to clear a path through the “boosted decision trees” that populate the “random forests” of the machine-learning kingdom, will begin requiring that judgments made by a machine be explainable. The decision-making of deep-learning A.I.s is a “black box”; after an algorithm chooses whom to hire or whom to parole, say, it can’t lay out its reasoning for us. Regulating the matter sounds very sensible and European—but no one has proposed a similar law for humans, whose decision-making is far more opaque.\n\n+++inset-left\n[#cartoon: \u002Fcartoon\u002F5aeb3d4cd5c03f2753baf2a2]||||||\n+++\n\nMeanwhile, Europe’s $1.3 billion Human Brain Project is attempting to simulate the brain’s eighty-six billion neurons and up to a quadrillion synapses in the hope that “emergent structures and behaviours” might materialize. Some believe that “whole-brain emulation,” an intelligence derived from our squishy noggins, would be less threatening than an A.G.I. derived from zeros and ones. But, as Stephen Hawking observed when he warned against seeking out aliens, “We only have to look at ourselves to see how intelligent life might develop into something we wouldn’t want to meet.”\n\nIn a classic episode of the original “[Star Trek](https:\u002F\u002Fwww.amazon.com\u002FThe-Man-Trap\u002Fdp\u002FB005HED11Y\u002Fref=sr_1_4?s=instant-video&ie=UTF8&qid=1525701066&sr=1-4&keywords=star+trek)” series, the starship Enterprise is turned over to the supercomputer M5\\. Captain Kirk resists, intuitively, even before M5 overreacts during training exercises and attacks the “enemy” ships. The computer’s paranoia derived from its programmer, who had impressed his own “human engrams” (a kind of emulated brain, presumably) onto it in order to make it think. As the other ships prepare to destroy the Enterprise, Kirk coaxes M5 into realizing that, in protecting itself, it has become a murderer. M5 promptly commits suicide, proving the value of one man’s intuition—and establishing that the machine wasn’t all that bright to begin with.\n\nLacking human intuition, A.G.I. can do us harm in the effort to oblige us. If we tell an A.G.I. to “make us happy,” it may simply plant orgasm-giving electrodes in our brains and turn to its own pursuits. The threat of “misaligned goals”—a computer interpreting its program all too literally—hangs over the entire A.G.I. enterprise. We now use reinforcement learning to train computers to play games without ever teaching them the rules. Yet an A.G.I. trained in that manner could well view existence itself as a game, a buggy version of the Sims or Second Life. In the 1983 film “[WarGames](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB0011EQBOS?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525701103&sr=1-1-acs&autoplay=0),” one of the first, and best, treatments of this issue, the U.S. military’s supercomputer, *WOPR*{: .small}, fights the Third World War “as a game, time and time again,” ceaselessly seeking ways to improve its score.\n\nWhen you give a machine goals, you’ve also given it a reason to preserve itself: how else can it do what you want? No matter what goal an A.G.I. has, one of ours or one of its own—self-preservation, cognitive enhancement, resource acquisition—it may need to take over in order to achieve it. “2001” had *HAL*{: .small}, the spaceship’s computer, deciding that it had to kill all the humans aboard because “this mission is too important for me to allow you to jeopardize it.” In “I, Robot,” *VIKI*{: .small} explained that the robots have to take charge because, “despite our best efforts, your countries wage wars, you toxify your Earth, and pursue ever more imaginative means of self-destruction.” In the philosopher Nick Bostrom’s now famous example, an A.G.I. intent on maximizing the number of paper clips it can make would consume all the matter in the galaxy to make paper clips and would eliminate anything that interfered with its achieving that goal, including us. “[The Matrix](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB000GJPL1S?ref=sr_1_1_acs_kn_imdb_pa_dp&qid=1525701121&sr=1-1-acs&autoplay=0)” spun an elaborate version of this scenario: the A.I.s built a dreamworld in order to keep us placid as they fed us on the liquefied remains of the dead and harvested us for the energy they needed to run their programs. Agent Smith, the humanized face of the A.I.s, explained, “As soon as we started thinking for you, it really became _our_ civilization.”\n\n-=-=-=\n\nThe real risk of an A.G.I., then, may stem not from malice, or emergent self-consciousness, but simply from autonomy. Intelligence entails control, and an A.G.I. will be the apex cogitator. From this perspective, an A.G.I., however well intentioned, would likely behave in a way as destructive to us as any Bond villain. “Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb,” Bostrom writes in his 2014 book, “[Superintelligence](https:\u002F\u002Fwww.amazon.com\u002FSuperintelligence-Dangers-Strategies-Nick-Bostrom\u002Fdp\u002F0198739834\u002Fref=sr_1_1?s=books&ie=UTF8&qid=1525701139&sr=1-1&keywords=Superintelligence&dpID=51xiCuJ7VML&preST=_SY344_BO1,204,203,200_QL70_&dpSrc=srch),” a closely reasoned, cumulatively terrifying examination of all the ways in which we’re unprepared to make our masters. A recursive, self-improving A.G.I. won’t be smart like Einstein but “smart in the sense that an average human being is smart compared with a beetle or a worm.” How the machines take dominion is just a detail: Bostrom suggests that “at a pre-set time, nanofactories producing nerve gas or target-seeking mosquito-like robots might then burgeon forth simultaneously from every square meter of the globe.” That sounds screenplay-ready—but, ever the killjoy, he notes, “In particular, the AI does not adopt a plan so stupid that even we present-day humans can foresee how it would inevitably fail. This criterion rules out many science fiction scenarios that end in human triumph.”\n\nIf we can’t control an A.G.I., can we at least load it with beneficent values and insure that it retains them once it begins to modify itself? Max Tegmark observes that a woke A.G.I. may well find the goal of protecting us “as banal or misguided as we find compulsive reproduction.” He lays out twelve potential “AI Aftermath Scenarios,” including “Libertarian Utopia,” “Zookeeper,” “1984,” and “Self-Destruction.” Even the nominally preferable outcomes seem worse than the status quo. In “Benevolent Dictator,” the A.G.I. “uses quite a subtle and complex definition of human flourishing, and has turned Earth into a highly enriched zoo environment that’s really fun for humans to live in. As a result, most people find their lives highly fulfilling and meaningful.” And more or less indistinguishable from highly immersive video games or a simulation.\n\nTrying to stay optimistic, by his lights—bear in mind that Tegmark is a physicist—he points out that an A.G.I. could explore and comprehend the universe at a level we can’t even imagine. He therefore encourages us to view ourselves as mere packets of information that A.I.s could beam to other galaxies as a colonizing force. “This could be done either rather low-tech by simply transmitting the two gigabytes of information needed to specify a person’s DNA and then incubating a baby to be raised by the AI, or the AI could nanoassemble quarks and electrons into full-grown people who would have all the memories scanned from their originals back on Earth.” Easy peasy. He notes that this colonization scenario should make us highly suspicious of any blueprints an alien species beams at us. It’s less clear why we ought to fear alien blueprints from another galaxy, yet embrace the ones we’re about to bequeath to our descendants (if any).\n\nA.G.I. may be a recurrent evolutionary cul-de-sac that explains Fermi’s paradox: while conditions for intelligent life likely exist on billions of planets in our galaxy alone, we don’t see any. Tegmark concludes that “it appears that we humans are a historical accident, and aren’t the optimal solution to any well-defined physics problem. This suggests that a superintelligent AI with a rigorously defined goal will be able to improve its goal attainment by eliminating us.” Therefore, “to program a friendly AI, we need to capture the meaning of life.” Uh-huh.\n\nIn the meantime, we need a Plan B. Bostrom’s starts with an effort to slow the race to create an A.G.I. in order to allow more time for precautionary trouble-shooting. Astoundingly, however, he advises that, once the A.G.I. arrives, we give it the utmost possible deference. Not only should we listen to the machine; we should ask it to figure out what we want. The misalignment-of-goals problem would seem to make that extremely risky, but Bostrom believes that trying to negotiate the terms of our surrender is better than the alternative, which is relying on ourselves, “foolish, ignorant, and narrow-minded that we are.” Tegmark also concludes that we should inch toward an A.G.I. It’s the only way to extend meaning in the universe that gave life to us: “Without technology, our human extinction is imminent in the cosmic context of tens of billions of years, rendering the entire drama of life in our Universe merely a brief and transient flash of beauty.” We are the analog prelude to the digital main event.\n\nSo the plan, after we create our own god, would be to bow to it and hope it doesn’t require a blood sacrifice. An autonomous-car engineer named Anthony Levandowski has set out to start a religion in Silicon Valley, called Way of the Future, that proposes to do just that. After “The Transition,” the church’s believers will venerate “a Godhead based on Artificial Intelligence.” Worship of the intelligence that will control us, Levandowski told a _[Wired](https:\u002F\u002Fwww.wired.com\u002Fstory\u002Fanthony-levandowski-artificial-intelligence-religion\u002F)_ reporter, is the only path to salvation; we should use such wits as we have to choose the manner of our submission. “Do you want to be a pet or livestock?” he asked. I’m thinking, I’m thinking&#160;.&#160;.&#160;.&#160;♦","canonicalUrl":"","categories":{"tags":[{"id":"5c2e1def397f5b30646d0782","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def397f5b30646d0782","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Artificial General Intelligence (A.G.I.)","parent":null,"photos":{},"root":[],"slug":"artificial-general-intelligence-agi"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"Artificial General Intelligence (A.G.I.)","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"artificial-general-intelligence-agi"},{"id":"5c2e1def2396212cbb9fcaf8","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def2396212cbb9fcaf8","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"“Human + Machine: Reimagining Work in the Age of AI”","parent":null,"photos":{},"root":[],"slug":"human-machine-reimagining-work-in-the-age-of-ai"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"“Human + Machine: Reimagining Work in the Age of AI”","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"human-machine-reimagining-work-in-the-age-of-ai"},{"id":"5c2e1def4a08312cd3aa6da2","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def4a08312cd3aa6da2","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"“Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins”","parent":null,"photos":{},"root":[],"slug":"deep-thinking-where-machine-intelligence-ends-and-human-creativity-begins"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"“Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins”","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"deep-thinking-where-machine-intelligence-ends-and-human-creativity-begins"},{"id":"5c2e1def2396212cbb9fcaf9","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def2396212cbb9fcaf9","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"“Common Sense, the Turing Test, and the Quest for Real AI”","parent":null,"photos":{},"root":[],"slug":"common-sense-the-turing-test-and-the-quest-for-real-ai"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"“Common Sense, the Turing Test, and the Quest for Real AI”","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"common-sense-the-turing-test-and-the-quest-for-real-ai"},{"id":"5c2e1def397f5b30646d0783","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def397f5b30646d0783","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"“Life 3.0: Being Human in the Age of Artificial Intelligence”","parent":null,"photos":{},"root":[],"slug":"life-30-being-human-in-the-age-of-artificial-intelligence"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"“Life 3.0: Being Human in the Age of Artificial Intelligence”","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"life-30-being-human-in-the-age-of-artificial-intelligence"},{"id":"5c2e1def2bfcc72cd92d06af","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1def2bfcc72cd92d06af","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"“The Sentient Machine: The Coming Age of Artificial Intelligence”","parent":null,"photos":{},"root":[],"slug":"the-sentient-machine-the-coming-age-of-artificial-intelligence"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"“The Sentient Machine: The Coming Age of Artificial Intelligence”","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"the-sentient-machine-the-coming-age-of-artificial-intelligence"},{"id":"5c2e1c7841c92e2c9b85da16","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1c7841c92e2c9b85da16","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Technology","parent":null,"photos":{},"root":[],"slug":"technology"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"Technology","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"technology"},{"id":"5c2e1c7622d4972cd5b83286","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5c2e1c7622d4972cd5b83286","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Books","parent":null,"photos":{},"root":[],"slug":"books"},{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"}],"name":"Books","parent":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"photos":{},"root":{"id":"5afc81b4577f6a3b0500895c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Tags","parent":null,"photos":{},"root":[],"slug":"tags"},"slug":"books"}],"sections":[{"id":"59f3745037485d0228e318f1","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"59f3745037485d0228e318f1","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Dept. of Speculation","parent":null,"photos":{},"root":[],"slug":"dept-of-speculation"},{"id":"59040e521048cc5ce9e6a56c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Magazine","parent":null,"photos":{},"root":[],"slug":"magazine"},{"id":"5afc81ab371770228fe7e770","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Channels","parent":null,"photos":{},"root":[],"slug":"channels"}],"name":"Dept. of Speculation","parent":{"id":"59040e521048cc5ce9e6a56c","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Magazine","parent":null,"photos":{},"root":[],"slug":"magazine"},"photos":{},"root":{"id":"5afc81ab371770228fe7e770","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Channels","parent":null,"photos":{},"root":[],"slug":"channels"},"slug":"dept-of-speculation"}],"issues":[{"id":"5cabad88e457ec299f109761","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"5cabad88e457ec299f109761","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"May 14, 2018","parent":null,"photos":{},"root":[],"slug":"2018-05-14"},{"id":"5ca22ed0927fef2d9274bc46","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Issues","parent":null,"photos":{},"root":[],"slug":"issues"}],"name":"May 14, 2018","parent":{"id":"5ca22ed0927fef2d9274bc46","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Issues","parent":null,"photos":{},"root":[],"slug":"issues"},"photos":{},"root":{"id":"5ca22ed0927fef2d9274bc46","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Issues","parent":null,"photos":{},"root":[],"slug":"issues"},"slug":"2018-05-14"}],"sections-toc":[{"id":"590412649f91e567e06eca93","modelName":"category","collection":"categories","contributors":{},"hierarchy":[{"id":"590412649f91e567e06eca93","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Reporting","parent":null,"photos":{},"root":[],"slug":"reporting"},{"id":"5902abaf27562e4d156e37e1","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Sections - TOC","parent":null,"photos":{},"root":[],"slug":"sections-toc"}],"name":"Reporting","parent":{"id":"5902abaf27562e4d156e37e1","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Sections - TOC","parent":null,"photos":{},"root":[],"slug":"sections-toc"},"photos":{},"root":{"id":"5902abaf27562e4d156e37e1","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Sections - TOC","parent":null,"photos":{},"root":[],"slug":"sections-toc"},"slug":"reporting"}]},"channel":"Magazine","contentSource":"magazine","contributors":{"author":[{"id":"590a035a019dfc3494ea416a","modelName":"contributor","collection":"contributors","bio":"Tad Friend has been a staff writer at *The New Yorker* since 1998. He writes the magazine’s Letter from California and has examined the venture capitalist Marc Andreessen, Silicon Valley’s quest for eternal life, and Donald Glover, among many other subjects. His piece on suicides at the Golden Gate Bridge, “Jumpers,” inspired the documentary film “The Bridge” and the Sleater-Kinney song “Jumpers.” His work has been chosen for “The Best American Travel Writing,” “The Best American Sports Writing,” “The Best American Crime Reporting,” and “The Best Technology Writing.” He is the author of a memoir, “[Cheerful Money: Me, My Family, and the Last Days of Wasp Splendor](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F0316003174),” and “[Lost in Mongolia: Travels in Hollywood and Other Foreign Lands](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F0812991559),” a collection of his articles. Previously, he was a contributing editor at *Esquire* and *Outside*.","canonicalUrl":"http:\u002F\u002Fwww.newyorker.com\u002Fcontributors\u002Ftad-friend","email":"","name":"Tad Friend","photo":{"id":"59097b6f2179605b11ad8f00","modelName":"photo","collection":"photos","aspectRatios":{"master":{"width":600,"height":600,"format":"PNG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2017\u002F05\u002F03\u002F59097b6f2179605b11ad8eff_friend-tad.png"}},"caption":"","altText":"Tad Friend","credit":"","filename":"friend-tad.png","revision":6,"title":"friend-tad"},"socialMedia":[{"network":"Twitter","handle":"tadfriend"}],"title":"Tad Friend has been a staff writer at The New Yorker since 1998. He is the author of the memoir “[Cheerful Money](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F0316003174)” and the essay collection “[Lost in Mongolia](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F0812991559).”","url":"contributors\u002Ftad-friend"}]},"dek":"Do the perils of A.I. exceed its promise?","hed":"Superior Intelligence","galleries":{},"inlineEmbeds":[{"id":"5aeb3d4cd315973015137c62","modelName":"cartoon","collection":"cartoons","altText":"“Please, Melissa, just give him your cashmere!”","aspectRatios":{"master":{"width":2560,"height":1592,"format":"JPEG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4cd315973015137c61_180514_a21704.jpg"},"2:2":{"override":false,"height":1592,"width":1592,"modifications":{"crop":{"height":1592,"width":1592,"x":484,"y":0}},"duration":null},"16:9":{"override":false,"height":1440,"width":2560,"modifications":{"crop":{"height":1440,"width":2560,"x":0,"y":0}},"duration":null},"4:3":{"override":false,"height":1590,"width":2120,"modifications":{"crop":{"height":1590,"width":2120,"x":220,"y":0}},"duration":null},"1:1":{"override":false,"height":1592,"width":1592,"modifications":{"crop":{"height":1592,"width":1592,"x":484,"y":0}},"duration":null}},"caption":"“Please, Melissa, just give him your cashmere!”","categories":{},"contributors":{},"filename":"180514_a21704.jpg","pubDate":"2018-05-03T16:48:12.000Z","revision":0,"socialDescription":"“Please, Melissa, just give him your cashmere!”","socialTitle":"A New Yorker Cartoon","tags":["_folio:46"],"title":"a21704","url":"cartoon\u002Fa21704"},{"id":"5aeb3d4c7505432fc35f541a","modelName":"cartoon","collection":"cartoons","altText":"“A number of items on that menu are consistently chosen by an overwhelming majority of the American people.”","aspectRatios":{"master":{"width":2560,"height":2047,"format":"JPEG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4c7505432fc35f5416_180514_a21673.jpg"},"2:2":{"override":false,"height":2047,"width":2047,"modifications":{"crop":{"height":2047,"width":2047,"x":256.5,"y":0}},"duration":null},"16:9":{"override":false,"height":1440,"width":2560,"modifications":{"crop":{"height":1440,"width":2560,"x":0,"y":0}},"duration":null},"4:3":{"override":false,"height":1920,"width":2560,"modifications":{"crop":{"height":1920,"width":2560,"x":0,"y":0}},"duration":null},"1:1":{"override":false,"height":2047,"width":2047,"modifications":{"crop":{"height":2047,"width":2047,"x":256.5,"y":0}},"duration":null}},"caption":"“A number of items on that menu are consistently chosen by an overwhelming majority of the American people.”","categories":{},"contributors":{},"filename":"180514_a21673.jpg","pubDate":"2018-05-03T16:48:12.000Z","revision":0,"socialDescription":"“A number of items on that menu are consistently chosen by an overwhelming majority of the American people.”","socialTitle":"A New Yorker Cartoon","tags":["_folio:48"],"title":"a21673","url":"cartoon\u002Fa21673"},{"id":"5aeb3d4c7505432fc35f5418","modelName":"cartoon","collection":"cartoons","altText":"“I’m afraid it’s not cheese—it’s ‘cheese-like.’ ”","aspectRatios":{"master":{"width":2560,"height":1685,"format":"JPEG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4c7505432fc35f5415_180514_a21744.jpg"},"2:2":{"override":false,"height":1685,"width":1685,"modifications":{"crop":{"height":1685,"width":1685,"x":437.5,"y":0}},"duration":null},"16:9":{"override":false,"height":1440,"width":2560,"modifications":{"crop":{"height":1440,"width":2560,"x":0,"y":0}},"duration":null},"4:3":{"override":false,"height":1683,"width":2244,"modifications":{"crop":{"height":1683,"width":2244,"x":158,"y":0}},"duration":null},"1:1":{"override":false,"height":1685,"width":1685,"modifications":{"crop":{"height":1685,"width":1685,"x":437.5,"y":0}},"duration":null}},"caption":"“I’m afraid it’s not cheese—it’s ‘cheese-like.’ ”","categories":{},"contributors":{},"filename":"180514_a21744.jpg","pubDate":"2018-05-03T16:48:12.000Z","revision":0,"socialDescription":"“I’m afraid it’s not cheese—it’s ‘cheese-like.’ ”","socialTitle":"A New Yorker Cartoon","tags":["_folio:50"],"title":"a21744","url":"cartoon\u002Fa21744"},{"id":"5aeb3d4cd5c03f2753baf2a2","modelName":"cartoon","collection":"cartoons","altText":"“It’s not personal. The boss just doesn’t like seeing people in so much debt for such a useless degree.”","aspectRatios":{"master":{"width":2560,"height":2070,"format":"JPEG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4cd5c03f2753baf2a1_180514_a20974.jpg"},"2:2":{"override":false,"height":2070,"width":2070,"modifications":{"crop":{"height":2070,"width":2070,"x":245,"y":0}},"duration":null},"16:9":{"override":false,"height":1440,"width":2560,"modifications":{"crop":{"height":1440,"width":2560,"x":0,"y":0}},"duration":null},"4:3":{"override":false,"height":1920,"width":2560,"modifications":{"crop":{"height":1920,"width":2560,"x":0,"y":0}},"duration":null},"1:1":{"override":false,"height":2070,"width":2070,"modifications":{"crop":{"height":2070,"width":2070,"x":245,"y":0}},"duration":null}},"caption":"“It’s not personal. The boss just doesn’t like seeing people in so much debt for such a useless degree.”","categories":{},"contributors":{},"filename":"180514_a20974.jpg","pubDate":"2018-05-03T16:48:13.000Z","revision":0,"socialDescription":"“It’s not personal. The boss just doesn’t like seeing people in so much debt for such a useless degree.”","socialTitle":"A New Yorker Cartoon","tags":["_folio:51"],"title":"a20974","url":"cartoon\u002Fa20974"}],"issueDate":"May 14, 2018","ledeCaption":"","modifiedAt":"2019-10-08T15:33:54.698Z","photos":{"tout":[{"id":"5aeb3d4c7505432fc35f5419","modelName":"photo","collection":"photos","aspectRatios":{"2:1":{"width":1262,"height":631,"override":false,"modifications":{"crop":{"x":633,"y":936,"height":631,"width":1262}},"duration":null},"2:2":{"width":2305,"height":2305,"override":false,"modifications":{"crop":{"x":121,"y":97,"height":2305,"width":2305}},"duration":null},"16:9":{"width":1286,"height":723,"override":false,"modifications":{"crop":{"x":619,"y":891,"height":723,"width":1286}},"duration":null},"4:3":{"width":2560,"height":1920,"override":false,"modifications":{"crop":{"x":0,"y":308,"height":1920,"width":2560}},"duration":null},"1:1":{"width":2307,"height":2307,"override":false,"modifications":{"crop":{"x":125,"y":110,"height":2307,"width":2307}},"duration":null},"master":{"format":"JPEG","url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4c7505432fc35f5417_180514_r32044.jpg","width":2560,"height":2560,"duration":null}},"caption":"An A.I. system may need to take charge in order to achieve the goals we gave it.","altText":"A cartoon-like illustration of a red eyeball and its veins","credit":"Illustration by Harry Campbell","filename":"180514_r32044.jpg","revision":8,"tags":[],"title":"180514_r32044"}],"social":[{"id":"5aeb3d4c7505432fc35f5419","modelName":"photo","collection":"photos","aspectRatios":{"2:1":{"width":1262,"height":631,"override":false,"modifications":{"crop":{"x":633,"y":936,"height":631,"width":1262}},"duration":null},"2:2":{"width":2305,"height":2305,"override":false,"modifications":{"crop":{"x":121,"y":97,"height":2305,"width":2305}},"duration":null},"16:9":{"width":1286,"height":723,"override":false,"modifications":{"crop":{"x":619,"y":891,"height":723,"width":1286}},"duration":null},"4:3":{"width":2560,"height":1920,"override":false,"modifications":{"crop":{"x":0,"y":308,"height":1920,"width":2560}},"duration":null},"1:1":{"width":2307,"height":2307,"override":false,"modifications":{"crop":{"x":125,"y":110,"height":2307,"width":2307}},"duration":null},"master":{"format":"JPEG","url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4c7505432fc35f5417_180514_r32044.jpg","width":2560,"height":2560,"duration":null}},"caption":"An A.I. system may need to take charge in order to achieve the goals we gave it.","altText":"A cartoon-like illustration of a red eyeball and its veins","credit":"Illustration by Harry Campbell","filename":"180514_r32044.jpg","revision":8,"tags":[],"title":"180514_r32044"}],"lede":[{"id":"5aeb3d4c7505432fc35f5419","modelName":"photo","collection":"photos","aspectRatios":{"2:1":{"width":1262,"height":631,"override":false,"modifications":{"crop":{"x":633,"y":936,"height":631,"width":1262}},"duration":null},"2:2":{"width":2305,"height":2305,"override":false,"modifications":{"crop":{"x":121,"y":97,"height":2305,"width":2305}},"duration":null},"16:9":{"width":1286,"height":723,"override":false,"modifications":{"crop":{"x":619,"y":891,"height":723,"width":1286}},"duration":null},"4:3":{"width":2560,"height":1920,"override":false,"modifications":{"crop":{"x":0,"y":308,"height":1920,"width":2560}},"duration":null},"1:1":{"width":2307,"height":2307,"override":false,"modifications":{"crop":{"x":125,"y":110,"height":2307,"width":2307}},"duration":null},"master":{"format":"JPEG","url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2018\u002F05\u002F03\u002F5aeb3d4c7505432fc35f5417_180514_r32044.jpg","width":2560,"height":2560,"duration":null}},"caption":"An A.I. system may need to take charge in order to achieve the goals we gave it.","altText":"A cartoon-like illustration of a red eyeball and its veins","credit":"Illustration by Harry Campbell","filename":"180514_r32044.jpg","revision":8,"tags":[],"title":"180514_r32044"}]},"promoDek":"Thinking about artificial intelligence can help clarify what makes us human—for better and for worse.","promoHed":"How Frightened Should We Be of A.I.?","pubDate":"2018-05-07T09:00:00.000Z","related":[{"id":"5911cbb2803aff0f1c1359ac","modelName":"article","collection":"articles","body":"## I. Omens\n\n\n\nLast year, a curious nonfiction book became a _Times_ best-seller: a dense meditation on artificial intelligence by the philosopher Nick Bostrom, who holds an appointment at Oxford. Titled “Superintelligence: Paths, Dangers, Strategies,” it argues that true artificial intelligence, if it is realized, might pose a danger that exceeds every previous threat from technology—even nuclear weapons—and that if its development is not managed carefully humanity risks engineering its own extinction. Central to this concern is the prospect of an “intelligence explosion,” a speculative event in which an A.I. gains the ability to improve itself, and in short order exceeds the intellectual potential of the human brain by many orders of magnitude. \n\n\n\nSuch a system would effectively be a new kind of life, and Bostrom’s fears, in their simplest form, are evolutionary: that humanity will unexpectedly become outmatched by a smarter competitor. He sometimes notes, as a point of comparison, the trajectories of people and gorillas: both primates, but with one species dominating the planet and the other at the edge of annihilation. “Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb,” he concludes. “We have little idea when the detonation will occur, though if we hold the device to our ear we can hear a faint ticking sound.” \n\n\n\nAt the age of forty-two, Bostrom has become a philosopher of remarkable influence. “Superintelligence” is only his most visible response to ideas that he encountered two decades ago, when he became a transhumanist, joining a fractious quasi-utopian movement united by the expectation that accelerating advances in technology will result in drastic changes—social, economic, and, most strikingly, biological—which could converge at a moment of epochal transformation known as the Singularity. Bostrom is arguably the leading transhumanist philosopher today, a position achieved by bringing order to ideas that might otherwise never have survived outside the half-crazy Internet ecosystem where they formed. He rarely makes concrete predictions, but, by relying on probability theory, he seeks to tease out insights where insights seem impossible. \n\n\n\nSome of Bostrom’s cleverest arguments resemble Swiss Army knives: they are simple, toylike, a pleasure to consider, with colorful exteriors and precisely calibrated mechanics. He once cast a moral case for medically engineered immortality as a fable about a kingdom terrorized by an insatiable dragon. A reformulation of Pascal’s wager became a dialogue between the seventeenth-­century philosopher and a mugger from another dimension. \n\n\n\n“Superintelligence” is not intended as a treatise of deep originality; Bostrom’s contribution is to impose the rigors of analytic philosophy on a messy corpus of ideas that emerged at the margins of academic thought. Perhaps because the field of A.I. has recently made striking advances—with everyday technology seeming, more and more, to exhibit something like intelligent reasoning—the book has struck a nerve. Bostrom’s supporters compare it to “Silent Spring.” In moral philosophy, Peter Singer and Derek Parfit have received it as a work of importance, and distinguished physicists such as Stephen Hawking have echoed its warning. Within the high caste of Silicon Valley, Bostrom has acquired the status of a sage. Elon Musk, the C.E.O. of Tesla, promoted the book on Twitter, noting, “We need to be super careful with AI. Potentially more dangerous than nukes.” Bill Gates recommended it, too. Suggesting that an A.I. could threaten humanity, he said, during a talk in China, “When people say it’s not a problem, then I really start to get to a point of disagreement. How can they not see what a huge challenge this is?”\n\n\n\nThe people who say that artificial intelligence is not a problem tend to work in artificial intelligence. Many prominent researchers regard Bostrom’s basic views as implausible, or as a distraction from the near-term benefits and moral dilemmas posed by the technology—not least because A.I. systems today can barely guide robots to open doors. Last summer, Oren Etzioni, the C.E.O. of the Allen Institute for Artificial Intelligence, in Seattle, referred to the fear of machine intelligence as a “Frankenstein complex.” Another leading researcher declared, “I don’t worry about that for the same reason I don’t worry about overpopulation on Mars.” Jaron Lanier, a Microsoft researcher and tech commentator, told me that even framing the differing views as a debate was a mistake. “This is not an honest conversation,” he said. “People think it is about technology, but it is really about religion, people turning to metaphysics to cope with the human condition. They have a way of dramatizing their beliefs with an end-of-days scenario—and one does not want to criticize other people’s religions.”\n\n\n\nBecause the argument has played out on blogs and in the popular press, beyond the ambit of peer-reviewed journals, the two sides have appeared in caricature, with headlines suggesting either doom (“*Will Super-intelligent Machines Kill Us All*{: .small}?”) or a reprieve from doom (“*Artificial intelligence*{: .small} ‘*will not end human race*{: .small}’ ”). Even the most grounded version of the debate occupies philosophical terrain where little is clear. But, Bostrom argues, if artificial intelligence can be achieved it would be an event of unparalleled consequence—perhaps even a rupture in the fabric of history. A bit of long-range forethought might be a moral obligation to our own species. \n\n\n\nBostrom’s sole responsibility at Oxford is to direct an organization called the Future of Humanity Institute, which he founded ten years ago, with financial support from James Martin, a futurist and tech millionaire. Bostrom runs the institute as a kind of philosophical radar station: a bunker sending out navigational pulses into the haze of possible futures. Not long ago, an F.H.I. fellow studied the possibility of a “dark fire scenario,” a cosmic event that, he hypothesized, could occur under certain high-energy conditions: everyday matter mutating into dark matter, in a runaway process that could erase most of the known universe. (He concluded that it was highly unlikely.) Discussions at F.H.I. range from conventional philosophic topics, like the nature of compromise, to the optimal structure of space empires—whether a single intergalactic machine intelligence, supported by a vast array of probes, presents a more ethical future than a cosmic imperium housing millions of digital minds. \n\n\n\nEarlier this year, I visited the institute, which is situated on a winding street in a part of Oxford that is a thousand years old. It takes some work to catch Bostrom at his office. Demand for him on the lecture circuit is high; he travels overseas nearly every month to relay his technological omens in a range of settings, from Google’s headquarters to a Presidential commission in Washington. Even at Oxford, he maintains an idiosyncratic schedule, remaining in the office until two in the morning and returning sometime the next afternoon.\n\n\n\nI arrived before he did, and waited in a hallway between two conference rooms. A plaque indicated that one of them was the Arkhipov Room, honoring Vasili Arkhipov, a Soviet naval officer. During the Cuban missile crisis, Arkhipov was serving on a submarine in the Caribbean when U.S. destroyers set off depth charges nearby. His captain, unable to establish radio contact with Moscow, feared that the conflict had escalated and ordered a nuclear strike. But Arkhipov dissuaded him, and all-out atomic war was averted. Across the hallway was the Petrov Room, named for another Soviet officer who prevented a global nuclear catastrophe. Bostrom later told me, “They may have saved more lives than most of the statesmen we celebrate on stamps.” \n\n\n\nThe sense that a vanguard of technical-minded people working in obscurity, at odds with consensus, might save the world from auto-annihilation runs through the atmosphere at F.H.I. like an electrical charge. While waiting for Bostrom, I peered through a row of windows into the Arkh­ipov Room, which looked as though it was used for both meetings and storage; on a bookcase there were boxes containing light bulbs, lampshades, cables, spare mugs. A gaunt philosophy Ph.D. wrapped in a thick knitted cardigan was pacing in front of a whiteboard covered in notation, which he attacked in bursts. After each paroxysm, he paced, hands behind his back, head tilted downward. At one point, he erased a panel of his work. Taking this as an opportunity to interrupt, I asked him what he was doing. “It is a problem involving an aspect of A.I. called ‘planning,’&#160;” he said. His demeanor radiated irritation. I left him alone.\n\n\n\nBostrom arrived at 2 *p.m*{: .small}. He has a boyish countenance and the lean, vital physique of a yoga instructor—though he could never be mistaken for a yoga instructor. His intensity is too untidily contained, evident in his harried gait on the streets outside his office (he does not drive), in his voracious consumption of audiobooks (played at two or three times the normal speed, to maximize efficiency), and his fastidious guarding against illnesses (he avoids handshakes and wipes down silverware beneath a tablecloth). Bostrom can be stubborn about the placement of an office plant or the choice of a font. But when his arguments are challenged he listens attentively, the mechanics of consideration nearly dis­cernible beneath his skin. Then, calmly, quickly, he dispatches a response, one idea interlocked with another. \n\n\n\nHe asked if I wanted to go to the market. “You can watch me make my elixir,” he said. For the past year or so, he has been drinking his lunch (another efficiency): a smoothie containing fruits, vegetables, proteins, and fats. Using his elbow, he hit a button that electronically opened the front door. Then we rushed out. \n\n\n\nBostrom has a reinvented man’s sense of lost time. An only child, he grew up—as Niklas Boström—in Helsingborg, on the southern coast of Sweden. Like many exceptionally bright children, he hated school, and as a teen-ager he developed a listless, romantic persona. In 1989, he wandered into a library and stumbled onto an anthology of nineteenth-century German philosophy, containing works by Nietzsche and Schopenhauer. He read it in a nearby forest, in a clearing that he often visited to think and to write poetry, and experienced a euphoric insight into the possibilities of learning and achievement. “It’s hard to convey in words what that was like,” Bostrom told me; instead he sent me a photograph of an oil painting that he had made shortly afterward. It was a semi-representational landscape, with strange figures crammed into dense undergrowth; beyond, a hawk soared below a radiant sun. He titled it “The First Day.”\n\n\n\nDeciding that he had squandered his early life, he threw himself into a campaign of self-education. He ran down the citations in the anthology, branching out into art, literature, science. He says that he was motivated not only by curiosity but also by a desire for actionable knowledge about how to live. To his parents’ dismay, Bostrom insisted on finishing his final year of high school from home by taking special exams, which he completed in ten weeks. He grew distant from old friends: “I became quite fanatical and felt quite isolated for a period of time.” \n\n\n\nWhen Bostrom was a graduate student in Stockholm, he studied the work of the analytic philosopher W. V. Quine, who had explored the difficult relationship between language and reality. His adviser drilled precision into him by scribbling “not clear” throughout the margins of his papers. “It was basically his only feedback,” Bostrom told me. “The effect was still, I think, beneficial.” His previous academic interests had ranged from psychology to mathematics; now he took up theoretical physics. He was fascinated by technology. The World Wide Web was just emerging, and he began to sense that the heroic philosophy which had inspired him might be outmoded. In 1995, Bostrom wrote a poem, “Requiem,” which he told me was “a signing-off letter to an earlier self.” It was in Swedish, so he offered me a synopsis: “I describe a brave general who has overslept and finds his troops have left the encampment. He rides off to catch up with them, pushing his horse to the limit. Then he hears the thunder of a modern jet plane streaking past him across the sky, and he realizes that he is obsolete, and that courage and spiritual nobility are no match for machines.”  \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b649e7206a168e2d17827]||||||\n\n+++\n\n \n\n\n\nAlthough Bostrom did not know it, a growing number of people around the world shared his intuition that technology could cause transformative change, and they were finding one another in an online discussion group administered by an organization in California called the Extropy Institute. The term “extropy,” coined in 1967, is generally used to describe life’s capacity to reverse the spread of entropy across space and time. Extropianism is a libertarian strain of transhumanism that seeks “to direct human evolution,” hoping to eliminate disease, suffering, even death; the means might be genetic modification, or as yet un­invented nanotechnology, or perhaps dispensing with the body entirely and uploading minds into supercomputers. (As one member noted, “Immortality is mathematical, not mystical.”) The Extropians advocated the development of artificial superintelligence to achieve these goals, and they envisioned humanity colonizing the universe, converting inert matter into engines of civilization. The discussions were nerdy, lunatic, imaginative, thought-provoking. Anders Sandberg, a former member of the group who now works at Bostrom’s institute, told me, “Just imagine if you could listen in on the debates of the Italian Futurists or early Surrealists.”\n\n\n\nIn 1996, while pursuing further graduate work at the London School of Economics, Bostrom learned about the Extropy discussion group and became an active participant. A year later, he co-founded his own organization, the World Transhumanist Association, which was less libertarian and more academically spirited. He crafted approachable statements on transhumanist values and gave interviews to the BBC. The line between his academic work and his activism blurred: his Ph.D. dissertation centered on a study of the Doomsday Argument, which uses probability theory to make inferences about the longevity of human civilization. The work baffled his advisers, who respected him but rarely agreed with his conclusions. Mostly, they left him alone.\n\n\n\nBostrom had little interest in conventional philosophy—not least because he expected that superintelligent minds, whether biologically enhanced or digital, would make it obsolete. “Suppose you had to build a new subway line, and it was this grand trans-generational enterprise that humanity was engaged in, and everybody had a little role,” he told me. “So you have a little shovel. But if you know that a giant bulldozer will arrive on the scene tomorrow, then does it really make sense to spend your time today digging the big hole with your shovel? Maybe there is something else you could do with your time. Maybe you could put up a signpost for the great shovel, so it will start digging in the right place.” He came to believe that a key role of the philosopher in modern society was to acquire the knowledge of a polymath, then use it to help guide humanity to its next phase of existence—a discipline that he called “the philosophy of technological prediction.” He was trying to become such a seer. \n\n\n\n“He was ultra-consistent,” Daniel Hill, a British philosopher who befriended Bostrom while they were graduate students in London, told me. “His interest in science was a natural outgrowing of his understandable desire to live forever, basically.” \n\n\n\nBostrom has written more than a hundred articles, and his longing for immortality can be seen throughout. In 2008, he framed an essay as a call to action from a future utopia. “Death is not one but a multitude of assassins,” he warned. “Take aim at the causes of early death—infection, violence, malnutrition, heart attack, cancer. Turn your biggest gun on aging, and fire. You must seize the biochemical processes in your body in order to vanquish, by and by, illness and senescence. In time, you will discover ways to move your mind to more durable media.” He tends to see the mind as immaculate code, the body as inefficient hardware—able to accommodate limited hacks but probably destined for replacement. \n\n\n\nEven Bostrom’s marriage is largely mediated by technology. His wife, Susan, has a Ph.D. in the sociology of medicine and a bright, down-to-earth manner. (“She teases me about the Terminator and the robot army,” he told me.) They met thirteen years ago, and for all but six months they have lived on opposite sides of the Atlantic, even after the recent birth of their son. The arrangement is voluntary: she prefers Montreal; his work keeps him at Oxford. They Skype several times a day, and he directs as much international travel as possible through Canada, so they can meet in non-digital form. \n\n\n\nIn Oxford, as Bostrom shopped for his smoothie, he pointed out a man vaping. “There is also the more old-school method of taking nicotine: chewing gum,” he told me. “I do chew nicotine gum. I read a few papers saying it might have some nootropic effect”—that is, it might enhance cognition. He drinks coffee, and usually abstains from alcohol. He briefly experimented with the smart drug Modafinil, but gave it up. \n\n\n\nBack at the institute, he filled an industrial blender with lettuce, carrots, cauliflower, broccoli, blueberries, turmeric, vanilla, oat milk, and whey powder. “If there is one thing Nick cares about, it is minds,” Sandberg told me. “That is at the root of many of his views about food, because he is worried that toxin X or Y might be bad for his brain.” He suspects that Bostrom also enjoys the ritualistic display. “Swedes are known for their smugness,” he joked. “Perhaps Nick is subsisting on smugness.” \n\n\n\nA young employee eyed Bostrom getting ready to fire up the blender. “I can tell when Nick comes into the office,” he said. “My hair starts shaking.” \n\n\n\n“Yeah, this has got three horsepower,” Bostrom said. He ran the blender, producing a noise like a circular saw, and then filled a tall glass stein with purple-­green liquid. We headed to his office, which was meticulous. By a window was a wooden desk supporting an iMac and not another item; against a wall were a chair and a cabinet with a stack of documents. The only hint of excess was light: there were fourteen lamps. \n\n\n\nIt is hard to spend time at Bostrom’s institute without drifting into reveries of a far future. What might humanity look like millions of years from now? The upper limit of survival on Earth is fixed to the life span of the sun, which in five billion years will become a red giant and swell to more than two hundred times its present size. It is possible that Earth’s orbit will adjust, but more likely that the planet will be destroyed. In any case, long before then, nearly all plant life will die, the oceans will boil, and the Earth’s crust will heat to a thousand degrees. In half a billion years, the planet will be uninhabitable.\n\n\n\nThe view of the future from Bostrom’s office can be divided into three grand panoramas. In one, humanity experiences an evolutionary leap—either assisted by technology or by merging into it and becoming software—to achieve a sublime condition that Bostrom calls “posthumanity.” Death is overcome, mental experience expands beyond recognition, and our descendants colonize the universe. In another panorama, humanity becomes extinct or experiences a disaster so great that it is unable to recover. Between these extremes, Bostrom envisions scenarios that resemble the status quo—people living as they do now, forever mired in the “human era.” It’s a vision familiar to fans of sci-fi: on “Star Trek,” Captain Kirk was born in the year 2233, but when an alien portal hurls him through time and space to Depression-era Manhattan he blends in easily. \n\n\n\nBostrom dislikes science fiction. “I’ve never been keen on stories that just try to present ‘wow’ ideas—the equivalent of movie productions that rely on stunts and explosions to hold the attention,” he told me. “The question is not whether we can think of something radical or extreme but whether we can discover some sufficient reason for updating our credence function.” \n\n\n\nHe believes that the future can be studied with the same meticulousness as the past, even if the conclusions are far less firm. “It may be highly unpredictable where a traveller will be one hour after the start of her journey, yet predictable that after five hours she will be at her destination,” he once argued. “The _very_ long-term future of humanity may be relatively easy to predict.” He offers an example: if history were reset, the industrial revolution might occur at a different time, or in a different place, or perhaps not at all, with innovation instead occurring in increments over hundreds of years. In the short term, predicting technological achievements in the counter-history might not be possible; but after, say, a hundred thousand years it is easier to imagine that all the same inventions would have emerged. \n\n\n\nBostrom calls this the Technological Completion Conjecture: “If scientific- and technological-development efforts do not effectively cease, then all impor­t­­­ant basic capabilities that could be obtained through some possible technology will be obtained.” In light of this, he suspects that the farther into the future one looks the less likely it seems that life will continue as it is. He favors the far ends of possibility: humanity becomes transcendent or it perishes. \n\n\n\nIn the nineteen-nineties, as these ideas crystallized in his thinking, Bostrom began to give more attention to the question of extinction. He did not believe that doomsday was imminent. His interest was in risk, like an insurance agent’s. No matter how improbable extinction may be, Bostrom argues, its consequences are near-infinitely bad; thus, even the tiniest step toward reducing the _chance_ that it will happen is near-­infinitely valuable. At times, he uses arithmetical sketches to illustrate this point. Imagining one of his utopian scenarios—trillions of digital minds thriving across the cosmos—he reasons that, if there is even a one-per-cent chance of this happening, the expected value of reducing an existential threat by a billionth of a billionth of one per cent would be worth a hundred billion times the value of a billion present-day lives. Put more simply: he believes that his work could dwarf the moral importance of anything else.\n\n\n\nBostrom introduced the philosophical concept of “existential risk” in 2002, in the _Journal of Evolution and Technology_. In recent years, new organizations have been founded almost annually to help reduce it—among them the Centre for the Study of Existential Risk, affiliated with Cambridge Uni­versity, and the Future of Life Institute, which has ties to the Massachusetts Institute of Technology. All of them face a key problem: _Homo sapiens_, since its emergence two hundred thousand years ago, has proved to be remarkably resilient, and figuring out what might imperil its existence is not obvious. Climate change is likely to cause vast environmental and economic damage—but it does not seem impossible to survive. So-called super-volcanoes have thus far not threatened the perpetuation of the species. *NASA*{: .small} spends forty million dollars each year to determine if there are significant comets or asteroids headed for Earth. (There aren’t.) \n\n\n\nBostrom does not find the lack of obvious existential threats comforting. Because it is impossible to endure extinction twice, he argues, we cannot rely on history to calculate the probability that it will occur. The most worrying dangers are those that Earth has never encountered before. “It is hard to cause human extinction with seventeenth-century technology,” Bostrom told me. Three centuries later, though, the prospect of a technological apocalypse was urgently plausible. Bostrom dates the first scientific analysis of existential risk to the Manhattan Project: in 1942, Robert Oppenheimer became concerned that an atomic detonation of sufficient power could cause the entire atmosphere to ignite. A subsequent study concluded that the scenario was “unreasonable,” given the limitations of the weapons then in development. But even if the great nuclear nightmares of the Cold War did not come true, the tools were there to cause destruction on a scale not previously possible. As innovations grow even more complex, it is increasingly difficult to evaluate the dangers ahead. The answers must be fraught with ambiguity, because they can be derived only by predicting the effects of technologies that exist mostly as theories or, even more indirectly, by using abstract reasoning. \n\n\n\n\n\n\n\nAs a philosopher, Bostrom takes a sweeping, even cosmic, view of such problems. One afternoon, he told me, “The probabilities that any given planet will produce intelligent life—this may also have action-relevant information.” In the past several years, *NASA*{: .small} probes have found increasing evidence that the building blocks of life are abundant throughout space. So much water has been discovered—on Mars and on the moons of Jupiter and Saturn—that one scientist described our solar system as “a pretty soggy place.” There are amino acids on icy comets and complex organic molecules in distant star-forming clouds. On this planet, life has proved capable of thriving in unimaginably punishing conditions: without oxygen, without light, at four hundred degrees above or below zero. In 2007, the European Space Agency hitched tiny creatures to the exterior of a satellite. They not only survived the flight; some even laid eggs afterward. \n\n\n\nWith ten billion Earth-like planets in our galaxy alone, and a hundred billion galaxies in the universe, there is good reason to suspect that extraterrestrial life may one day be discovered. For Bostrom, this would augur disaster. “It would be great news to find that Mars is a completely sterile planet,” he argued not long ago. “Dead rocks and lifeless sands would lift my spirits.” His reasoning begins with the age of the universe. Many of those Earth-like planets are thought to be far, far older than ours. One that was recently discovered, called Kepler 452b, is as much as one and a half billion years older. Bostrom asks: If life had formed there on a time scale resembling our own, what would it look like? What kind of technological progress could a civilization achieve with a head start of hundreds of millions of years?\n\n\n\nLife as we know it tends to spread wherever it can, and Bostrom estimates that, if an alien civilization could design space probes capable of travelling at even one per cent of the speed of light, the entire Milky Way could be colonized in twenty million years—a tiny fraction of the age difference between Kepler 452b and Earth. One could argue that no technology will ever propel ships at so great a speed. Or perhaps millions of alien civilizations possess the know-how for intergalactic travel, but they aren’t interested. Even so, because the universe is so colossal, and because it is so old, only a small number of civilizations would need to behave as life does on Earth—unceasingly expanding—in order to be visible. Yet, as Bostrom notes, “You start with billions and billions of potential germination points for life, and you end up with a sum total of _zero_ alien civilizations that developed technologically to the point where they become manifest to us earthly observers. So what’s stopping them?” \n\n\n\nIn 1950, Enrico Fermi sketched a version of this paradox during a lunch break while he was working on the H-bomb, at Los Alamos. Since then, many resolutions have been proposed—some of them exotic, such as the idea that Earth is housed in an interplanetary alien zoo. Bostrom suspects that the answer is simple: space appears to be devoid of life because it is. This implies that intelligent life on Earth is an astronomically rare accident. But, if so, when did that accident occur? Was it in the first chemical reactions in the primordial soup? Or when single-celled organisms began to replicate using DNA? Or when animals learned to use tools? Bos­trom likes to think of these hurdles as Great Filters: key phases of improbability that life everywhere must pass through in order to develop into intelligent species. Those which do not make it either go extinct or fail to evolve.\n\n\n\nThus, for Bostrom, the discovery of a single-celled creature inhabiting a damp stretch of Martian soil would constitute a disconcerting piece of evidence. If two planets independently evolved primitive organisms, then it seems more likely that this type of life can be found on many planets throughout the universe. Bostrom reasons that this would suggest that the Great Filter comes at some later evolutionary stage. The discovery of a fossilized vertebrate would be even worse: it would suggest that the universe appears lifeless not because complex life is unusual but, rather, because it is always somehow thwarted before it becomes advanced enough to colonize space. \n\n\n\nIn Bostrom’s view, the most distressing possibility is that the Great Filter is ahead of us—that evolution frequently achieves civilizations like our own, but they perish before reaching their technological maturity. Why might that be? “Natural disasters such as asteroid hits and super-­volcanic eruptions are unlikely Great Filter candidates, because, even if they destroyed a significant number of civilizations, we would expect some civilizations to get lucky and escape disaster,” he argues. “Perhaps the most likely type of existential risks that could constitute a Great Filter are those that arise from technological discovery. It is not far-fetched to suppose that there might be some possible technology which is such that (a) virtually all suffi­ciently advanced civilizations eventually discover it and (b) its discovery leads almost universally to existential disaster.”\n\n## II. The Machines\n\n\n\nThe field of artificial intelligence was born in a fit of scientific optimism, in 1955, when a small group of researchers—three mathematicians and an I.B.M. programmer—drew up a proposal for a project at Dartmouth. “An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves,” they stated. “We think a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.”\n\n\n\nTheir optimism was understandable. Since the turn of the twentieth century, science had been advancing at a breakneck pace: the discovery of radioactivity quickly led to insights into the inner workings of the atom, and then to the development of controlled nuclear energy, and then to the warheads over Hiroshima and Nagasaki, and then to the H-bomb. This rush of discovery was reflected in fiction, too, in the work of Isaac Asimov, among others, who envisioned advanced civilizations inhabited by intelligent robots (each encoded with simple, ethical Laws of Robotics, to prevent it from causing harm). The year the scientists met at Dartmouth, Asimov published “The Last Question,” a story featuring a superintelligent A.I. that is continually “self-adjusting and self-correcting”—gaining knowledge as it helps human civilization expand throughout the universe. When the universe’s last stars start dying out, all humanity uploads itself into the A.I., and the device, achieving godhood, creates a new cosmos.\n\n\n\nScientists perceived the mechanics of intelligence—like those of the atom—as a source of huge potential, a great frontier. If the brain was merely a biological machine, there was no theoretical reason that it could not be replicated, or even surpassed, much the way a jet could outfly a falcon. Even before the Dartmouth conference, machines exceeded human ability in narrow domains like code-breaking. In 1951, Alan Turing argued that at some point computers would probably exceed the intellectual capacity of their inventors, and that “therefore we should have to expect the machines to take control.” Whether this would be good or bad he did not say. \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a057b86d47b169c7b9]||||||\n\n+++\n\n \n\n\n\nSix years later, Herbert Simon, one of the Dartmouth attendees, declared that machines would achieve human intelligence “in a visible future.” The crossing of such a threshold, he suspected, could be psychologically crushing, but he was on the whole optimistic. “We must also remain sensitive to the need to keep the computer’s goals attuned with our own,” he later said, but added, “I am not convinced that this will be difficult.” For other computer pioneers, the future appeared more ambivalent. Norbert Wiener, the father of cybernetics, argued that it would be difficult to manage powerful computers, or even to accurately predict their behavior. “Complete subservience and complete intelligence do not go together,” he said. Envisioning Sorcerer’s Apprentice scenarios, he predicted, “The future will be an ever more demanding struggle against the limitations of our intelligence, not a comfortable hammock in which we can lie down to be waited upon by our robot slaves.” \n\n\n\nIt was in this milieu that the “intelligence explosion” idea was first formally expressed by I. J. Good, a statistician who had worked with Turing. “An ultraintelligent machine could design even better machines,” he wrote. “There would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the _last_ invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. It is curious that this point is made so seldom outside of science fiction. It is sometimes worthwhile to take science fiction seriously.” \n\n\n\nThe scientists at Dartmouth recognized that success required answers to fundamental questions: What is intelligence? What is the mind? By 1965, the field had experimented with several models of problem solving: some were based on formal logic; some used heuristic reasoning; some, called “neural networks,” were inspired by the brain. With each, the scientists’ work indicated that A.I. systems could find their own solutions to problems. One algorithm proved numerous theorems in the classic text “Principia Mathematica,” and in one instance it did so more elegantly than the authors. A program designed to play checkers learned to beat its programmer. And yet, despite the great promise in these experiments, the challenges to creating an A.I. were forbidding. Programs that performed well in the laboratory were useless in everyday situations; a simple act like picking up a ball turned out to require an overwhelming number of computations. \n\n\n\nThe research fell into the first of several “A.I. winters.” As Bostrom notes in his book, “Among academics and their funders, ‘A.I.’ became an unwanted epithet.” Eventually, the researchers started to question the goal of building a mind altogether. Why not try instead to divide the problem into pieces? They began to limit their interests to specific cognitive functions: vision, say, or speech. Even in isolation, these functions would have value: a computer that could identify objects might not be an A.I., but it could help guide a forklift. As the research fragmented, the morass of technical problems made any questions about the consequences of success seem distant, even silly. \n\n\n\nUnexpectedly, by dismissing its founding goals, the field of A.I. created space for outsiders to imagine more freely what the technology might look like. Bostrom wrote his first paper on artificial superintelligence in the nineteen-nineties, envisioning it as potentially perilous but irresistible to both commerce and government. “If there is a way of guaranteeing that superior artificial intellects will never harm human beings, then such intellects will be created,” he argued. “If there is no way to have such a guarantee, then they will probably be created nevertheless.” His audience at the time was primarily other transhumanists. But the movement was maturing. In 2005, an organization called the Singularity Institute for Artificial Intelligence began to operate out of Silicon Valley; its primary founder, a former member of the Extropian discussion group, published a stream of literature on the dangers of A.I. That same year, the futurist and inventor Ray Kurzweil wrote “The Singularity Is Near,” a best-seller that prophesied a merging of man and machine in the foreseeable future. Bostrom created his institute at Oxford.\n\n\n\nThe two communities could not have been more different. The scientists, steeped in technical detail, were preoccupied with making devices that worked; the transhumanists, motivated by the hope of a utopian future, were asking, What would the ultimate impact of those devices be? In 2007, the Association for the Advancement of Artificial Intelligence—the most prominent professional organization for A.I. researchers—elected Eric Horvitz, a scientist from Microsoft, as its president. Until then, it had given virtually no attention to the ethical and social implications of the research, but Horvitz was open to the big questions. “It is hard to understand what success would mean for A.I.,” he told me. “I was friendly with Jack Good, who wrote that piece on superintelligence. I knew him as a creative, funny guy who referred to a lot of his ideas as P.B.I.s—partly baked ideas. And here is this piece of his being opened up outside the field as this Bible and studied with a silver pointer. Wouldn’t it be useful, I said, even if you thought these were crazy or low-probability scenarios, to find out: Can we be proactive, should there be some poor outcome for humanity?” \n\n\n\nHorvitz organized a meeting at the Asilomar Conference Grounds, in California, a place chosen for its symbolic value: biologists had gathered there in 1975 to discuss the hazards of their research in the age of modern genetics. He divided the researchers into groups. One studied short-term ramifications, like the possible use of A.I. to commit crimes; another considered long-term consequences. Mostly, there was skepticism about the intelligence-explosion idea, which assumed answers to many unresolved questions. No one fully understands what intelligence is, let alone how it might evolve in a machine. Can it grow as Good imagined, gaining I.Q. points like a rocketing stock price? If so, what would its upper limit be? And would its increase be merely a function of optimized software design, without the difficult process of acquiring knowledge through experience? Can software fundamentally rewrite itself without risking crippling breakdowns? No one knows. In the history of computer science, no programmer has created code that can substantially improve itself. \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a21f743c6ee49a53e4]||||||\n\n+++\n\n \n\n\n\nBut the notion of an intelligence explosion was also impossible to disprove. It was theoretically coherent, and it had even been attempted in limited ways. David McAllester, an A.I. researcher at the Toyota Technological Institute, affiliated with the University of Chicago, headed the long-term panel. The idea, he argued, was worth taking seriously. “I am uncomfortable saying that we are ninety-­nine per cent certain that we are safe for fifty years,” he told me. “That feels like hubris to me.” The group concluded that more technical work was needed before an evaluation of the dangers could be made, but it also hinted at a concern among panelists that the gathering was based on “a _perception_ of urgency”—generated largely by the transhumanists—and risked raising unfounded alarm. With A.I. seeming like a remote prospect, the researchers declared, attention was better spent on near-term concerns. Bart Selman, a professor at Cornell who co-­organized the panel, told me, “The mode was ‘This is interesting, but it’s all academic—it’s not going to happen.’&#160;”\n\n\n\nAt the time the A.I researchers met at Asilomar, Bostrom was grappling with an expansive book on existential risks. He had sketched out chapters on bioengineering and on nanotechnology, among other topics, but many of these problems came to seem less compelling, while his chapter on A.I. grew and grew. Eventually, he pasted the A.I. chapter into a new file, which became “Superintelligence.” \n\n\n\nThe book is its own elegant paradox: analytical in tone and often lucidly argued, yet punctuated by moments of messianic urgency. Some portions are so extravagantly speculative that it is hard to take them seriously. (“Suppose we could somehow establish that a certain future AI will have an IQ of 6,455: then what?”) But Bostrom is aware of the limits to his type of futurology. When he was a graduate student in London, thinking about how to maximize his ability to communicate, he pursued stand­­up comedy; he has a deadpan sense of humor, which can be found lightly buried among the book’s self-serious passages. “Many of the points made in this book are probably wrong,” he writes, with an endnote that leads to the line “I don’t know which ones.”\n\n\n\nBostrom prefers to act as a cartographer rather than a polemicist, but beneath his exhaustive mapping of scenarios one can sense an argument being built and perhaps a fear of being forthright about it. “Traditionally, this topic domain has been occupied by cranks,” he told me. “By popular media, by science fiction—or maybe by a retired physicist no longer able to do serious work, so he will write a popular book and pontificate. That is kind of the level of rigor that is the baseline. I think that a lot of reasons why there has not been more serious work in this area is that academics don’t want to be conflated with flaky, crackpot type of things. Futurists are a certain type.”\n\n\n\nThe book begins with an “unfinished” fable about a flock of sparrows that decide to raise an owl to protect and advise them. They go looking for an owl egg to steal and bring back to their tree, but, because they believe their search will be so difficult, they postpone studying how to domesticate owls until they succeed. Bostrom concludes, “It is not known how the story ends.”\n\n\n\nThe parable is his way of introducing the book’s core question: Will an A.I., if realized, use its vast capability in a way that is beyond human control? One way to think about the concern is to begin with the familiar. Bos­trom writes, “Artificial intelligence already outperforms human intelligence in many domains.” The examples range from chess to Scrabble. One program from 1981, called Eurisko, was designed to teach itself a naval role-playing game. After playing ten thousand matches, it arrived at a morally grotesque strategy: to field thousands of small, immobile ships, the vast majority of which were intended as cannon fodder. In a national tournament, Eurisko demolished its human opponents, who insisted that the game’s rules be changed. The following year, Eurisko won again—by forcing its damaged ships to sink themselves. \n\n\n\nThe program was by no means superintelligent. But Bostrom’s book essentially asks: What if it were? Assume that it has a broad ability to consider problems and that it has access to the Internet. It could read and acquire general knowledge and communicate with people seamlessly online. It could conduct experiments, either virtually or by tinkering with networked infrastructure. Given even the most benign objective—to win a game—such a system, Bostrom argues, might develop “instrumental goals”: gather resources, or invent technology, or take steps to insure that it cannot be turned off, in the process paying as much heed to human life as humans do to ants. \n\n\n\nIn people, intelligence is inseparable from consciousness, emotional and social awareness, the complex interaction of mind and body. An A.I. need not have any such attributes. Bostrom believes that machine intelligences—no matter how flexible in their tactics—will likely be rigidly fixated on their ultimate goals. How, then, to create a machine that respects the nuances of social cues? That adheres to ethical norms, even at the expense of its goals? No one has a coherent solution. It is hard enough to reliably inculcate such behavior in people. \n\n\n\nIn science fiction, superintelligent computers that run amok are often circumvented at the last minute; think of WOPR, the computer in “WarGames,” which was stopped just short of triggering nuclear war, or HAL 9000, which was reduced to helplessly singing while it watched itself get dismantled. For Bos­trom, this strains credulity. Whether out of a desire to consider the far ends of risk or out of transhumanist longings, he often ascribes nearly divine abilities to machines, as if to ask: Can a digital god really be contained? He imagines machines so intelligent that merely by inspecting their own code they can extrapolate the nature of the universe and of human society, and in this way outsmart any effort to contain them. “Is it possible to build machines that are not like agents—goal-pursuing, autonomous, artificial intelligences?” he asked me. “Maybe you can design something more like an oracle that can only answer yes or no. Would that be safer? It is not so clear. There might be agent-like processes within it.” Asking a simple question—“Is it possible to convert a DeLorean into a time machine and travel to 1955?”—might trigger a cascade of action as the device tests hypotheses. What if, working through a police computer, it impounds a DeLorean that happens to be convenient to a clock tower? “In fairy tales, you have genies who grant wishes,” Bostrom said. “Almost universally, the moral of those is that if you are not extremely careful what you wish for, then what seems like it should be a great blessing turns out to be a curse.”\n\n\n\nBostrom worries that solving the “control problem”—insuring that a superintelligent machine does what humans want it to do—will require more time than solving A.I. does. The intelligence explosion is not the only way that a superintelligence might be created suddenly. Bostrom once sketched out a decades-long process, in which researchers arduously improved their systems to equal the intelligence of a mouse, then a chimp, then—after incredible labor—the village idiot. “The difference between village idiot and genius-­level intelligence might be trivial from the point of view of how hard it is to replicate the same functionality in a machine,” he said. “The brain of the village idiot and the brain of a scientific genius are almost identical. So we might very well see relatively slow and incremental progress that doesn’t really raise any alarm bells until we are just one step away from something that is radically superintelligent.”\n\n\n\nTo a large degree, Bostrom’s concerns turn on a simple question of timing: Can breakthroughs be predicted? “It is ridiculous to talk about such things so early—A.I. is eons away,” Edward Feigenbaum, an emeritus professor at Stanford University, told me. The researcher Oren Etzioni, who used the term “Frankenstein complex” to dismiss the “dystopian vision of A.I.,” concedes Bostrom’s overarching point: that the field must one day confront profound philosophical questions. Decades ago, he explored them himself, in a brief paper, but concluded that the problem was too remote to think about productively. “Once, Nick Bostrom gave a talk, and I gave a little counterpoint,” he told me. “A lot of the disagreements come down to what time scale you are thinking about. Nobody responsible would say you will see anything remotely like A.I. in the next five to ten years. And I think most computer scientists would say, ‘In a million years—we don’t see why it shouldn’t happen.’ So now the question is: What is the rate of progress? There are a lot of people who will ask: Is it _possible_ we are wrong? Yes. I am not going to rule it out. I am going to say, ‘I am a scientist. Show me the evidence.’&#160;”\n\n\n\nThe history of science is an uneven guide to the question: How close are we? There has been no shortage of unfulfilled promises. But there are also plenty of examples of startling nearsightedness, a pattern that Arthur C. Clarke enshrined as Clarke’s First Law: “When a distinguished but elderly scientist states that something is possible, he is almost certainly right. When he states that something is impossible, he is very probably wrong.” After the electron was discovered, at Cambridge, in 1897, physicists at an annual dinner toasted, “To the electron: may it never be of use to anybody.” Lord Kelvin famously declared, just eight years before the Wright brothers launched from Kitty Hawk, that heavier-than-air flight was impossible. \n\n\n\nStuart Russell, the co-author of the textbook “Artificial Intelligence: A Modern Approach” and one of Bostrom’s most vocal supporters in A.I., told me that he had been studying the physics community during the advent of nuclear weapons. At the turn of the twentieth century, Ernest Rutherford discovered that heavy elements produced radiation by atomic decay, confirming that vast reservoirs of energy were stored in the atom. Rutherford believed that the energy could not be harnessed, and in 1933 he proclaimed, “Anyone who expects a source of power from the transformation of these atoms is talking moonshine.” The next day, a former student of Einstein’s named Leo Szilard read the comment in the papers. Irritated, he took a walk, and the idea of a nuclear chain reaction occurred to him. He visited Rutherford to discuss it, but Rutherford threw him out. Einstein, too, was skeptical about nuclear energy—splitting atoms at will, he said, was “like shooting birds in the dark in a country where there are only a few birds.” A decade later, Szilard’s insight was used to build the bomb.\n\n\n\nRussell now relays the story to A.I. researchers as a cautionary tale. “There will have to be more breakthroughs to get to A.I., but, as Szilard illustrated, those can happen overnight,” he told me. “People are putting billions of dollars into achieving those breakthroughs. As the debate stands, Bostrom and others have said, ‘If we achieve superintelligence, here are some of the problems that might arise.’ As far as I know, no one has proved why those are not real.”\n\n## III. Mission Control\n\n\n\nThe offices of the Future of Humanity Institute have a hybrid atmosphere: part physics lab, part college dorm room. There are whiteboards covered with mathematical notation and technical glyphs; there are posters of “Brave New World” and HAL 9000. There is also art work by Nick Bostrom. One afternoon, he guided me to one of his pieces, “At Sea,” a digital collage that he had printed out and then drawn on. “It is a bit damaged, but the good thing about digital is that you can re-instantiate it,” he said. At the center was a pale man, nearly an apparition, clinging to a barrel in an inky-black ocean. “It is an existentialist vibe. You are hanging on for as long as you can. When you get tired, you sink, and become fish food—or maybe a current will take him to land. We don’t know.” \n\n\n\nDespite the time he spends going to conferences and raising money, Bostrom attends to many details at the institute. “We needed a logo when we started,” he told me. “We went to this online site where you could buy the work of freelance artists. If you sat down and tried to make the ugliest logo, you couldn’t come close. Then we hired a designer, who made a blurry figure of a person. We showed it to someone here, who said it looked like a toilet sign. As soon as she said it, I thought, Oh, my God, we almost adopted a toilet sign as our logo. So I mucked around a bit and came up with a black diamond. You have the black monolith from ‘2001.’ Standing on its corner, it indicates instability. Also, there is a limit to how ugly a black square can be.” \n\n\n\nThe institute shares office space with the Centre for Effective Altruism, and both organizations intersect with a social movement that promotes pure rationality as a guide to moral action. Toby Ord, a philosopher who works with both, told me that Bostrom often pops into his office at the end of the day, poses a problem, then leaves him pondering it for the night. Among the first of Bostrom’s questions was this: If the universe turns out to contain an infinite number of beings, then how could any single person’s action affect the cosmic balance of suffering and happiness? After lengthy discussions, they left the paradox unresolved. “My main thinking is that we can sort it out later,” Ord told me.  \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a47206a168e2d1782f]||||||\n\n+++\n\n \n\n\n\nWhen I asked Bostrom if I could observe a discussion at the institute, he seemed reluctant; it was hard to judge whether he was concerned that my presence would interfere or that unfiltered talk of, say, engineered pathogens might inspire criminals. (“At some point, one gets into the realm of information hazard,” he hinted.) Eventually, he let me observe a session in the Petrov Room involving half a dozen staff members. The key question under discussion was whether a global catastrophe, on the order of a continent-wide famine, could trigger a series of geopolitical events that would result in human extinction—and whether that meant that a merely catastrophic risk could therefore be taken as seriously as an existential risk. Bostrom, wearing a gray hoodie over a blue button-­down, organized the problem on a whiteboard with visible pleasure. Anders Sandberg told me that he once spent days with Bostrom working through such a problem, distilling a complex argument to its essence. “He had to _refine_ it,” he said. “We had a lot of schemes on the whiteboard that gradually were simplified to one box and three arrows.” \n\n\n\nFor anyone in the business of publicizing existential risk, 2015 began as a good year. Other institutes devoted to these issues had started to find their voice, bringing an additional gloss of respectability to the ideas in Bostrom’s book. The people weighing in now were no longer just former Extropians. They were credentialled, like Lord Martin Rees, an astrophysicist and the co-founder of Cambridge’s Centre for the Study of Existential Risk. In January, he wrote of A.I., in the _Evening Standard_, “We don’t know where the boundary lies between what may happen and what will remain science fiction.”\n\n\n\nRees’s counterpart at the Future of Life Institute, the M.I.T. physicist Max Tegmark, hosted a closed-door meeting in Puerto Rico, to try to make sense of the long-term trajectory of the research. Bostrom flew down, joining a mix of A.I. practitioners, legal scholars, and, for lack of a better term, members of the “A.I. safety” community. “These are not people who are usually in the same room,” Tegmark told me. “Someone advised me to put Valium in people’s drinks so nobody got into fistfights. But, by the time Nick’s session started, people were ready to listen to each other.” Questions that had seemed fanciful to researchers only seven years earlier were beginning to look as though they might be worth reconsidering. Whereas the Asilomar meeting concluded on a note of skepticism about the validity of the whole endeavor, the Puerto Rico conference resulted in an open letter, signed by many prominent researchers, that called for more research to insure that A.I. would be “robust and beneficial.” \n\n\n\nBetween the two conferences, the field had experienced a revolution, built on an approach called deep learning—a type of neural network that can discern complex patterns in huge quantities of data. For de­c­ades, researchers, hampered by the limits of their hardware, struggled to get the technique to work well. But, beginning in 2010, the increasing availability of Big Data and cheap, powerful video-­game processors had a dramatic effect on performance. Without any profound theoretical breakthrough, deep learning suddenly offered breathtaking advances. “I have been talking to quite a few contemporaries,” Stuart Russell told me. “Pretty much everyone sees examples of progress they just didn’t expect.” He cited a YouTube clip of a four-legged robot: one of its designers tries to kick it over, but it quickly regains its balance, scrambling with uncanny naturalness. “A problem that had been viewed as very difficult, where progress was slow and incremental, was all of a sudden done. Locomotion: done.”\n\n\n\nIn an array of fields—speech processing, face recognition, language translation—the approach was ascendant. Researchers working on computer vision had spent years to get systems to identify objects. In almost no time, the deep-learning networks crushed their records. In one common test, using a database called ImageNet, humans identify photographs with a five-per-cent error rate; Google’s network operates at 4.8 per cent. A.I. systems can differentiate a Pembroke Welsh Corgi from a Cardigan Welsh Corgi. \n\n\n\nLast October, Tomaso Poggio, an M.I.T. researcher, gave a skeptical interview. “The ability to describe the content of an image would be one of the most intellectually challenging things of all for a machine to do,” he said. “We will need another cycle of basic research to solve this kind of question.” The cycle, he predicted, would take at least twenty years. A month later, Google announced that its deep-learning network could analyze an image and offer a caption of what it saw: “Two pizzas sitting on top of a stove top,” or “People shopping at an outdoor market.” When I asked Poggio about the results, he dismissed them as automatic associations between objects and language; the system did not _understand_ what it saw. “Maybe human intelligence is the same thing, in which case I am wrong, or not, in which case I was right,” he told me. “How do you decide?”\n\n\n\nA respected minority of A.I. researchers began to wonder: If increasingly powerful hardware could facilitate the deep-learning revolution, would it make other long-shelved A.I. principles viable? “Suppose the brain is just a million different evolutionarily developed hacks: one for smell, one for recognizing faces, one for how you recognize animals,” Tom Mitchell, who holds a chair in machine learning at Carnegie Mellon, told me. “If that is what underlies intelligence, then I think we are far, far from getting there—because we don’t have many of those hacks. On the other hand, suppose that what underlies intelligence are twenty-three general mechanisms, and when you put them together you get synergy, and it works. We now have systems that can do a pretty good job with computer vision—and it turns out that we didn’t have to construct a million hacks. So part of the uncertainty is: if we do not need a million different hacks, then will we find the right twenty-­three fundamental generic methods?” He paused. “I no longer have the feeling, which I had twenty-five years ago, that there are gaping holes. I know we don’t have a good architecture to assemble the ideas, but it is not obvious to me that we are missing components.”  \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a557b86d47b169c7c1]||||||\n\n+++\n\n \n\n\n\nBostrom noticed the shift in attitude. He recently conducted a poll of A.I. researchers to gauge their sense of progress, and in Puerto Rico a survey gathered opinions on how long it would be until an artificial intelligence could reason indistinguishably from a human being. Like Bostrom, the engineers are often careful to express their views as probabilities, rather than as facts. Richard Sutton, a Canadian computer scientist whose work has earned tens of thousands of scholarly citations, gives a range of outcomes: there is a ten-per-cent chance that A.I. will never be achieved, but a twenty-five-per-cent chance that it will arrive by 2030. The median response in Bostrom’s poll gives a fifty-fifty chance that human-level A.I. would be attained by 2050. These surveys are unscientific, but he is confident enough to offer an interpretive assumption: “It is not a ridiculous prospect to take seriously the possibility that it can happen in the lifetime of people alive today.”\n\n\n\nOn my last day in Oxford, I walked with Bostrom across town. He was racing to catch a train to London, to speak at the Royal Society, one of the world’s oldest scientific institutions. His spirits were high. The gulf between the transhumanists and the scientific community was slowly shrinking. Elon Musk had pledged ten million dollars in grants for academics seeking to investigate A.I. safety, and, rather than mock him, researchers applied for the money; Bostrom’s institute was helping to evaluate the proposals. “Right now, there is a lot of interest,” he told me. “But then there were all these long years when nobody else seemed to pay attention at all. I am not sure which is the less abnormal condition.” \n\n\n\nThere were clear limits to that interest. To publicly stake out a position in the middle of the debate was difficult, not least because of the polarized atmosphere Bostrom’s book had helped to create. Even though a growing number of researchers were beginning to suspect that profound questions loomed, and that they might be worth addressing now, it did not mean that they believed A.I. would lead inevitably to an existential demise or a techno-utopia. Most of them were engaged with more immediate problems: privacy, unemployment, weaponry, driverless cars running amok. When I asked Bostrom about this pragmatic ethical awakening, he reacted with dismay. “My fear is that it would swallow up the concerns for the longer term,” he said. “On the other hand, yes, maybe it is useful to build bridges to these different communities. Kind of makes the issue part of a larger continuum of things to work on.”\n\n\n\nAt the Royal Society, Bostrom took a seat at the back of a large hall. As he crossed his legs, I noticed a thin leather band around his ankle. A metal buckle was engraved with contact information for Alcor, a cryonics facility in Arizona, where Bostrom is a fee-paying member. Within hours of his death, Alcor will take custody of his body and maintain it in a giant steel bottle flooded with liquid nitrogen, in the hope that one day technology will allow him to be revived, or to have his mind uploaded into a computer. When he signed up, two other colleagues at the institute joined him. “My background is transhumanism,” he once reminded me. “The character of that is gung-ho techno-cheerleading, bring it on now, where are my life-­extension pills.” \n\n\n\nThe hall was packed with some of the most technically sophisticated researchers in A.I.—not necessarily Bostrom’s people—and when he spoke he began by trying to assure them that his concern was not out of Ludditism. “It would be tragic if machine intelligence were never developed to its full capacity,” he said. “I think this is ultimately the key, or the portal, we have to pass through to realize the full dimension of humanity’s long-term potential.” But, even as he avoided talk of existential risk, he pressed his audience to consider the danger of building an A.I. without regarding its ethical design. \n\n\n\nAn attendee raised his hand to object. “We can’t control basic computer worms,” he said. “The A.I. that will happen is going to be a highly adaptive, emergent capability, and highly distributed. We will be able to work with it—_for_ it—not necessarily contain it.” \n\n\n\n“I guess I am a little frustrated,” Bos­trom responded. “People tend to fall into two camps. On one hand, there are those, like yourself, who think it is probably hopeless. The other camp thinks it is easy enough that it will be solved automatically. And both of these have in common the implication that we don’t have to make any effort now.”\n\n\n\nFor the rest of the day, engineers presented their work at the lectern, each promising a glimpse of the future—robot vision, quantum computers, algorithms called “thought vectors.” Early in Bostrom’s career, he predicted that cascading economic demand for an A.I. would build up across the fields of medicine, entertainment, finance, and defense. As the technology became useful, that demand would only grow. “If you make a one-per-cent improvement to something—say, an algorithm that recommends books on Amazon—there is a lot of value there,” Bostrom told me. “Once every improvement potentially has enormous economic benefit, that promotes effort to make more improvements.” \n\n\n\nMany of the world’s largest tech companies are now locked in an A.I. arms race, purchasing other companies and opening specialized units to advance the technology. Industry is vacuuming up Ph.D.s so quickly that people in the field worry there will no longer be top talent in academia. After decades of pursuing narrow forms of A.I., researchers are seeking to integrate them into systems that resemble a general intellect. Since I.B.M.’s Watson won “Jeopardy,” the company has committed more than a billion dollars to develop it, and is reorienting its business around “cognitive systems.” One senior I.B.M. executive declared, “The separation between human and machine is going to blur in a very fundamental way.” \n\n\n\nAt the Royal Society, a contingent of researchers from Google occupied a privileged place; they likely had more resources at their disposal than anyone else in the room. Early on, Google’s founders, Larry Page and Sergey Brin, understood that the company’s mission required solving fundamental A.I. problems. Page has said that he believes the ideal system would understand questions, even anticipate them, and produce responses in conversational language. Google scientists often invoke the computer in “Star Trek” as a model.  \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a757b86d47b169c7c3]||||||\n\n+++\n\n \n\n\n\nIn recent years, Google has purchased seven robotics companies and several firms specializing in machine intelligence; it may now employ the world’s largest contingent of Ph.D.s in deep learning. Perhaps the most interesting acquisition is a British company called DeepMind, started in 2011 to build a general artificial intelligence. Its founders had made an early bet on deep learning, and sought to combine it with other A.I. mechanisms in a cohesive architecture. In 2013, they published the results of a test in which their system played seven classic Atari games, with no instruction other than to improve its score. For many people in A.I., the importance of the results was immediately evident. I.B.M.’s chess program had defeated Garry Kasparov, but it could not beat a three-year-old at tic-tac-toe. In six games, DeepMind’s system outperformed all previous algorithms; in three it was superhuman. In a boxing game, it learned to pin down its opponent and subdue him with a barrage of punches.\n\n\n\nWeeks after the results were released, Google bought the company, reportedly for half a billion dollars. DeepMind placed two unusual conditions on the deal: its work could never be used for espionage or defense purposes, and an ethics board would oversee the research as it drew closer to achieving A.I. Anders Sandberg had told me, “We are happy that they are among the most likely to do it. They recognize there are some problems.”\n\n\n\nDeepMind’s chief founder, Demis Hassabis, described his company to the audience at the Royal Society as an “Apollo Program” with a two-part mission: “Step one, solve intelligence. Step two, use it to solve everything else.” Since the test in 2013, his system had aced more than a dozen other Atari titles. Hassabis demonstrated an unpublished trial using a three-dimensional driving game, in which it had quickly outperformed the game’s automated drivers. The plan was to test it in increasingly complex virtual environments and, eventually, in the real world. The patent lists a range of uses, from finance to robotics. \n\n\n\nHassabis was clear about the challenges. DeepMind’s system still fails hopelessly at tasks that require long-range planning, knowledge about the world, or the ability to defer rewards—things that a five-year-old child might be expected to handle. The company is working to give the algorithm conceptual understanding and the capability of transfer learning, which allows humans to apply lessons from one situation to another. These are not easy problems. But DeepMind has more than a hundred Ph.D.s to work on them, and the rewards could be immense. Hassabis spoke of building artificial scientists to resolve climate change, disease, poverty. “Even with the smartest set of humans on the planet working on these problems, these systems might be so complex that it is difficult for individual humans, scientific experts,” he said. “If we can crack what intelligence is, then we can use it to help us solve all these other problems.” He, too, believes that A.I. is a gateway to expanded human potential. \n\n\n\nThe keynote speaker at the Royal Society was another Google employee: Geoffrey Hinton, who for decades has been a central figure in developing deep learning. As the conference wound down, I spotted him chatting with Bostrom in the middle of a scrum of researchers. Hinton was saying that he did not expect A.I. to be achieved for decades. “No sooner than 2070,” he said. “I am in the camp that is hopeless.”\n\n\n\n“In that you think it will not be a cause for good?” Bostrom asked. \n\n\n\n“I think political systems will use it to terrorize people,” Hinton said. Already, he believed, agencies like the N.S.A. were attempting to abuse similar technology. \n\n\n\n“Then why are you doing the research?” Bostrom asked.\n\n\n\n“I could give you the usual arguments,” Hinton said. “But the truth is that the prospect of discovery is too _sweet_.” He smiled awkwardly, the word hanging in the air—an echo of Oppenheimer, who famously said of the bomb, “When you see something that is technically sweet, you go ahead and do it, and you argue about what to do about it only after you have had your technical success.” \n\n\n\nAs the scientists retreated to tables set up for refreshments, I asked Hinton if he believed an A.I. could be controlled. “That is like asking if a child can control his parents,” he said. “It can happen with a baby and a mother—there is biological hardwiring—but there is not a good track record of less intelligent things controlling things of greater intelligence.” He looked as if he might elaborate. Then a scientist called out, “Let’s all get drinks!”\n\n\n\nBostrom had little interest in the cocktail party. He shook a few hands, then headed for St. James’s Park, a public garden that extends from the gates of Buckingham Palace through central London. The world appeared in splendorous analog: sunlight over trees, duck ponds, children and grandparents feeding birds. The spot had been a park for hundreds of years, and the vista seemed timeless. Yet, during the past millennium, the grounds had also been a marsh, a leper hospital, a deer sanctuary, and royal gardens. It seemed plausible that, a thousand years from now, digital posthumans, regarding it as wasted space, would tear it up, replace the landscaping with computer banks, and erect a vast virtual idyll.\n\n\n\nBostrom’s pace settled into its natural quickness as we circled the park. He talked about his family; he would be seeing his wife and son soon. He was reading widely: history, psychology, economics. He was learning to code. He was thinking about expanding his institute. Although he did not know it then, F.H.I. was about to receive one and a half million dollars from Elon Musk, to create a unit that would craft social policies informed by some of Bostrom’s theories. He would need to hire people. He was also giving thought to the framing of his message. “A lot more is said about the risks than the upsides, but that is not necessarily because the upside is not there,” he told me. “There is just more to be said about the risk—and maybe more use in describing the pitfalls, so we know how to steer around them—than spending time now figuring out the details of how we are going to furnish the great palace a thousand years from now.” \n\n+++inset-left\n\n[#cartoon: \u002Fcartoon\u002F593b64a96f669264efc139ef]||||||\n\n+++\n\n \n\n\n\nWe passed a fountain, near a cluster of rocks engineered to give ducks a resting place. Bostrom, in his forties, must soon contend with physical decline, and he spoke with annoyance of the first glimmers of mortality. Even though he is an Alcor member, there is no guarantee that cryonics will work. Perhaps the most radical of his visions is that superintelligent A.I. will hasten the uploading of minds—what he calls “whole-brain emulations”—technology that might not be possible for centuries, if at all. Bostrom, in his most hopeful mode, imagines emulations not only as reproductions of the original intellect “with memory and personality intact”—a soul in the machine—but as minds expandable in countless ways. “We live for seven decades, and we have three-pound lumps of cheesy matter to think with, but to me it is plausible that there could be extremely valuable mental states outside this little particular set of possibilities that might be much better,” he told me. \n\n\n\nIn his book, Bostrom considers a distant future in which trillions of digital minds merge into an enormous cognitive cyber-soup. “Whether the set of extremely positive posthuman modes of being would include some kind of dissolved bouillon, there is some uncertainty,” he said. “If you look at religious views, there are many where merging with something greater is a form of heaven, being in the presence of this enormous beauty and goodness. In many traditions, the best possible state does not involve being a little individual pursuing goals. But it is hard to get a grasp of what would be going on in that soup. Maybe some soups would not be preferable as a long-term outcome. I don’t know.” He stopped and looked ahead. “What I want to avoid is to think from our parochial 2015 view—from my own limited life experience, my own limited brain—and super-confidentially postulate what is the best form for civilization a billion years from now, when you could have brains the size of planets and billion-year life spans. It seems unlikely that we will figure out some detailed blueprint for utopia. What if the great apes had asked whether they should evolve into _Homo sapiens_—pros and cons—and they had listed, on the pro side, ‘Oh, we could have a lot of bananas if we became human’? Well, we can have unlimited bananas now, but there is more to the human condition than that.”&#160;♦\n\n\n\n_Illustration by Todd St. John\u002FCoding by Jono Brandel._","canonicalUrl":"https:\u002F\u002Fwww.newyorker.com\u002Fmagazine\u002F2015\u002F11\u002F23\u002Fdoomsday-invention-artificial-intelligence-nick-bostrom","categories":{"functional-tags":[{"id":"5db369e24ff58c0008943ef8","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"_override_all","parent":null,"photos":{},"root":[],"slug":"override-all"}],"tags":[{"id":"5c2e1c7922d4972cd5b8328f","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Artificial Intelligence (A.I.)","parent":null,"photos":{},"root":[],"slug":"artificial-intelligence-ai"},{"id":"5c2e1c782bfcc72cd92d0523","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"category_science_tech","parent":null,"photos":{},"root":[],"slug":"category-science-tech"},{"id":"5c2e1cc5b75f002c8941e4e2","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Philosophers","parent":null,"photos":{},"root":[],"slug":"philosophers"}],"sections":[{"id":"5907ef12019dfc3494e9c8f2","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"A Reporter at Large","parent":null,"photos":{},"root":[],"slug":"a-reporter-at-large"}]},"channel":"Magazine","contentSource":"magazine","contributors":{"author":[{"id":"590a0325fba4e90c8d8d92b1","modelName":"contributor","collection":"contributors","bio":"Raffi Khatchadourian has been a staff writer at *The New Yorker* since 2008. He covers a wide range of topics, including science, art, politics, foreign affairs, and national security. His articles have been anthologized in “Best American Sports Writing” and in “Best American Nonrequired Reading.” On two occasions, Khatchadourian’s work was nominated for National Magazine Awards—once for his profile of an Al Qaeda propagandist, titled “[Azzam the American](https:\u002F\u002Fwww.newyorker.com\u002Fmagazine\u002F2007\u002F01\u002F22\u002Fazzam-the-american),” and a second time, in collaboration with a *New Yorker* multimedia team, for “[Secrets of Edgewood](https:\u002F\u002Fwww.newyorker.com\u002Fnews\u002Fnews-desk\u002Fsecrets-of-edgewood),” an investigation into Cold War psychochemical experiments. His work has also been short-listed for Overseas Press Club and James Beard Foundation awards and for the Livingston Award. His verified Twitter account, linked above, can be used to validate his identity. His public P.G.P. encryption key can be found [here](https:\u002F\u002Fpgp.mit.edu\u002Fpks\u002Flookup?op=get&search=0x0D056F393D907157).  ","canonicalUrl":"http:\u002F\u002Fwww.newyorker.com\u002Fcontributors\u002Fraffi-khatchadourian","email":"","name":"Raffi Khatchadourian","socialMedia":[{"network":"Twitter","handle":"raffiwriter"}],"title":"Raffi Khatchadourian became a staff writer at The New Yorker in 2008."}]},"dek":"Will artificial intelligence bring us utopia or destruction?","hed":"The Doomsday Invention","galleries":{},"inlineEmbeds":[],"issueDate":"November 23, 2015","ledeCaption":"","modifiedAt":"2019-10-30T17:34:59.498Z","photos":{"tout":[{"id":"590971f5ebe912338a377328","modelName":"photo","collection":"photos","aspectRatios":{"2:1":{"width":2440,"height":1220,"override":false,"modifications":{"crop":{"x":62,"y":779,"height":1220,"width":2440}},"duration":null},"2:2":{"width":2000,"height":2000,"override":false,"modifications":{"crop":{"height":2000,"width":2000,"x":280,"y":0}},"duration":null},"16:9":{"width":2560,"height":1440,"override":false,"modifications":{"crop":{"x":0,"y":559,"height":1440,"width":2560}},"duration":null},"4:3":{"width":2560,"height":1920,"override":false,"modifications":{"crop":{"x":0,"y":79,"height":1920,"width":2560}},"duration":null},"1:1":{"width":2000,"height":2000,"override":false,"modifications":{"crop":{"x":276,"y":0,"height":2000,"width":2000}},"duration":null},"master":{"format":"JPEG","url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2017\u002F05\u002F03\u002F590971f4ebe912338a377327_151123_r27342.jpg","width":2560,"height":2000,"duration":null}},"caption":"Nick Bostrom, a philosopher focussed on A.I. risks, says, “The very long-term future of humanity may be relatively easy to predict.”","altText":"An animation of floating, 3-D puzzle pieces","credit":"Illustration by Todd St. John","filename":"151123_r27342.jpg","revision":6,"tags":[],"title":"151123_r27342"}]},"promoDek":"","promoHed":"","pubDate":"2015-11-16T04:00:00.000Z","related":[],"rubric":"","seoDescription":"Raffi Khatchadourian on Nick Bostrom, an Oxford philosopher who asks whether inventing artificial intelligence will bring us utopia or destruction.","seoTitle":"The Philosopher of Doomsday","socialDescription":"Will artificial intelligence bring us utopia or destruction?","socialTitle":"The Doomsday Invention","subChannel":"A Reporter at Large","tags":["_wordpress_id:3135335","_page_numbers:064-079","_migration_id:151123fa_fact_khatchadourian","_serial_number:TNY_LIBRY_000082322","_stackname:2100_dept_khatchadourian_151123","Artificial Intelligence (A.I.)","category_science_tech","Philosophers","_override_all"],"template":"single-column","url":"magazine\u002F2015\u002F11\u002F23\u002Fdoomsday-invention-artificial-intelligence-nick-bostrom","videos":{},"magazineStartPage":64},{"id":"5911cbfee168895225c1e55c","modelName":"article","collection":"articles","body":"-=-=-=-\n\nThere are many accounts of the genesis of Watson. The most popular, which is not necessarily the most accurate—and this is the sort of problem that Watson himself often stumbled on—begins in 2004, at a steakhouse near Poughkeepsie. One evening, an I.B.M. executive named Charles Lickel was having dinner there when he noticed that the tables around him had suddenly emptied out. Instead of finishing their sirloins, his fellow-diners had rushed to the bar to watch “Jeopardy!” This was deep into Ken Jennings’s seventy-four-game winning streak, and the crowd around the TV was rapt. Not long afterward, Lickel attended a brainstorming session in which participants were asked to come up with I.B.M.’s next “grand challenge.” The firm, he suggested, should take on Jennings.\n\n\n\n\n\nI.B.M. had already fulfilled a similar “grand challenge” seven years earlier, with Deep Blue. The machine had bested Garry Kasparov, then the reigning world chess champion, in a six-game match. To most people, beating Kasparov at chess would seem a far more impressive feat than coming up with “Famous First Names,” say, or “State Birds.” But chess is a game of strictly defined rules. The open-endedness of “Jeopardy!”—indeed, its very goofiness—made it, for a machine, much more daunting.\n\n\n\nLickel’s idea was batted around, rejected, and finally resurrected. In 2006, the task of building an automated “Jeopardy!” champion was assigned to a team working on question-answering technology, or QA. As Stephen Baker recounts in his book about the project, “Final Jeopardy,” progress was, at first, slow. Consider the following (actual) “Jeopardy!” clue: “In 1984, his grandson succeeded his daughter to become his country’s Prime Minister.” A person can quickly grasp that the clue points to the patriarch of a political family and, with luck, summon up “Who is Nehru?” For a computer, the sentence is a quagmire. Is what’s being sought a name? If so, is it the name of the grandson, the daughter, or the Prime Minister? Or is the question about geography or history?\n\n\n\nWatson—basically a collection of processing cores—could be loaded with whole Wikipedias’ worth of information. But just to begin to search this enormous database Watson had to run through dozens of complicated algorithms, which his programmers referred to as his “parsing and semantic analysis suite.” This process yielded hundreds of “hypotheses” that could then be investigated.\n\n\n\nAfter a year, many problems with Watson had been solved, but not the essential one. The computer took hours to generate answers that Jennings could find in an instant.\n\n\n\nA year turned into two and then three. Watson’s hardware was upgraded. Benefitting from algorithms that allowed him to learn from his own mistakes, he became more proficient at parsing questions and judging the quality of potential answers. In 2009, I.B.M. began to test the machine against former, sub-Jennings “Jeopardy!” contestants. Watson defeated some, lost to others, and occasionally embarrassed his creators. In one round, in response to a question about nineteenth-century British literature, the computer proposed the eighties pop duo Pet Shop Boys when the answer was Oliver Twist. In another round, under the category “Just Say No,” Watson offered “What is fuck?” when the right response was “What is _nein_?”\n\n\n\nI.B.M.’s aspirations for Watson went way beyond game shows. A computer that could cope with the messiness and the complexity of English could transform the tech world; one that could improve his own performance in the process could upend nearly everything else. Firms like Google, Microsoft, and Amazon were competing with I.B.M. to dominate the era of intelligent machines, and they continue to do so. For the companies involved, hundreds of billions of dollars are at stake, and the same could also be said for the rest of us. What business will want to hire a messy, complex carbon-based life form when a software tweak can get the job done just as well?\n\n\n\nKen Jennings, who might be described as the first person to be rendered redundant by Watson, couldn’t resist a dig at his rival when the two finally, as it were, faced off. In January, 2011, Jennings and another former champion, Brad Rutter, played a two-game match against the computer, which was filmed in a single day. Heading into the final “Final Jeopardy!,” the humans were so far behind that, for all intents and purposes, they were finished. All three contestants arrived at the correct response to the clue, which featured an obscure work of geography that inspired a nineteenth-century novelist. Beneath his answer—“Who is Bram Stoker?”—Jennings added a message: “I for one welcome our new computer overlords.”\n\n\n\n-=-=-=-\n\nHow long will it be before you, too, lose your job to a computer? This question is taken up by a number of recent books, with titles that read like variations on a theme: “The Industries of the Future,” “The Future of the Professions,” “Inventing the Future.” Although the authors of these works are employed in disparate fields—law, finance, political theory—they arrive at more or less the same conclusion. How long? Not long.\n\n\n\n\n\n“Could another person learn to do your job by studying a detailed record of everything you’ve done in the past?” Martin Ford, a software developer, asks early on in “Rise of the Robots: Technology and the Threat of a Jobless Future” (Basic Books). “Or could someone become proficient by repeating the tasks you’ve already completed, in the way that a student might take practice tests to prepare for an exam? If so, then there’s a good chance that an algorithm may someday be able to learn to do much, or all, of your job.”\n\n\n\nLater, Ford notes, “A computer doesn’t need to replicate the entire spectrum of your intellectual capability in order to displace you from your job; it only needs to do the specific things you are paid to do.” He cites a 2013 study by researchers at Oxford, which concluded that nearly half of all occupations in the United States are “potentially automatable,” perhaps within “a decade or two.” (“Even the work of software engineers may soon largely be computerisable,” the study observed. )\n\n\n\nThe “threat of a jobless future” is, of course, an old one, almost as old as technology. The first, rudimentary knitting machine, known as a “stocking frame,” was invented in the late sixteenth century by a clergyman named William Lee. Seeking a patent for his invention, Lee demonstrated the machine for Elizabeth I. Concerned about throwing hand-knitters out of work, she refused to grant one. In the early nineteenth century, a more sophisticated version of the stocking frame became the focus of the Luddites’ rage; in towns like Liversedge and Middleton, in northern England, textile mills were looted. Parliament responded by declaring “frame breaking” a capital offense, and the machines kept coming. Each new technology displaced a new cast of workers: first knitters, then farmers, then machinists. The world as we know it today is a product of these successive waves of displacement, and of the social and artistic movements they inspired: Romanticism, socialism, progressivism, Communism.\n\n\n\nMeanwhile, the global economy kept growing, in large part _because_ of the new machines. As one occupation vanished, another came into being. Employment migrated from farms and mills to factories and offices to cubicles and call centers.\n\n\n\nEconomic history suggests that this basic pattern will continue, and that the jobs eliminated by Watson and his ilk will be balanced by those created in enterprises yet to be imagined—but not without a good deal of suffering. If nearly half the occupations in the U.S. are “potentially automatable,” and if this could play out within “a decade or two,” then we are looking at economic disruption on an unparalleled scale. Picture the entire Industrial Revolution compressed into the life span of a beagle.\n\n\n\nAnd that’s assuming history repeats itself. What if it doesn’t? What if the jobs of the future are also potentially automatable?\n\n\n\n“This time is always different where technology is concerned,” Ford observes. “That, after all, is the entire point of innovation.”\n\n\n\nJerry Kaplan is a computer scientist and entrepreneur who teaches at Stanford. In “Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence” (Yale), he notes that most workplaces are set up to suit the way people think. In a warehouse staffed by people, like items are stored near one another—mops next to brooms next to dustpans—so their location is easy for stock clerks to remember. Computers don’t need such mnemonics; they’re programmed to know where things are. So a warehouse organized for a robotic workforce can be arranged according to entirely different principles, with mops, say, stored next to glue guns because the two happen to be often ordered together.\n\n\n\n“When most people think about automation, they usually have in mind only the simple replacement of labor or improving workers’ speed or productivity, not the more extensive disruption caused by process reengineering,” Kaplan writes. Process reëngineering means that, no matter how much the warehouse business expands, it’s not going to hire more humans, because they’ll just get in the way. It’s worth noting that in 2012 Amazon acquired a robotics company, called Kiva, for three-quarters of a billion dollars. The company’s squat orange bots look like microwave ovens with a grudge. They zip around on the ground, retrieving whole racks’ worth of merchandise. Amazon now deploys at least thirty thousand of them in its fulfillment centers. Speaking of the next wave of automation, Amazon’s chairman, Jeff Bezos, said recently, “It’s probably hard to overstate how big of an impact it’s going to have on society over the next twenty years.”\n\n\n\n-=-=-=-\n\nNot long ago, a team of researchers at Berkeley set out to design a robot that could fold towels. The machine they came up with looked a lot like Rosie, the robot maid on “The Jetsons,” minus the starched white cap. It had two cameras mounted on its “head” and two more between its arms. Each arm could rotate up and down and also sideways, and was equipped with a pincer-like “gripper” that could similarly rotate. The robot was supposed to turn a mess of towels into a neat stack. It quickly learned how to grasp the towels but had a much harder time locating the corners. When the researchers tested the robot on a pile of assorted towels, the results were, from a practical standpoint, disastrous. It took the robot an average of twenty-four and a half minutes to fold each towel, or ten hours to produce a stack of twenty-five.\n\n\n\n\n\nEven as robots grow cleverer, some tasks continue to bewilder them. “At present, machines are not very good at walking up stairs, picking up a paper clip from the floor, or reading the emotional cues of a frustrated customer” is how the M.I.T. researchers Erik Brynjolfsson and Andrew McAfee put it, in “The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies” (Norton). Because we see the world through human eyes and feel it with human hands, robotic frustrations are hard for us to understand. But doing so is worth the effort, Brynjolfsson and McAfee contend, because machines and their foibles explain a lot about our current economic situation.\n\n\n\nImagine a matrix with two axes, manual versus cognitive and routine versus nonroutine. Jobs can then be arranged into four boxes: manual routine, manual nonroutine, and so on. (Two of Brynjolfsson and McAfee’s colleagues at M.I.T., Daron Acemoglu and David Autor, performed a formal version of this analysis in 2010.) Jobs on an assembly line fall into the manual-routine box, jobs in home health care into the manual-nonroutine box. Keeping track of inventory is in the cognitive-routine box; dreaming up an ad campaign is cognitive nonroutine.\n\n\n\nThe highest-paid jobs are clustered in the last box; managing a hedge fund, litigating a bankruptcy, and producing a TV show are all cognitive and nonroutine. Manual, nonroutine jobs, meanwhile, tend to be among the lowest paid—emptying bedpans, bussing tables, cleaning hotel rooms (and folding towels). Routine jobs on the factory floor or in payroll or accounting departments tend to fall in between. And it’s these middle-class jobs that robots have the easiest time laying their grippers on.\n\n\n\nDuring the recent Presidential campaign, much was said—most of it critical—about trade deals like the North American Free Trade Agreement and the Trans-Pacific Partnership. The argument, made by both Bernie Sanders and Donald Trump, was that these deals have shafted middle-class workers by encouraging companies to move jobs to countries like China and Mexico, where wages are lower. Trump has vowed to renegotiate *NAFTA*{: .small} and to withdraw from the T.P.P., and has threatened to slap tariffs on goods manufactured by American companies overseas. “Under a Trump Presidency, the American worker will finally have a President who will protect them and fight for them,” he has declared.\n\n\n\nAccording to Brynjolfsson and McAfee, such talk misses the point: trying to save jobs by tearing up trade deals is like applying leeches to a head wound. Industries in China are being automated just as fast as, if not faster than, those in the U.S. Foxconn, the world’s largest contract-electronics company, which has become famous for its city-size factories and grim working conditions, plans to automate a third of its positions out of existence by 2020.The _South China_ _Morning Post_ recently reported that, thanks to a significant investment in robots, the company already has succeeded in reducing the workforce at its plant in Kunshan, near Shanghai, from a hundred and ten thousand people to fifty thousand. “More companies are likely to follow suit,” a Kunshan official told the newspaper.\n\n\n\n“If you look at the types of tasks that have been offshored in the past twenty years, you see that they tend to be relatively routine,” Brynjolfsson and McAfee write. “These are precisely the tasks that are easiest to automate.” Off-shoring jobs, they argue, is often just a “way station” on the road to eliminating them entirely.\n\n\n\nIn “Rise of the Robots,” Ford takes this argument one step further. He notes that a “significant ‘reshoring’ trend” is now under way. Reshoring reduces transportation costs and cuts down on the time required to bring new designs to market. But it doesn’t do much for employment, because the operations that are moving back to the U.S. are largely automated. This is the major reason that there is a reshoring trend; salaries are no longer an issue once you get rid of the salaried. Ford cites the example of a factory in Gaffney, South Carolina, that produces 2.5 million pounds of cotton yarn a week with fewer than a hundred and fifty workers. A story about the Gaffney factory in the _Times_ ran under the headline “*U.S. Textile Plants Return, With Floors Largely Empty of People*{: .small}.”\n\n\n\n-=-=-=-\n\nAs recently as twenty years ago, Google didn’t exist, and as recently as thirty years ago it _couldn’t_ have existed, since the Web didn’t exist. At the close of the third quarter of 2016, Google was valued at almost five hundred and fifty billion dollars and ranked as the world’s second-largest publicly traded company, by market capitalization. (The first was Apple.)\n\n\n\n\n\nGoogle offers a vivid illustration of how new technologies create new opportunities. Two computer-science students at Stanford go looking for a research project, and the result, within two decades, is worth more than the G.D.P. of a country like Norway or Austria. But Google also illustrates how, in the age of automation, new wealth can be created without creating new jobs. Google employs about sixty thousand workers. General Motors, which has a tenth of the market capitalization, employs two hundred and fifteen thousand people. And this is G.M. post-Watson. In the late nineteen-seventies, the carmaker’s workforce numbered more than eight hundred thousand.\n\n\n\nHow much technology has contributed to the widening income gap in the U.S. is a matter of debate; some economists treat it as just one factor, others treat it as the determining factor. In either case, the trend line is ominous. Facebook is worth two hundred and seventy billion dollars and employs just thirteen thousand people. In 2014, Facebook acquired Whatsapp for twenty-two billion dollars. At that point, the messaging firm had a grand total of fifty-five employees. When a twenty-two-billion-dollar company can fit its entire workforce into a Greyhound bus, the concept of surplus labor would seem to have run its course.\n\n\n\nFord worries that we are headed toward an era of “techno-feudalism.” He imagines a plutocracy shut away “in gated communities or in elite cities, perhaps guarded by autonomous military robots and drones.” Under the old feudalism, the peasants were exploited; under the new arrangement, they’ll merely be superfluous. The best we can hope for, he suggests, is a collective form of semi-retirement. He recommends a guaranteed basic income for all, to be paid for with new taxes, levelled, at least in part, on the new gazillionaires.\n\n\n\nTo one degree or another, just about everyone writing on the topic shares this view. Jerry Kaplan proposes that the federal government create a 401(k)-like account for every ten-year-old in the U.S. Those who ultimately do find jobs could contribute some of their earnings to the accounts; those who don’t could perform volunteer work in return for government contributions. (What the volunteers would live off is a little unclear; Kaplan implies that they might be able to get by on their dividends.) Brynjolfsson and McAfee prefer the idea of a negative income tax; this would provide the unemployed with a minimal living and the underemployed with additional cash.\n\n\n\nBut, if it’s unrealistic to suppose that smart machines can be stopped, it’s probably just as unrealistic to imagine that smart policies will follow. Which brings us back to Trump. The other day, during his “victory lap” through the Midwest, the President-elect vowed to “usher in a new Industrial Revolution,” apparently unaware that such a revolution is already under way, and that this is precisely the problem. The pain of dislocation he spoke to during the campaign is genuine; the solutions he offers are not. How this will all end, no one can say with confidence, except, perhaps, for Watson. ♦","canonicalUrl":"http:\u002F\u002Fwww.newyorker.com\u002Fmagazine\u002F2016\u002F12\u002F19\u002Four-automated-future","categories":{"tags":[{"id":"5c2e1e0d81ab3335f580f312","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Automation","parent":null,"photos":{},"root":[],"slug":"automation"},{"id":"5c2e1c7622d4972cd5b83286","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Books","parent":null,"photos":{},"root":[],"slug":"books"},{"id":"5c2e1cd7e56e652c902746eb","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Computers","parent":null,"photos":{},"root":[],"slug":"computers"},{"id":"5c2e1c7f2396212cbb9fc9a3","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Jobs","parent":null,"photos":{},"root":[],"slug":"jobs"},{"id":"5c2e1d332bfcc72cd92d05d7","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Progress","parent":null,"photos":{},"root":[],"slug":"progress"},{"id":"5c2e1c9b2710c62d10815459","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Robots","parent":null,"photos":{},"root":[],"slug":"robots"}],"sections":[{"id":"592e2a5036e1a35e5cba5262","modelName":"category","collection":"categories","contributors":{},"hierarchy":[],"name":"Books","parent":null,"photos":{},"root":[],"slug":"books"}]},"channel":"","contentSource":"magazine","contributors":{"author":[{"id":"590a03351c7a8e33fb390bec","modelName":"contributor","collection":"contributors","bio":"Elizabeth Kolbert has been a staff writer at *The New Yorker* since 1999. Previously, she worked at the *Times*, where she wrote the Metro Matters column and served as the paper’s Albany bureau chief. Her three-part series on global warming, “[The Climate of Man](https:\u002F\u002Fwww.newyorker.com\u002Fmagazine\u002F2005\u002F04\u002F25\u002Fthe-climate-of-man-i),” won the 2006 National Magazine Award for Public Interest and the 2006 National Academies Communication Award. She received a Heinz Award, in 2010, and won the 2010 National Magazine Award for Reviews and Criticism. She is the editor of “The Best American Science and Nature Writing 2009” and the author of  “[The Prophet of Love: And Other Tales of Power and Deceit](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002FB000GG4ISS)”; “[Field Notes from a Catastrophe](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F1620409887);\" and “[The Sixth Extinction](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F1250062187),” for which she won the Pulitzer Prize for general nonfiction in 2015. She received the Blake-Dodd Prize, from the American Academy of Arts and Letters, in 2017.  \n","canonicalUrl":"http:\u002F\u002Fwww.newyorker.com\u002Fcontributors\u002Felizabeth-kolbert","email":"","name":"Elizabeth Kolbert","socialMedia":[{"network":"Twitter","handle":"ElizKolbert"}],"title":"Elizabeth Kolbert has been a staff writer at The New Yorker since 1999. She is the author of “[The Sixth Extinction: An Unnatural History](https:\u002F\u002Fwww.amazon.com\u002Fdp\u002F1250062187\u002F?tag=thneyo0f-20),” which won the Pulitzer Prize for nonfiction in 2015."}]},"dek":"Will robots take your job?","hed":"Rage Against the Machine","galleries":{},"inlineEmbeds":[],"issueDate":"December 19 &amp; 26, 2016","ledeCaption":"","modifiedAt":"2019-07-09T18:26:26.922Z","photos":{"tout":[{"id":"59097c922179605b11ad911c","modelName":"photo","collection":"photos","aspectRatios":{"master":{"width":1840,"height":2560,"format":"JPEG","duration":null,"url":"https:\u002F\u002Fcn-copilot-media.s3.amazonaws.com\u002Fpublic\u002Ftny-services\u002Fproduction\u002F2017\u002F05\u002F03\u002F59097c922179605b11ad911b_161219_r29189.jpg"}},"caption":"“Reshoring,” the return of once off-shored operations, is fuelled by automation: salaries aren’t an issue without the salaried.","altText":"“Reshoring,” the return of once off-shored operations, is fuelled by automation: salaries aren’t an issue without the salaried.","credit":"Illustration by Matt Blease","filename":"161219_r29189.jpg","revision":5,"title":"161219_r29189"}]},"promoDek":"How long will it be before you lose your job to a robot?","promoHed":"Our Automated Future","pubDate":"2016-12-12T04:00:00.000Z","related":[],"rubric":"","seoDescription":"How long will it be before you lose your job to a robot?","seoTitle":"Our Automated Future","socialDescription":"How long will it be before you lose your job to a robot?","socialTitle":"Our Automated Future","subChannel":"","tags":["Automation","Books","Computers","Jobs","Progress","Robots","_wordpress_id:3289834","_page_numbers:114-118","_migration_id:161219crbo_books_kolbert","_serial_number:TNY_LIBRY_000085527","_stackname:2500_crit_kolbert_161219"],"template":"standard","url":"magazine\u002F2016\u002F12\u002F19\u002Four-automated-future","videos":{},"magazineStartPage":114},{"id":"5adcdc3bd6962f7b6e59b85d","modelName":"cnevideo","collection":"cnevideos","categories":["Politics","News"],"channel":"Politics","cneId":"5adcd22ddbc8584c47000003","credit":"","dek":"David Remnick speaks with James Comey about the “emptiness” of Donald Trump and whether the President is fit for office.","description":"David Remnick speaks with James Comey about the “emptiness” of Donald Trump and whether the President is fit for office.","embedUrl":"\u002F\u002Fplayer.cnevids.com\u002Fiframe\u002Fvideo\u002F5adcd22ddbc8584c47000003","hed":"James Comey on His Infamous Dinner with Trump","photos":{"cnevideo":[{"url":"http:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_640\u002Fv1524423645\u002Fthenewyorker_the-new-yorker-interview-james-comey-on-his-infamous-dinner-with-trump.jpg"}]},"pubDate":"2018-04-22T19:00:00.000Z","scriptEmbedUrl":"\u002F\u002Fplayer.cnevids.com\u002Fscript\u002Fvideo\u002F5adcd22ddbc8584c47000003.js","title":"James Comey on His Infamous Dinner with Trump","url":"https:\u002F\u002Fvideo.newyorker.com\u002Fwatch\u002Fthe-new-yorker-interview-james-comey-on-his-infamous-dinner-with-trump","canonicalUrl":""}],"rubric":"","seoDescription":"Tad Friend writes that thinking about artificial intelligence can help clarify what makes us human—for better and for worse.","seoTitle":"How Frightened Should We Be of A.I.?","socialDescription":"Thinking about artificial intelligence can help clarify what makes us human—for better and for worse.","socialTitle":"How Frightened Should We Be of A.I.?","subChannel":"Dept. of Speculation","tags":["_page_numbers:44-51","_xmlfilename:180514fa_fact_friend","_stackname:2000_dept_friend_180514","Artificial General Intelligence (A.G.I.)","“Human + Machine: Reimagining Work in the Age of AI”","“Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins”","“Common Sense, the Turing Test, and the Quest for Real AI”","“Life 3.0: Being Human in the Age of Artificial Intelligence”","“The Sentient Machine: The Coming Age of Artificial Intelligence”","Technology","Books"],"template":"standard","url":"magazine\u002F2018\u002F05\u002F14\u002Fhow-frightened-should-we-be-of-ai","videos":{},"magazineStartPage":44},"pageSize":4},"interlude":{"brand":"newyorker","humanName":"The New Yorker","playerBase":"https:\u002F\u002Fplayer.cnevids.com","strategy":{"enabled":true,"target":{"method":"midpoint"},"embed":{"method":"default"}},"embeddedVideos":[],"hasExcludedEmbed":false},"hideContributorBio":false,"badge":null,"tagCloud":{"tags":[{"tag":"Alan Turing","id":"5c2e1faa22d4972cd5b83532","url":"\u002Ftag\u002Falan-turing"},{"tag":"Artificial Intelligence","id":"5c2e1e2622d4972cd5b83465","url":"\u002Ftag\u002Fartificial-intelligence"},{"tag":"Second World War","id":"5c2e1ce322d4972cd5b8330c","url":"\u002Ftag\u002Fsecond-world-war"},{"tag":"Science Fiction","id":"5c2e1cc441e4c73c088d77e6","url":"\u002Ftag\u002Fscience-fiction"},{"tag":"Technology","id":"5c2e1c7841c92e2c9b85da16","url":"\u002Ftag\u002Ftechnology"},{"tag":"Mathematics","id":"5c2e1ea9aef5062c9d94ab03","url":"\u002Ftag\u002Fmathematics"}],"tagCloudHeader":"More:"},"newsletter":{"apiURL":"\u002Fverso\u002Fapi\u002Futility\u002Fnewsletter-subscriptions","formName":"newsletter","sourceCode":"article-newsletter","provider":"sailthru","placeholder":"Your e-mail address","textFieldLabel":"Enter your e-mail address","buttonLabelOnSuccess":"Subscribed","dangerousDisclaimer":"\u003Cp\u003EWill be used in accordance with our \u003Ca href=\"https:\u002F\u002Fwww.condenast.com\u002Fprivacy-policy\"\u003EPrivacy Policy\u003C\u002Fa\u003E.\u003C\u002Fp\u003E","newsletterId":248805,"dangerousHed":"The New Yorker Recommends","dangerousDek":"What our staff is reading, watching, and listening to each week.","buttonLabel":"Sign up"},"shouldUsePersistentAd":true,"lightboxImages":[{"dangerousCaption":"The British mathematician Alan Turing was one of the more unquantifiably original minds of the twentieth century.","dangerousCredit":"Photograph from Alamy","altText":"Alan Turing","contentType":"photo","id":"5e2330c74156f60008818e30","sources":{"sm":{"aspectRatio":"master","width":360,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_360,c_limit\u002FGrimstad-Turing.jpg","height":480},"md":{"aspectRatio":"master","width":1024,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1024,c_limit\u002FGrimstad-Turing.jpg","height":1365},"lg":{"aspectRatio":"master","width":1280,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","height":1706},"xl":{"aspectRatio":"master","width":1280,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_1280,c_limit\u002FGrimstad-Turing.jpg","height":1706},"xxl":{"aspectRatio":"master","width":2560,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5e2330c74156f60008818e30\u002Fmaster\u002Fw_2560,c_limit\u002FGrimstad-Turing.jpg","height":3412}}}]},"inlineRecirc":[],"outbrain":null,"related":[{"authors":{"items":[{"name":"Tad Friend"}]},"contentType":"article","copilotID":"5ae878d23a694734bacc2c04","dangerousHed":"How Frightened Should We Be of A.I.?","dangerousDek":"Thinking about artificial intelligence can help clarify what makes us human&#8212;for better and for worse.","date":"May 7, 2018","image":{"altText":"A cartoonlike illustration of a red eyeball and its veins","caption":"An A.I. system may need to take charge in order to achieve the goals we gave it.","contentType":"photo","credit":"Illustration by Harry Campbell","id":"5aeb3d4c7505432fc35f5419","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"}]}},"rubric":{"name":"Dept. of Speculation","url":"\u002Fmagazine\u002Fdept-of-speculation"},"url":"\u002Fmagazine\u002F2018\u002F05\u002F14\u002Fhow-frightened-should-we-be-of-ai"},{"authors":{"items":[{"name":"Siobhan Roberts"}]},"contentType":"article","copilotID":"5924f6fafc1a6c1c6785cd9b","dangerousHed":"Christopher Strachey’s Nineteen-Fifties Love Machine","dangerousDek":"","date":"February 14, 2017","image":{"altText":"Long before artificial intelligence came into its own Strachey taught a computer to write love letters.","caption":"Long before artificial intelligence came into its own, Strachey taught a computer to write love letters.","contentType":"photo","credit":"ILLUSTRATION BY WREN MCDONALD","id":"59097e19ebe912338a378bda","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"}]}},"rubric":{"name":"Tech","url":"\u002Ftech"},"url":"\u002Ftech\u002Fannals-of-technology\u002Fchristopher-stracheys-nineteen-fifties-love-machine"},{"authors":{"items":[{"name":"The New Yorker"}]},"contentType":"cnevideo","copilotID":"5beedc971aa15345aeca363f","dangerousHed":"A Robotic Arm Controlled by the Mind","dangerousDek":"After Nathan Copeland survived a car crash that paralyzed him from the neck down, he volunteered for an ambitious program aimed at giving people mastery of brain-controlled robotics.","date":"November 19, 2018","image":{"altText":"","sources":{"sm":{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"md":{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"lg":{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"xl":{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}},"segmentedSources":{"sm":[{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}],"lg":[{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}]}},"rubric":{"name":"Video"},"url":"http:\u002F\u002Fvideo.newyorker.com\u002Fwatch\u002Fa-robotic-arm-controlled-by-the-mind"},{"authors":{"items":[{"name":"Dan Rockmore"}]},"contentType":"article","copilotID":"5924bbccc607487ed1deaaa2","dangerousHed":"What’s Missing from “The Imitation Game”","dangerousDek":"","date":"November 6, 2014","image":{"altText":"Benedict Cumberbatch plays Alan Turing in The Imitation Game.","caption":"Benedict Cumberbatch plays Alan Turing in &quot;The Imitation Game.&quot;","contentType":"photo","credit":"Photograph by SSPL \u002F Getty","id":"59095e96019dfc3494e9fb3f","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"}]}},"rubric":{"name":"Annals of Technology","url":"\u002Ftech\u002Fannals-of-technology"},"url":"\u002Ftech\u002Fannals-of-technology\u002Fimitation-game-alan-turing"}],"relatedRiser":[{"authors":{"items":[{"name":"Tad Friend"}]},"contentType":"article","copilotID":"5ae878d23a694734bacc2c04","dangerousHed":"How Frightened Should We Be of A.I.?","dangerousDek":"Thinking about artificial intelligence can help clarify what makes us human&#8212;for better and for worse.","date":"May 7, 2018","image":{"altText":"A cartoonlike illustration of a red eyeball and its veins","caption":"An A.I. system may need to take charge in order to achieve the goals we gave it.","contentType":"photo","credit":"Illustration by Harry Campbell","id":"5aeb3d4c7505432fc35f5419","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F16:9\u002Fw_720,c_limit\u002F180514_r32044.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F5aeb3d4c7505432fc35f5419\u002F4:3\u002Fw_480,c_limit\u002F180514_r32044.jpg"}]}},"rubric":{"name":"Dept. of Speculation","url":"\u002Fmagazine\u002Fdept-of-speculation"},"url":"\u002Fmagazine\u002F2018\u002F05\u002F14\u002Fhow-frightened-should-we-be-of-ai"},{"authors":{"items":[{"name":"Siobhan Roberts"}]},"contentType":"article","copilotID":"5924f6fafc1a6c1c6785cd9b","dangerousHed":"Christopher Strachey’s Nineteen-Fifties Love Machine","dangerousDek":"","date":"February 14, 2017","image":{"altText":"Long before artificial intelligence came into its own Strachey taught a computer to write love letters.","caption":"Long before artificial intelligence came into its own, Strachey taught a computer to write love letters.","contentType":"photo","credit":"ILLUSTRATION BY WREN MCDONALD","id":"59097e19ebe912338a378bda","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F16:9\u002Fw_720,c_limit\u002Fstrachey-love-letter_WP.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59097e19ebe912338a378bda\u002F4:3\u002Fw_480,c_limit\u002Fstrachey-love-letter_WP.jpg"}]}},"rubric":{"name":"Tech","url":"\u002Ftech"},"url":"\u002Ftech\u002Fannals-of-technology\u002Fchristopher-stracheys-nineteen-fifties-love-machine"},{"authors":{"items":[{"name":"The New Yorker"}]},"contentType":"cnevideo","copilotID":"5beedc971aa15345aeca363f","dangerousHed":"A Robotic Arm Controlled by the Mind","dangerousDek":"After Nathan Copeland survived a car crash that paralyzed him from the neck down, he volunteered for an ambitious program aimed at giving people mastery of brain-controlled robotics.","date":"November 19, 2018","image":{"altText":"","sources":{"sm":{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"md":{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"lg":{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"},"xl":{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}},"segmentedSources":{"sm":[{"width":720,"height":405,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_405,q_80,w_720\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}],"lg":[{"width":480,"height":360,"url":"https:\u002F\u002Fdwgyu36up6iuz.cloudfront.net\u002Fheru80fdn\u002Fimage\u002Fupload\u002Fc_fill,d_placeholder_thescene.jpg,fl_progressive,g_center,h_360,q_80,w_480\u002Fv1542299457\u002Fthenewyorker_a-robotic-arm-controlled-by-the-mind.jpg"}]}},"rubric":{"name":"Video"},"url":"http:\u002F\u002Fvideo.newyorker.com\u002Fwatch\u002Fa-robotic-arm-controlled-by-the-mind"},{"authors":{"items":[{"name":"Dan Rockmore"}]},"contentType":"article","copilotID":"5924bbccc607487ed1deaaa2","dangerousHed":"What’s Missing from “The Imitation Game”","dangerousDek":"","date":"November 6, 2014","image":{"altText":"Benedict Cumberbatch plays Alan Turing in The Imitation Game.","caption":"Benedict Cumberbatch plays Alan Turing in &quot;The Imitation Game.&quot;","contentType":"photo","credit":"Photograph by SSPL \u002F Getty","id":"59095e96019dfc3494e9fb3f","sources":{"sm":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"},"md":{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"},"lg":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"},"xl":{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"}},"segmentedSources":{"sm":[{"aspectRatio":"16:9","width":720,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F16:9\u002Fw_720,c_limit\u002FRockmore-Imitation-Game.jpg"}],"lg":[{"aspectRatio":"4:3","width":480,"url":"https:\u002F\u002Fmedia.newyorker.com\u002Fphotos\u002F59095e96019dfc3494e9fb3f\u002F4:3\u002Fw_480,c_limit\u002FRockmore-Imitation-Game.jpg"}]}},"rubric":{"name":"Annals of Technology","url":"\u002Ftech\u002Fannals-of-technology"},"url":"\u002Ftech\u002Fannals-of-technology\u002Fimitation-game-alan-turing"}],"identifier":"culture\u002Fculture-desk\u002Fliving-in-alan-turings-future"}};</script><script type="text/javascript">window.dataLayer = [{"event":"data-layer-loaded","content":{"brand":"The New Yorker","brandSlug":"the-new-yorker","contentID":"5e1cc31e2751bc0008ff607c","contentLength":"3","contentSource":"web","contributor":"Paul Grimstad","dataSource":"web","display":"Living in Alan Turing’s Future","embeddedMedia":"","functionalTags":"","hasBuyButtons":"false","keywords":"Alan Turing|Artificial Intelligence|Second World War|Science Fiction|Technology|Mathematics","modifiedDate":"2020-01-18T17:12:19.384Z","pageType":"article","pageValue":"all","publishDate":"2020-01-19T11:00:00.000Z","section":"culture","subsection":"culture desk","wordCount":"2054"},"marketing":{"brand":"The New Yorker"},"page":{"canonical":"https:\u002F\u002Fwww.newyorker.com\u002Fculture\u002Fculture-desk\u002Fliving-in-alan-turings-future"},"search":{},"site":{"orgId":"d647fe37-5256-4891-90f8-2f46a4932677","orgAppId":"a61a3c7a-01d9-4175-8ab8-7171949de605","appVersion":"multi-tenant"}}];</script><script defer="" type="text/javascript" src="/verso/static/polyfill.bcf57698a76dcb8e70cef7146ab6d7914302279e.js"></script><script defer="" type="text/javascript" src="/verso/static/presenter-articles.221f02f50a42e25cc4baa2e6c7a41d61fa40ff9e.js"></script><div id="parsely-root" style="display:none"><div id="parsely-cfg" data-parsely-site="newyorker.com"></div></div><script>
    (function(w) {
      w.PARSELY = {
        autotrack: false,
        onReady: function() {
          PARSELY.updateDefaults({
            data: {
              plan: "Not Active"
            }
          });
          PARSELY.beacon.trackPageView();
        }
      };
    })(window);
  </script><script>
            !function(a, b, c) {
              var d = c.location.protocol,
              e = b + "-" + a,
              f = c.getElementById(e),
              g = c.getElementById(b + "-root"),
              h = "https:" === d ? "d1z2jf7jlzjs58.cloudfront.net" : "static." + b + ".com";
              f || (f = c.createElement(a), f.id = e, f.async = !0, f.src = d + "//" + h + "/p.js", g.appendChild(f))
            }("script", "parsely", document);
          </script><script></script><script id="esi-1">var dl=(window.dataLayer||[])[0];window.CN_STACK_TEMP=(dl&&dl.site&&dl.site.appVersion==='multi-tenant')?'verso':'unknown';</script><script id="cns-config-include">window.cns = window.cns || {}; window.cns.config = {"config":{"ad_unit":{"generate_path":"function(opts) { return \"3379/\" + opts.suffix + \"/\" + opts.position + \"/\" + opts.category + \"/\" + opts.contentType + \"/\" + opts.instance; }","generate_legacy_path":"function(opts) { return \"3379/newyorker.\" + opts.suffix + \"/\" + opts.channel + (opts.subChannel && \"/\" + opts.subChannel) }"},"request_vp_range":{"_default":{"desktop":800,"tablet":800,"mobile":400}},"domain":"newyorker.com","network":3379,"slot":{"__auid_one":"newyorker","sets":{"_default":[],"mt_article":["_out_of_page","hero","rail","mid_content","mid_gallery","footer","cm_incognito_modal_call_to_action","cm_paywall_bar_call_to_action","cm_paywall_modal_full_barrier","nav_cta","nav_left","nav_rollover","cm_in_content","cm_footer"],"mt_article_two_column":["_out_of_page","hero","rail","mid_content","mid_gallery","footer","cm_incognito_modal_call_to_action","cm_paywall_bar_call_to_action","cm_paywall_modal_full_barrier","nav_cta","nav_left","nav_rollover","cm_in_content","cm_footer"],"mt_article_override":["_out_of_page","hero","rail","mid_content","mid_gallery","mid_content_manual","footer","cm_incognito_modal_call_to_action","cm_paywall_bar_call_to_action","cm_paywall_modal_full_barrier","nav_cta","nav_left","nav_rollover","cm_in_content","cm_footer"],"mt_contributor":["_out_of_page","hero","rail","mid_content","footer"],"mt_gallery":["_out_of_page","hero","rail","mid_content","footer","cm_incognito_modal_call_to_action","cm_paywall_bar_call_to_action","cm_paywall_modal_full_barrier","nav_cta","nav_left","nav_rollover","cm_in_content","cm_footer"],"mt_homepage":["_out_of_page","hero","rail","mid_content","footer"],"news_the-future-of-democracy_mt_bundle":["_out_of_page","hero","mid_content","nav_cta","nav_left","nav_rollover","cm_footer"],"home_about_mt_article_two_column":["nav_cta","nav_left","nav_rollover","cm_footer"]},"types":{"_default":{"suffix":"conde.newyorker","render":{"slot":{"top":"body"}}},"_out_of_page":{"_default":{"position":"interstitial","refresh":false,"isOutOfPage":true,"can_be_hidden":true,"render":{"slot":{"top":".ad__slot--out-of-page"}}}},"hero":{"_default":{"position":"hero","static_refresh_size":true,"sizes":{"desktop":["728x90","970x250","970x90","9x1","10x1"],"tablet":["728x90","9x1","8x1"],"mobile":["300x50","320x50","9x1","3x1"]},"render":{"slot":{"top":".ad__slot--hero"}}}},"rail":{"_default":{"position":"rail","sizes":{"desktop":["300x250","300x600"],"tablet":["300x250","300x600"],"mobile":false},"render":{"slot":{"top":".ad__slot--rail"}}}},"mid_content":{"_default":{"position":"mid-content","static_refresh_size":true,"sizes":{"desktop":["728x90","970x250","970x90","9x2","9x1","4x1","2x1"],"tablet":["728x90","9x2","9x1","4x1","2x1"],"mobile":["300x50","300x250","320x50","9x2","9x1","16x9","2x1"]},"render":{"slot":{"top":".ad__slot--mid-content"}}}},"mid_content_manual":{"_default":{"position":"mid-content","static_refresh_size":true,"sizes":{"desktop":["728x90","970x250","970x90","9x2","9x1","4x1","2x1"],"tablet":["728x90","9x2","9x1","4x1","2x1"],"mobile":["300x50","300x250","320x50","9x2","9x1","16x9","2x1"]},"render":{"slot":{"top":"[data-callout=\"inline-ad\"]"}}}},"mid_gallery":{"_default":{"position":"mid-gallery","sizes":{"desktop":["300x250"],"tablet":["300x250"],"mobile":["300x250"]},"render":{"slot":{"top":".ad__slot--mid-gallery"}}}},"footer":{"_default":{"position":"footer","sizes":{"desktop":["728x90","970x250","970x90","9x1","9x2","4x1"],"tablet":["728x90","9x1","9x2","4x1"],"mobile":["300x50","320x50","9x1","9x2","16x9"]},"render":{"slot":{"top":".ad__slot--footer"}},"request_vp_range":{"desktop":400,"tablet":400,"mobile":300}}},"promo":{"_default":{"position":"promo","suffix":"conde.newyorker.native","refresh":false,"sizes":{"desktop":["fluid"],"tablet":["fluid"],"mobile":["fluid"]},"render":{"slot":{"top":".ad__slot--promo"}}}},"cm_incognito_modal_call_to_action":{"_default":{"position":"cm","suffix":"cm","insert_after_react_ready":true,"should_use_legacy_path":true,"required_targeting":["cnt_cm"],"refresh":false,"sizes":{"desktop":["520x638"],"tablet":["320x440"],"mobile":["320x440"]},"render":{"slot":{"top":".consumer-marketing-unit__slot--incognito-modal-call-to-action"}}}},"cm_paywall_bar_call_to_action":{"_default":{"position":"cm","suffix":"cm","insert_after_react_ready":true,"should_use_legacy_path":true,"required_targeting":["cnt_cm"],"refresh":false,"sizes":{"desktop":["1280x300"],"tablet":["768x300"],"mobile":["375x300"]},"render":{"slot":{"top":".consumer-marketing-unit__slot--paywall-bar-call-to-action"}}}},"cm_paywall_modal_full_barrier":{"_default":{"position":"cm","suffix":"cm","insert_after_react_ready":true,"should_use_legacy_path":true,"required_targeting":["cnt_cm"],"refresh":false,"sizes":{"desktop":["520x638"],"tablet":["320x440"],"mobile":["320x440"]},"render":{"slot":{"top":".consumer-marketing-unit__slot--paywall-modal-full-barrier"}}}},"nav_rollover":{"_default":{"position":"nav-rollover","insert_after_react_ready":true,"suffix":"conde.newyorker.cm","render":{"slot":{"top":".consumer-marketing-unit__slot--nav-rollover"}},"sizes":{"desktop":["300x200"],"tablet":false,"mobile":false}}},"nav_left":{"_default":{"position":"nav-left","insert_after_react_ready":true,"suffix":"conde.newyorker.cm","render":{"slot":{"top":".consumer-marketing-unit__slot--nav-left"}},"sizes":{"desktop":["230x20"],"tablet":["230x20"],"mobile":false}}},"nav_cta":{"_default":{"position":"nav-cta","insert_after_react_ready":true,"suffix":"conde.newyorker.cm","render":{"desktop":{"slot":{"top":".consumer-marketing-unit__slot--nav-cta"}},"tablet":{"slot":{"top":".consumer-marketing-unit__slot--mob-nav-cta"}},"mobile":{"slot":{"top":".consumer-marketing-unit__slot--mob-nav-cta"}}},"sizes":{"desktop":["80x38"],"tablet":["80x38"],"mobile":["90x58"]}}},"cm_in_content":{"_default":{"position":"in-content","insert_after_react_ready":true,"suffix":"conde.newyorker.cm","render":{"slot":{"top":".consumer-marketing-unit__slot--in-content"}},"sizes":{"desktop":["450x140"],"tablet":["724x190"],"mobile":["276x100"]}}},"cm_footer":{"_default":{"position":"cm-footer","insert_after_react_ready":true,"suffix":"conde.newyorker.cm","render":{"slot":{"top":".consumer-marketing-unit__slot--cm-footer"}},"sizes":{"desktop":["940x140"],"tablet":["724x190"],"mobile":["276x100"]}}}}}},"plugins":{"amazon_match_buy":{},"index_exchange":{},"4d":{"xid_pixels":true}},"buildDate":"2020-02-18T18:24:04.315Z"}</script><script id="cns-footer-include">!function(){"use strict";!function(e,t){function n(e){this.time=e.time,this.target=e.target,this.rootBounds=e.rootBounds,this.boundingClientRect=e.boundingClientRect,this.intersectionRect=e.intersectionRect||{top:0,bottom:0,left:0,right:0,width:0,height:0},this.isIntersecting=!!e.intersectionRect;var t=this.boundingClientRect,n=t.width*t.height,r=this.intersectionRect,i=r.width*r.height;this.intersectionRatio=n?i/n:this.isIntersecting?1:0}function r(e,t){var n,r,i,o=t||{};if("function"!=typeof e)throw new Error("callback must be a function");if(o.root&&1!=o.root.nodeType)throw new Error("root must be an Element");this._checkForIntersections=(n=this._checkForIntersections.bind(this),r=this.THROTTLE_TIMEOUT,i=null,function(){i||(i=setTimeout(function(){n(),i=null},r))}),this._callback=e,this._observationTargets=[],this._queuedEntries=[],this._rootMarginValues=this._parseRootMargin(o.rootMargin),this.thresholds=this._initThresholds(o.threshold),this.root=o.root||null,this.rootMargin=this._rootMarginValues.map(function(e){return e.value+e.unit}).join(" ")}function i(e,t,n,r){"function"==typeof e.addEventListener?e.addEventListener(t,n,r||!1):"function"==typeof e.attachEvent&&e.attachEvent("on"+t,n)}function o(e,t,n,r){"function"==typeof e.removeEventListener?e.removeEventListener(t,n,r||!1):"function"==typeof e.detatchEvent&&e.detatchEvent("on"+t,n)}function a(e){var t;try{t=e.getBoundingClientRect()}catch(e){}return t?(t.width&&t.height||(t={top:t.top,right:t.right,bottom:t.bottom,left:t.left,width:t.right-t.left,height:t.bottom-t.top}),t):{top:0,bottom:0,left:0,right:0,width:0,height:0}}function s(e,t){for(var n=t;n;){if(n==e)return!0;n=c(n)}return!1}function c(e){var t=e.parentNode;return t&&11==t.nodeType&&t.host?t.host:t}"IntersectionObserver"in e&&"IntersectionObserverEntry"in e&&"intersectionRatio"in e.IntersectionObserverEntry.prototype?"isIntersecting"in e.IntersectionObserverEntry.prototype||Object.defineProperty(e.IntersectionObserverEntry.prototype,"isIntersecting",{get:function(){return this.intersectionRatio>0}}):(r.prototype.THROTTLE_TIMEOUT=100,r.prototype.POLL_INTERVAL=null,r.prototype.USE_MUTATION_OBSERVER=!0,r.prototype.observe=function(e){if(!this._observationTargets.some(function(t){return t.element==e})){if(!e||1!=e.nodeType)throw new Error("target must be an Element");this._registerInstance(),this._observationTargets.push({element:e,entry:null}),this._monitorIntersections(),this._checkForIntersections()}},r.prototype.unobserve=function(e){this._observationTargets=this._observationTargets.filter(function(t){return t.element!=e}),this._observationTargets.length||(this._unmonitorIntersections(),this._unregisterInstance())},r.prototype.disconnect=function(){this._observationTargets=[],this._unmonitorIntersections(),this._unregisterInstance()},r.prototype.takeRecords=function(){var e=this._queuedEntries.slice();return this._queuedEntries=[],e},r.prototype._initThresholds=function(e){var t=e||[0];return Array.isArray(t)||(t=[t]),t.sort().filter(function(e,t,n){if("number"!=typeof e||isNaN(e)||e<0||e>1)throw new Error("threshold must be a number between 0 and 1 inclusively");return e!==n[t-1]})},r.prototype._parseRootMargin=function(e){var t=(e||"0px").split(/\s+/).map(function(e){var t=/^(-?\d*\.?\d+)(px|%)$/.exec(e);if(!t)throw new Error("rootMargin must be specified in pixels or percent");return{value:parseFloat(t[1]),unit:t[2]}});return t[1]=t[1]||t[0],t[2]=t[2]||t[0],t[3]=t[3]||t[1],t},r.prototype._monitorIntersections=function(){this._monitoringIntersections||(this._monitoringIntersections=!0,this.POLL_INTERVAL?this._monitoringInterval=setInterval(this._checkForIntersections,this.POLL_INTERVAL):(i(e,"resize",this._checkForIntersections,!0),i(t,"scroll",this._checkForIntersections,!0),this.USE_MUTATION_OBSERVER&&"MutationObserver"in e&&(this._domObserver=new MutationObserver(this._checkForIntersections),this._domObserver.observe(t,{attributes:!0,childList:!0,characterData:!0,subtree:!0}))))},r.prototype._unmonitorIntersections=function(){this._monitoringIntersections&&(this._monitoringIntersections=!1,clearInterval(this._monitoringInterval),this._monitoringInterval=null,o(e,"resize",this._checkForIntersections,!0),o(t,"scroll",this._checkForIntersections,!0),this._domObserver&&(this._domObserver.disconnect(),this._domObserver=null))},r.prototype._checkForIntersections=function(){var t=this._rootIsInDom(),r=t?this._getRootRect():{top:0,bottom:0,left:0,right:0,width:0,height:0};this._observationTargets.forEach(function(i){var o=i.element,s=a(o),c=this._rootContainsTarget(o),u=i.entry,l=t&&c&&this._computeTargetAndRootIntersection(o,r),f=i.entry=new n({time:e.performance&&performance.now&&performance.now(),target:o,boundingClientRect:s,rootBounds:r,intersectionRect:l});u?t&&c?this._hasCrossedThreshold(u,f)&&this._queuedEntries.push(f):u&&u.isIntersecting&&this._queuedEntries.push(f):this._queuedEntries.push(f)},this),this._queuedEntries.length&&this._callback(this.takeRecords(),this)},r.prototype._computeTargetAndRootIntersection=function(n,r){if("none"!=e.getComputedStyle(n).display){for(var i,o,s,u,l,f,d,g,p=a(n),h=c(n),m=!1;!m;){var v=null,y=1==h.nodeType?e.getComputedStyle(h):{};if("none"==y.display)return;if(h==this.root||h==t?(m=!0,v=r):h!=t.body&&h!=t.documentElement&&"visible"!=y.overflow&&(v=a(h)),v&&(i=v,o=p,s=Math.max(i.top,o.top),u=Math.min(i.bottom,o.bottom),l=Math.max(i.left,o.left),g=u-s,!(p=(d=(f=Math.min(i.right,o.right))-l)>=0&&g>=0&&{top:s,bottom:u,left:l,right:f,width:d,height:g})))break;h=c(h)}return p}},r.prototype._getRootRect=function(){var e;if(this.root)e=a(this.root);else{var n=t.documentElement,r=t.body;e={top:0,left:0,right:n.clientWidth||r.clientWidth,width:n.clientWidth||r.clientWidth,bottom:n.clientHeight||r.clientHeight,height:n.clientHeight||r.clientHeight}}return this._expandRectByRootMargin(e)},r.prototype._expandRectByRootMargin=function(e){var t=this._rootMarginValues.map(function(t,n){return"px"==t.unit?t.value:t.value*(n%2?e.width:e.height)/100}),n={top:e.top-t[0],right:e.right+t[1],bottom:e.bottom+t[2],left:e.left-t[3]};return n.width=n.right-n.left,n.height=n.bottom-n.top,n},r.prototype._hasCrossedThreshold=function(e,t){var n=e&&e.isIntersecting?e.intersectionRatio||0:-1,r=t.isIntersecting?t.intersectionRatio||0:-1;if(n!==r)for(var i=0;i<this.thresholds.length;i++){var o=this.thresholds[i];if(o==n||o==r||o<n!=o<r)return!0}},r.prototype._rootIsInDom=function(){return!this.root||s(t,this.root)},r.prototype._rootContainsTarget=function(e){return s(this.root||t,e)},r.prototype._registerInstance=function(){},r.prototype._unregisterInstance=function(){},e.IntersectionObserver=r,e.IntersectionObserverEntry=n)}(window,document);var commonjsGlobal="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{};function createCommonjsModule(e,t){return e(t={exports:{}},t.exports),t.exports}var usertiming=createCommonjsModule(function(e){!function(t){void 0===t&&(t={}),void 0===t.performance&&(t.performance={}),t._perfRefForUserTimingPolyfill=t.performance,t.performance.userTimingJsNow=!1,t.performance.userTimingJsNowPrefixed=!1,t.performance.userTimingJsUserTiming=!1,t.performance.userTimingJsUserTimingPrefixed=!1,t.performance.userTimingJsPerformanceTimeline=!1,t.performance.userTimingJsPerformanceTimelinePrefixed=!1;var n,r,i=[],o=[],a=null;if("function"!=typeof t.performance.now){for(t.performance.userTimingJsNow=!0,o=["webkitNow","msNow","mozNow"],n=0;n<o.length;n++)if("function"==typeof t.performance[o[n]]){t.performance.now=t.performance[o[n]],t.performance.userTimingJsNowPrefixed=!0;break}var s=+new Date;t.performance.timing&&t.performance.timing.navigationStart?s=t.performance.timing.navigationStart:"undefined"!=typeof process&&"function"==typeof process.hrtime&&(s=process.hrtime(),t.performance.now=function(){var e=process.hrtime(s);return 1e3*e[0]+1e-6*e[1]}),"function"!=typeof t.performance.now&&(Date.now?t.performance.now=function(){return Date.now()-s}:t.performance.now=function(){return+new Date-s})}var c=function(){},u=function(){},l=[],f=!1,d=!1;if("function"!=typeof t.performance.getEntries||"function"!=typeof t.performance.mark){for("function"==typeof t.performance.getEntries&&"function"!=typeof t.performance.mark&&(d=!0),t.performance.userTimingJsPerformanceTimeline=!0,i=["webkit","moz"],o=["getEntries","getEntriesByName","getEntriesByType"],n=0;n<o.length;n++)for(r=0;r<i.length;r++)a=i[r]+o[n].substr(0,1).toUpperCase()+o[n].substr(1),"function"==typeof t.performance[a]&&(t.performance[o[n]]=t.performance[a],t.performance.userTimingJsPerformanceTimelinePrefixed=!0);c=function(e){l.push(e),"measure"===e.entryType&&(f=!0)};var g=function(){f&&(l.sort(function(e,t){return e.startTime-t.startTime}),f=!1)};if(u=function(e,t){for(n=0;n<l.length;)l[n].entryType!==e||void 0!==t&&l[n].name!==t?n++:l.splice(n,1)},"function"!=typeof t.performance.getEntries||d){var p=t.performance.getEntries;t.performance.getEntries=function(){g();var e=l.slice(0);return d&&p&&(Array.prototype.push.apply(e,p.call(t.performance)),e.sort(function(e,t){return e.startTime-t.startTime})),e}}if("function"!=typeof t.performance.getEntriesByType||d){var h=t.performance.getEntriesByType;t.performance.getEntriesByType=function(e){if(void 0===e||"mark"!==e&&"measure"!==e)return d&&h?h.call(t.performance,e):[];"measure"===e&&g();var r=[];for(n=0;n<l.length;n++)l[n].entryType===e&&r.push(l[n]);return r}}if("function"!=typeof t.performance.getEntriesByName||d){var m=t.performance.getEntriesByName;t.performance.getEntriesByName=function(e,r){if(r&&"mark"!==r&&"measure"!==r)return d&&m?m.call(t.performance,e,r):[];void 0!==r&&"measure"===r&&g();var i=[];for(n=0;n<l.length;n++)void 0!==r&&l[n].entryType!==r||l[n].name===e&&i.push(l[n]);return d&&m&&(Array.prototype.push.apply(i,m.call(t.performance,e,r)),i.sort(function(e,t){return e.startTime-t.startTime})),i}}}if("function"!=typeof t.performance.mark){for(t.performance.userTimingJsUserTiming=!0,i=["webkit","moz","ms"],o=["mark","measure","clearMarks","clearMeasures"],n=0;n<o.length;n++)for(r=0;r<i.length;r++)a=i[r]+o[n].substr(0,1).toUpperCase()+o[n].substr(1),"function"==typeof t.performance[a]&&(t.performance[o[n]]=t.performance[a],t.performance.userTimingJsUserTimingPrefixed=!0);var v={};"function"!=typeof t.performance.mark&&(t.performance.mark=function(e){var n=t.performance.now();if(void 0===e)throw new SyntaxError("Mark name must be specified");if(t.performance.timing&&e in t.performance.timing)throw new SyntaxError("Mark name is not allowed");v[e]||(v[e]=[]),v[e].push(n),c({entryType:"mark",name:e,startTime:n,duration:0})}),"function"!=typeof t.performance.clearMarks&&(t.performance.clearMarks=function(e){e?v[e]=[]:v={},u("mark",e)}),"function"!=typeof t.performance.measure&&(t.performance.measure=function(e,n,r){var i=t.performance.now();if(void 0===e)throw new SyntaxError("Measure must be specified");if(n){var o=0;if(t.performance.timing&&n in t.performance.timing){if("navigationStart"!==n&&0===t.performance.timing[n])throw new Error(n+" has a timing of 0");o=t.performance.timing[n]-t.performance.timing.navigationStart}else{if(!(n in v))throw new Error(n+" mark not found");o=v[n][v[n].length-1]}var a=i;if(r)if(a=0,t.performance.timing&&r in t.performance.timing){if("navigationStart"!==r&&0===t.performance.timing[r])throw new Error(r+" has a timing of 0");a=t.performance.timing[r]-t.performance.timing.navigationStart}else{if(!(r in v))throw new Error(r+" mark not found");a=v[r][v[r].length-1]}c({entryType:"measure",name:e,startTime:o,duration:a-o})}else c({entryType:"measure",name:e,startTime:0,duration:i})}),"function"!=typeof t.performance.clearMeasures&&(t.performance.clearMeasures=function(e){u("measure",e)})}e.exports=t.performance}("undefined"!=typeof window?window:void 0)}),_isObject=function(e){return"object"==typeof e?null!==e:"function"==typeof e},_anObject=function(e){if(!_isObject(e))throw TypeError(e+" is not an object!");return e},_fails=function(e){try{return!!e()}catch(e){return!0}},_descriptors=!_fails(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a}),_global=createCommonjsModule(function(e){var t=e.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=t)}),document$1=_global.document,is=_isObject(document$1)&&_isObject(document$1.createElement),_domCreate=function(e){return is?document$1.createElement(e):{}},_ie8DomDefine=!_descriptors&&!_fails(function(){return 7!=Object.defineProperty(_domCreate("div"),"a",{get:function(){return 7}}).a}),_toPrimitive=function(e,t){if(!_isObject(e))return e;var n,r;if(t&&"function"==typeof(n=e.toString)&&!_isObject(r=n.call(e)))return r;if("function"==typeof(n=e.valueOf)&&!_isObject(r=n.call(e)))return r;if(!t&&"function"==typeof(n=e.toString)&&!_isObject(r=n.call(e)))return r;throw TypeError("Can't convert object to primitive value")},dP=Object.defineProperty,f=_descriptors?Object.defineProperty:function(e,t,n){if(_anObject(e),t=_toPrimitive(t,!0),_anObject(n),_ie8DomDefine)try{return dP(e,t,n)}catch(e){}if("get"in n||"set"in n)throw TypeError("Accessors not supported!");return"value"in n&&(e[t]=n.value),e},_objectDp={f:f},_propertyDesc=function(e,t){return{enumerable:!(1&e),configurable:!(2&e),writable:!(4&e),value:t}},_hide=_descriptors?function(e,t,n){return _objectDp.f(e,t,_propertyDesc(1,n))}:function(e,t,n){return e[t]=n,e},hasOwnProperty={}.hasOwnProperty,_has=function(e,t){return hasOwnProperty.call(e,t)},id=0,px=Math.random(),_uid=function(e){return"Symbol(".concat(void 0===e?"":e,")_",(++id+px).toString(36))},_core=createCommonjsModule(function(e){var t=e.exports={version:"2.5.3"};"number"==typeof __e&&(__e=t)}),_redefine=createCommonjsModule(function(e){var t=_uid("src"),n=Function.toString,r=(""+n).split("toString");_core.inspectSource=function(e){return n.call(e)},(e.exports=function(e,n,i,o){var a="function"==typeof i;a&&(_has(i,"name")||_hide(i,"name",n)),e[n]!==i&&(a&&(_has(i,t)||_hide(i,t,e[n]?""+e[n]:r.join(String(n)))),e===_global?e[n]=i:o?e[n]?e[n]=i:_hide(e,n,i):(delete e[n],_hide(e,n,i)))})(Function.prototype,"toString",function(){return"function"==typeof this&&this[t]||n.call(this)})}),_defined=function(e){if(void 0==e)throw TypeError("Can't call method on  "+e);return e},SHARED="__core-js_shared__",store=_global[SHARED]||(_global[SHARED]={}),_shared=function(e){return store[e]||(store[e]={})},_wks=createCommonjsModule(function(e){var t=_shared("wks"),n=_global.Symbol,r="function"==typeof n;(e.exports=function(e){return t[e]||(t[e]=r&&n[e]||(r?n:_uid)("Symbol."+e))}).store=t}),_fixReWks=function(e,t,n){var r=_wks(e),i=n(_defined,r,""[e]),o=i[0],a=i[1];_fails(function(){var t={};return t[r]=function(){return 7},7!=""[e](t)})&&(_redefine(String.prototype,e,o),_hide(RegExp.prototype,r,2==t?function(e,t){return a.call(e,this,t)}:function(e){return a.call(e,this)}))},toString={}.toString,_cof=function(e){return toString.call(e).slice(8,-1)},MATCH=_wks("match"),_isRegexp=function(e){var t;return _isObject(e)&&(void 0!==(t=e[MATCH])?!!t:"RegExp"==_cof(e))};_fixReWks("split",2,function(e,t,n){var r=_isRegexp,i=n,o=[].push;if("c"=="abbc".split(/(b)*/)[1]||4!="test".split(/(?:)/,-1).length||2!="ab".split(/(?:ab)*/).length||4!=".".split(/(.?)(.?)/).length||".".split(/()()/).length>1||"".split(/.?/).length){var a=void 0===/()??/.exec("")[1];n=function(e,t){var n=String(this);if(void 0===e&&0===t)return[];if(!r(e))return i.call(n,e,t);var s,c,u,l,f,d=[],g=(e.ignoreCase?"i":"")+(e.multiline?"m":"")+(e.unicode?"u":"")+(e.sticky?"y":""),p=0,h=void 0===t?4294967295:t>>>0,m=new RegExp(e.source,g+"g");for(a||(s=new RegExp("^"+m.source+"$(?!\\s)",g));(c=m.exec(n))&&!((u=c.index+c[0].length)>p&&(d.push(n.slice(p,c.index)),!a&&c.length>1&&c[0].replace(s,function(){for(f=1;f<arguments.length-2;f++)void 0===arguments[f]&&(c[f]=void 0)}),c.length>1&&c.index<n.length&&o.apply(d,c.slice(1)),l=c[0].length,p=u,d.length>=h));)m.lastIndex===c.index&&m.lastIndex++;return p===n.length?!l&&m.test("")||d.push(""):d.push(n.slice(p)),d.length>h?d.slice(0,h):d}}else"0".split(void 0,0).length&&(n=function(e,t){return void 0===e&&0===t?[]:i.call(this,e,t)});return[function(r,i){var o=e(this),a=void 0==r?void 0:r[t];return void 0!==a?a.call(r,o,i):n.call(String(o),r,i)},n]});var _iobject=Object("z").propertyIsEnumerable(0)?Object:function(e){return"String"==_cof(e)?e.split(""):Object(e)},_toIobject=function(e){return _iobject(_defined(e))},ceil=Math.ceil,floor=Math.floor,_toInteger=function(e){return isNaN(e=+e)?0:(e>0?floor:ceil)(e)},min=Math.min,_toLength=function(e){return e>0?min(_toInteger(e),9007199254740991):0},max=Math.max,min$1=Math.min,_toAbsoluteIndex=function(e,t){return(e=_toInteger(e))<0?max(e+t,0):min$1(e,t)},_arrayIncludes=function(e){return function(t,n,r){var i,o=_toIobject(t),a=_toLength(o.length),s=_toAbsoluteIndex(r,a);if(e&&n!=n){for(;a>s;)if((i=o[s++])!=i)return!0}else for(;a>s;s++)if((e||s in o)&&o[s]===n)return e||s||0;return!e&&-1}},shared=_shared("keys"),_sharedKey=function(e){return shared[e]||(shared[e]=_uid(e))},arrayIndexOf=_arrayIncludes(!1),IE_PROTO=_sharedKey("IE_PROTO"),_objectKeysInternal=function(e,t){var n,r=_toIobject(e),i=0,o=[];for(n in r)n!=IE_PROTO&&_has(r,n)&&o.push(n);for(;t.length>i;)_has(r,n=t[i++])&&(~arrayIndexOf(o,n)||o.push(n));return o},_enumBugKeys="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(","),_objectKeys=Object.keys||function(e){return _objectKeysInternal(e,_enumBugKeys)},_objectDps=_descriptors?Object.defineProperties:function(e,t){_anObject(e);for(var n,r=_objectKeys(t),i=r.length,o=0;i>o;)_objectDp.f(e,n=r[o++],t[n]);return e},document$2=_global.document,_html=document$2&&document$2.documentElement,IE_PROTO$1=_sharedKey("IE_PROTO"),Empty=function(){},PROTOTYPE="prototype",createDict=function(){var e,t=_domCreate("iframe"),n=_enumBugKeys.length;for(t.style.display="none",_html.appendChild(t),t.src="javascript:",(e=t.contentWindow.document).open(),e.write("<script>document.F=Object<\/script>"),e.close(),createDict=e.F;n--;)delete createDict[PROTOTYPE][_enumBugKeys[n]];return createDict()},_objectCreate=Object.create||function(e,t){var n;return null!==e?(Empty[PROTOTYPE]=_anObject(e),n=new Empty,Empty[PROTOTYPE]=null,n[IE_PROTO$1]=e):n=createDict(),void 0===t?n:_objectDps(n,t)},_redefineAll=function(e,t,n){for(var r in t)_redefine(e,r,t[r],n);return e},_aFunction=function(e){if("function"!=typeof e)throw TypeError(e+" is not a function!");return e},_ctx=function(e,t,n){if(_aFunction(e),void 0===t)return e;switch(n){case 1:return function(n){return e.call(t,n)};case 2:return function(n,r){return e.call(t,n,r)};case 3:return function(n,r,i){return e.call(t,n,r,i)}}return function(){return e.apply(t,arguments)}},_anInstance=function(e,t,n,r){if(!(e instanceof t)||void 0!==r&&r in e)throw TypeError(n+": incorrect invocation!");return e},_iterCall=function(e,t,n,r){try{return r?t(_anObject(n)[0],n[1]):t(n)}catch(t){var i=e.return;throw void 0!==i&&_anObject(i.call(e)),t}},_iterators={},ITERATOR=_wks("iterator"),ArrayProto=Array.prototype,_isArrayIter=function(e){return void 0!==e&&(_iterators.Array===e||ArrayProto[ITERATOR]===e)},TAG=_wks("toStringTag"),ARG="Arguments"==_cof(function(){return arguments}()),tryGet=function(e,t){try{return e[t]}catch(e){}},_classof=function(e){var t,n,r;return void 0===e?"Undefined":null===e?"Null":"string"==typeof(n=tryGet(t=Object(e),TAG))?n:ARG?_cof(t):"Object"==(r=_cof(t))&&"function"==typeof t.callee?"Arguments":r},ITERATOR$1=_wks("iterator"),core_getIteratorMethod=_core.getIteratorMethod=function(e){if(void 0!=e)return e[ITERATOR$1]||e["@@iterator"]||_iterators[_classof(e)]},_forOf=createCommonjsModule(function(e){var t={},n={},r=e.exports=function(e,r,i,o,a){var s,c,u,l,f=a?function(){return e}:core_getIteratorMethod(e),d=_ctx(i,o,r?2:1),g=0;if("function"!=typeof f)throw TypeError(e+" is not iterable!");if(_isArrayIter(f)){for(s=_toLength(e.length);s>g;g++)if((l=r?d(_anObject(c=e[g])[0],c[1]):d(e[g]))===t||l===n)return l}else for(u=f.call(e);!(c=u.next()).done;)if((l=_iterCall(u,d,c.value,r))===t||l===n)return l};r.BREAK=t,r.RETURN=n}),_library=!1,PROTOTYPE$1="prototype",$export=function(e,t,n){var r,i,o,a,s=e&$export.F,c=e&$export.G,u=e&$export.S,l=e&$export.P,f=e&$export.B,d=c?_global:u?_global[t]||(_global[t]={}):(_global[t]||{})[PROTOTYPE$1],g=c?_core:_core[t]||(_core[t]={}),p=g[PROTOTYPE$1]||(g[PROTOTYPE$1]={});for(r in c&&(n=t),n)o=((i=!s&&d&&void 0!==d[r])?d:n)[r],a=f&&i?_ctx(o,_global):l&&"function"==typeof o?_ctx(Function.call,o):o,d&&_redefine(d,r,o,e&$export.U),g[r]!=o&&_hide(g,r,a),l&&p[r]!=o&&(p[r]=o)};_global.core=_core,$export.F=1,$export.G=2,$export.S=4,$export.P=8,$export.B=16,$export.W=32,$export.U=64,$export.R=128;var _export=$export,def=_objectDp.f,TAG$1=_wks("toStringTag"),_setToStringTag=function(e,t,n){e&&!_has(e=n?e:e.prototype,TAG$1)&&def(e,TAG$1,{configurable:!0,value:t})},IteratorPrototype={};_hide(IteratorPrototype,_wks("iterator"),function(){return this});var _iterCreate=function(e,t,n){e.prototype=_objectCreate(IteratorPrototype,{next:_propertyDesc(1,n)}),_setToStringTag(e,t+" Iterator")},_toObject=function(e){return Object(_defined(e))},IE_PROTO$2=_sharedKey("IE_PROTO"),ObjectProto=Object.prototype,_objectGpo=Object.getPrototypeOf||function(e){return e=_toObject(e),_has(e,IE_PROTO$2)?e[IE_PROTO$2]:"function"==typeof e.constructor&&e instanceof e.constructor?e.constructor.prototype:e instanceof Object?ObjectProto:null},ITERATOR$2=_wks("iterator"),BUGGY=!([].keys&&"next"in[].keys()),FF_ITERATOR="@@iterator",KEYS="keys",VALUES="values",returnThis=function(){return this},_iterDefine=function(e,t,n,r,i,o,a){_iterCreate(n,t,r);var s,c,u,l=function(e){if(!BUGGY&&e in p)return p[e];switch(e){case KEYS:case VALUES:return function(){return new n(this,e)}}return function(){return new n(this,e)}},f=t+" Iterator",d=i==VALUES,g=!1,p=e.prototype,h=p[ITERATOR$2]||p[FF_ITERATOR]||i&&p[i],m=!BUGGY&&h||l(i),v=i?d?l("entries"):m:void 0,y="Array"==t&&p.entries||h;if(y&&(u=_objectGpo(y.call(new e)))!==Object.prototype&&u.next&&(_setToStringTag(u,f,!0),_library||_has(u,ITERATOR$2)||_hide(u,ITERATOR$2,returnThis)),d&&h&&h.name!==VALUES&&(g=!0,m=function(){return h.call(this)}),_library&&!a||!BUGGY&&!g&&p[ITERATOR$2]||_hide(p,ITERATOR$2,m),_iterators[t]=m,_iterators[f]=returnThis,i)if(s={values:d?m:l(VALUES),keys:o?m:l(KEYS),entries:v},a)for(c in s)c in p||_redefine(p,c,s[c]);else _export(_export.P+_export.F*(BUGGY||g),t,s);return s},_iterStep=function(e,t){return{value:t,done:!!e}},SPECIES=_wks("species"),_setSpecies=function(e){var t=_global[e];_descriptors&&t&&!t[SPECIES]&&_objectDp.f(t,SPECIES,{configurable:!0,get:function(){return this}})},_meta=createCommonjsModule(function(e){var t=_uid("meta"),n=_objectDp.f,r=0,i=Object.isExtensible||function(){return!0},o=!_fails(function(){return i(Object.preventExtensions({}))}),a=function(e){n(e,t,{value:{i:"O"+ ++r,w:{}}})},s=e.exports={KEY:t,NEED:!1,fastKey:function(e,n){if(!_isObject(e))return"symbol"==typeof e?e:("string"==typeof e?"S":"P")+e;if(!_has(e,t)){if(!i(e))return"F";if(!n)return"E";a(e)}return e[t].i},getWeak:function(e,n){if(!_has(e,t)){if(!i(e))return!0;if(!n)return!1;a(e)}return e[t].w},onFreeze:function(e){return o&&s.NEED&&i(e)&&!_has(e,t)&&a(e),e}}}),_validateCollection=function(e,t){if(!_isObject(e)||e._t!==t)throw TypeError("Incompatible receiver, "+t+" required!");return e},dP$1=_objectDp.f,fastKey=_meta.fastKey,SIZE=_descriptors?"_s":"size",getEntry=function(e,t){var n,r=fastKey(t);if("F"!==r)return e._i[r];for(n=e._f;n;n=n.n)if(n.k==t)return n},_collectionStrong={getConstructor:function(e,t,n,r){var i=e(function(e,o){_anInstance(e,i,t,"_i"),e._t=t,e._i=_objectCreate(null),e._f=void 0,e._l=void 0,e[SIZE]=0,void 0!=o&&_forOf(o,n,e[r],e)});return _redefineAll(i.prototype,{clear:function(){for(var e=_validateCollection(this,t),n=e._i,r=e._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];e._f=e._l=void 0,e[SIZE]=0},delete:function(e){var n=_validateCollection(this,t),r=getEntry(n,e);if(r){var i=r.n,o=r.p;delete n._i[r.i],r.r=!0,o&&(o.n=i),i&&(i.p=o),n._f==r&&(n._f=i),n._l==r&&(n._l=o),n[SIZE]--}return!!r},forEach:function(e){_validateCollection(this,t);for(var n,r=_ctx(e,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(e){return!!getEntry(_validateCollection(this,t),e)}}),_descriptors&&dP$1(i.prototype,"size",{get:function(){return _validateCollection(this,t)[SIZE]}}),i},def:function(e,t,n){var r,i,o=getEntry(e,t);return o?o.v=n:(e._l=o={i:i=fastKey(t,!0),k:t,v:n,p:r=e._l,n:void 0,r:!1},e._f||(e._f=o),r&&(r.n=o),e[SIZE]++,"F"!==i&&(e._i[i]=o)),e},getEntry:getEntry,setStrong:function(e,t,n){_iterDefine(e,t,function(e,n){this._t=_validateCollection(e,t),this._k=n,this._l=void 0},function(){for(var e=this._k,t=this._l;t&&t.r;)t=t.p;return this._t&&(this._l=t=t?t.n:this._t._f)?_iterStep(0,"keys"==e?t.k:"values"==e?t.v:[t.k,t.v]):(this._t=void 0,_iterStep(1))},n?"entries":"values",!n,!0),_setSpecies(t)}},ITERATOR$3=_wks("iterator"),SAFE_CLOSING=!1;try{var riter=[7][ITERATOR$3]();riter.return=function(){SAFE_CLOSING=!0}}catch(e){}var _iterDetect=function(e,t){if(!t&&!SAFE_CLOSING)return!1;var n=!1;try{var r=[7],i=r[ITERATOR$3]();i.next=function(){return{done:n=!0}},r[ITERATOR$3]=function(){return i},e(r)}catch(e){}return n},f$1={}.propertyIsEnumerable,_objectPie={f:f$1},gOPD=Object.getOwnPropertyDescriptor,f$2=_descriptors?gOPD:function(e,t){if(e=_toIobject(e),t=_toPrimitive(t,!0),_ie8DomDefine)try{return gOPD(e,t)}catch(e){}if(_has(e,t))return _propertyDesc(!_objectPie.f.call(e,t),e[t])},_objectGopd={f:f$2},check=function(e,t){if(_anObject(e),!_isObject(t)&&null!==t)throw TypeError(t+": can't set as prototype!")},_setProto={set:Object.setPrototypeOf||("__proto__"in{}?function(e,t,n){try{(n=_ctx(Function.call,_objectGopd.f(Object.prototype,"__proto__").set,2))(e,[]),t=!(e instanceof Array)}catch(e){t=!0}return function(e,r){return check(e,r),t?e.__proto__=r:n(e,r),e}}({},!1):void 0),check:check},setPrototypeOf=_setProto.set,_inheritIfRequired=function(e,t,n){var r,i=t.constructor;return i!==n&&"function"==typeof i&&(r=i.prototype)!==n.prototype&&_isObject(r)&&setPrototypeOf&&setPrototypeOf(e,r),e},_collection=function(e,t,n,r,i,o){var a=_global[e],s=a,c=i?"set":"add",u=s&&s.prototype,l={},f=function(e){var t=u[e];_redefine(u,e,"delete"==e?function(e){return!(o&&!_isObject(e))&&t.call(this,0===e?0:e)}:"has"==e?function(e){return!(o&&!_isObject(e))&&t.call(this,0===e?0:e)}:"get"==e?function(e){return o&&!_isObject(e)?void 0:t.call(this,0===e?0:e)}:"add"==e?function(e){return t.call(this,0===e?0:e),this}:function(e,n){return t.call(this,0===e?0:e,n),this})};if("function"==typeof s&&(o||u.forEach&&!_fails(function(){(new s).entries().next()}))){var d=new s,g=d[c](o?{}:-0,1)!=d,p=_fails(function(){d.has(1)}),h=_iterDetect(function(e){new s(e)}),m=!o&&_fails(function(){for(var e=new s,t=5;t--;)e[c](t,t);return!e.has(-0)});h||((s=t(function(t,n){_anInstance(t,s,e);var r=_inheritIfRequired(new a,t,s);return void 0!=n&&_forOf(n,i,r[c],r),r})).prototype=u,u.constructor=s),(p||m)&&(f("delete"),f("has"),i&&f("get")),(m||g)&&f(c),o&&u.clear&&delete u.clear}else s=r.getConstructor(t,e,i,c),_redefineAll(s.prototype,n),_meta.NEED=!0;return _setToStringTag(s,e),l[e]=s,_export(_export.G+_export.W+_export.F*(s!=a),l),o||r.setStrong(s,e,i),s},SET="Set",es6_set=_collection(SET,function(e){return function(){return e(this,arguments.length>0?arguments[0]:void 0)}},{add:function(e){return _collectionStrong.def(_validateCollection(this,SET),e=0===e?0:e,e)}},_collectionStrong),_createProperty=function(e,t,n){t in e?_objectDp.f(e,t,_propertyDesc(0,n)):e[t]=n};_export(_export.S+_export.F*!_iterDetect(function(e){}),"Array",{from:function(e){var t,n,r,i,o=_toObject(e),a="function"==typeof this?this:Array,s=arguments.length,c=s>1?arguments[1]:void 0,u=void 0!==c,l=0,f=core_getIteratorMethod(o);if(u&&(c=_ctx(c,s>2?arguments[2]:void 0,2)),void 0==f||a==Array&&_isArrayIter(f))for(n=new a(t=_toLength(o.length));t>l;l++)_createProperty(n,l,u?c(o[l],l):o[l]);else for(i=f.call(o),n=new a;!(r=i.next()).done;l++)_createProperty(n,l,u?_iterCall(i,c,[r.value,l],!0):r.value);return n.length=l,n}});var f$3=Object.getOwnPropertySymbols,_objectGops={f:f$3},$assign=Object.assign,_objectAssign=!$assign||_fails(function(){var e={},t={},n=Symbol(),r="abcdefghijklmnopqrst";return e[n]=7,r.split("").forEach(function(e){t[e]=e}),7!=$assign({},e)[n]||Object.keys($assign({},t)).join("")!=r})?function(e,t){for(var n=_toObject(e),r=arguments.length,i=1,o=_objectGops.f,a=_objectPie.f;r>i;)for(var s,c=_iobject(arguments[i++]),u=o?_objectKeys(c).concat(o(c)):_objectKeys(c),l=u.length,f=0;l>f;)a.call(c,s=u[f++])&&(n[s]=c[s]);return n}:$assign;_export(_export.S+_export.F,"Object",{assign:_objectAssign});var prefix="ads.";function emitEvent(e,t,n){window.cnBus.emit(prefix+t+"."+e,n)}var levels={debug:emitEvent.bind(null,"debug"),info:emitEvent.bind(null,"info"),warn:emitEvent.bind(null,"warn"),error:emitEvent.bind(null,"error")},debug=levels.debug,error=levels.error,warn=levels.warn,styling={debug:"color:darkgreen",info:"color:darkblue"};function EventEmitter(e){return Object.keys(levels).reduce(function(t,n){return t[n]=function(t,r){return levels[n](e+"."+t,r)},t},{})}function addStyling(e,t){styling[e]&&(t[1]&&(t[2]=t[1]),t[0]="%c"+t[0],t[1]=styling[e])}function render(e,t){var n=t.topic,r=n.split("."),i=r[r.length-1],o=console[i],a=[n];e&&a.push(e),addStyling(i,a),o.apply(console,a)}function addDefaultSubscriptions(e,t){t&&e.on("ads.#.debug",render),e.on("ads.#.info",render),e.on("ads.#.warn",render),e.on("ads.#.error",render)}function handlePromiseError(e){return function(t){return emitEvent("error",e,t)}}function pathToArray(e){return e.split?e.split("."):e}function get(e,t){t=pathToArray(t);for(var n=0;e&&n<t.length;n++)e=e[t[n]];return e}function set(e,t,n){for(var r=(t=pathToArray(t)).length-1,i=t[r],o=0;o<r;o++){var a=t[o];!e[a]&&o<r&&(e[a]={}),e=e[t[o]]}return{oldValue:e&&e[i],newValue:e&&(e[i]=n)}}function pick(e,t){var n={};return t.forEach(function(t){var r=get(e,t);r&&set(n,t,r)}),n}function convertSizeToString(e){Array.isArray(e)&&e.map(function(e){return Array.isArray(e)?e.join("x"):e}).join()}function getSizesObjectToString(e){return e.getSizes(window.innerWidth,window.innerHeight).map(function(e){return"object"==typeof e?e.getWidth()+"x"+e.getHeight():e}).join()}function SlotMetricsReport(e){var t=e.slot.getSlotElementId();Object.defineProperties(this,{adUnitPath:{value:e.slot.getAdUnitPath(),writable:!1,enumerable:!0},advertiserId:{value:e.advertiserId,writable:!1,enumerable:!0},campaignId:{value:e.campaignId,writable:!1,enumerable:!0},creativeId:{value:e.creativeId,writable:!1,enumerable:!0},isBackfill:{value:e.isBackfill,writable:!1,enumerable:!0},isEmpty:{value:e.isEmpty,writable:!1,enumerable:!0},lineItemId:{value:e.lineItemId,writable:!1,enumerable:!0},outOfPage:{value:e.slot.getOutOfPage(),writable:!1,enumerable:!0},requested:{value:Date.now(),writable:!1,enumerable:!0},size:{value:convertSizeToString(e.size),writable:!1,enumerable:!0},sizes:{value:getSizesObjectToString(e.slot),writable:!1,enumerable:!0},slotElementId:{value:t,writable:!1,enumerable:!0},instance:{value:t.split("_").pop(),writable:!1,enumerable:!0},slotTargeting:{value:e.slot.getTargetingMap(),writable:!1,enumerable:!0}}),Object.freeze(this)}Object.assign({emitEvent:emitEvent,EventEmitter:EventEmitter,handlePromiseError:handlePromiseError},levels,{addDefaultSubscriptions:addDefaultSubscriptions});var cloneArray=function(e){return Array.prototype.slice.apply(e)},debounce=function(e,t){var n;return function(){var r=this,i=arguments;clearTimeout(n),n=setTimeout(function(){return e.apply(r,i)},t)}},cumulativeArgumentDebounce=function(e,t){var n,r=[];return function(){var i=this;r.push(cloneArray(arguments)),clearTimeout(n),n=setTimeout(function(){e.apply(i,[cloneArray(r)]),r.length=0},t)}},errorMessage="Ads -- Missing page context",errorParamMessage=errorMessage+" parameter : ",requiredKeys=["templateType"],expectedKeys=["channel","server"];function validate(e){requiredKeys.forEach(function(t){!e.templateType&&error(""+errorParamMessage+t)}),expectedKeys.forEach(function(t){!e[t]&&warn(""+errorParamMessage+t)})}function getPageContext(e){var t=e.cns&&e.cns.pageContext;if(t)return t.templateType=t.templateType||t.template_type,t.subChannel=t.subChannel||t.sub_channel,validate(t),t;error(errorMessage)}var bufferPeriod=1e3,startTs=Date.now(),fields=["adUnitPath","advertiserId","campaignId","companyIds","creativeId","creativeTemplateId","device","instance","inViewPercentage","isBackfill","isEmpty","isEmpty","isFirstImpression","isFirstImpressionViewable","isFirstMoneyImpression","isFirstMoneyImpressionViewable","isFirstMoneyRequested","isFirstRequested","isRefresh","labelIds","lineItemId","outOfPage","requestNumber","size","sizes","slotElementId","slotTargeting","sourceAgnosticCreativeId","sourceAgnosticLineItemId"],sentPageTargeting=!1,slotsWiped=[],sendEvent=cumulativeArgumentDebounce(function(e){var t=e.map(function(e){return e[0]}),n=JSON.stringify(t)||"",r="https://wren.condenastdigital.com/1.0/conde/events?topic=wren.events.ads&api_key=d3Jlbg",i=!1;if(navigator&&"function"==typeof navigator.sendBeacon&&"function"==typeof window.Blob&&(i=navigator.sendBeacon(r,n)),!i)if(n.length<1500){var o=r+"&data="+encodeURIComponent(n);(new Image).src=o}else{var a=new XMLHttpRequest;a.open("POST",r,!0),a.setRequestHeader("Content-type","application/json"),a.send(n)}},bufferPeriod);function delta(){return parseFloat(((Date.now()-startTs)/1e3).toFixed(1))}function decorate(e){return e.delta=delta(),e.pageContext=getPageContext(window),get(e,"pageContext.device")&&delete e.pageContext.device,e._device=!0,e._geo=!0,e._did=!0,e._ref=!0,e._xid=!0,e._key=get(window,"cns.runtimeId"),e}function add(e){sendEvent(decorate(e))}function onStart(){var e={type:"page"};e.targeting=getPageTargeting(),add(e)}function slotEventPayload(e,t){var n={},r=new SlotMetricsReport(e);return fields.forEach(function(i){null!=r[i]&&(n[i]=r[i]),null!=e[i]&&(n[i]=e[i]),null!=t[i]&&(n[i]=t[i])}),n.companyIds&&!n.companyIds.length&&delete n.companyIds,decorate(n),n}function checkForWipedAdSlots(){window.googletag.pubads().getSlots().forEach(function(e){var t=e.getSlotElementId();document.getElementById(t)||-1!==slotsWiped.indexOf(t)||(slotsWiped.push(t),add({type:"slot.wiped",slotId:t}))})}function markStart(){startTs=Date.now(),window.cnBus.on("ads.environment.adblock.detected",function(){return add({type:"adblock",detected:!0})}),window.cnBus.on("ads.environment.adblock.notdetected",function(){return add({type:"adblock",detected:!1})})}function onPubadsReady(){markStart(),add({type:"pubadsReady"})}function onSlotRenderEnded(e,t){void 0===t&&(t={});var n=slotEventPayload(e,t);n.type="slotRenderEnded",sendEvent(n),sentPageTargeting||(sentPageTargeting=!0,onStart()),checkForWipedAdSlots()}function onImpressionViewable(e,t){void 0===t&&(t={});var n=slotEventPayload(e,t);n.type="impressionViewable",sendEvent(n)}var wren={add:add,markStart:markStart,onImpressionViewable:onImpressionViewable,onPubadsReady:onPubadsReady,onSlotRenderEnded:onSlotRenderEnded,onStart:onStart,sendEvent:sendEvent},minInterval=50;function deprecated(e,t){return void 0===t&&(t="unnamed"),function(){warn("function "+t+" is deprecated"),wren.add({type:"deprecatedFunctionCall",name:t});for(var n=arguments.length,r=new Array(n),i=0;i<n;i++)r[i]=arguments[i];return e.apply(null,r)}}function til(e,t,n){n=Math.max(n||minInterval,minInterval);try{if(e())try{return t()}catch(e){error("til",e)}}catch(e){}setTimeout(til.bind(null,e,t,n),n)}function find(e,t){for(var n=0;n<e.length;n++)if(t(e[n]))return e[n]}function any(e,t){return!!find(e,t)}function all(e,t){for(var n=0;n<e.length;n++)if(!t(e[n]))return!1;return!0}function uniq(e){return Array.from(new Set(e))}function difference(e,t){return e.filter(function(e){return-1===t.indexOf(e)})}function applyTargeting(e,t){Object.keys(t).forEach(function(n){return e.setTargeting(n,t[n])})}function shouldSetSlotSize(e,t,n){var r=e&&Array.isArray(e),i=e&&2===e.length&&e[0]===e[1]===1;return n.hasStaticRefreshSize&&r&&!t&&!i}function getPageTargeting(){var e=window.googletag.pubads();return e.getTargetingKeys().reduce(function(t,n){return t[n]=e.getTargeting(n),t},{})}function setSlotSize(e,t,n){t.defineSizeMapping(e.sizeMapping().addSize([0,0],n).build())}function getSizeStringAsArray(e){return"fluid"===e?e:e.split("x").map(function(e){return parseInt(e,10)})}function sizesToArray(e){return e?e.map(getSizeStringAsArray):[]}function getSlotById(e){return find(window.googletag.pubads().getSlots(),function(t){return t.getSlotElementId()===e})}function getSizeMapping(e){var t=e.getSizeMapping(),n=t.desktop,r=t.tablet,i=t.mobile;return window.googletag.sizeMapping().addSize([1024,0],n).addSize([768,0],r).addSize([0,0],i).build()}var fastdom=createCommonjsModule(function(e){!function(t){var n=t.requestAnimationFrame||t.webkitRequestAnimationFrame||t.mozRequestAnimationFrame||t.msRequestAnimationFrame||function(e){return setTimeout(e,16)};function r(){this.reads=[],this.writes=[],this.raf=n.bind(t)}function i(e){e.scheduled||(e.scheduled=!0,e.raf(function(e){var t,n=e.writes,r=e.reads;try{o(r),o(n)}catch(e){t=e}if(e.scheduled=!1,(r.length||n.length)&&i(e),t){if(!e.catch)throw t;e.catch(t)}}.bind(null,e)))}function o(e){for(var t;t=e.shift();)t()}function a(e,t){var n=e.indexOf(t);return!!~n&&!!e.splice(n,1)}r.prototype={constructor:r,measure:function(e,t){var n=t?e.bind(t):e;return this.reads.push(n),i(this),n},mutate:function(e,t){var n=t?e.bind(t):e;return this.writes.push(n),i(this),n},clear:function(e){return a(this.reads,e)||a(this.writes,e)},extend:function(e){if("object"!=typeof e)throw new Error("expected object");var t=Object.create(this);return function(e,t){for(var n in t)t.hasOwnProperty(n)&&(e[n]=t[n])}(t,e),t.fastdom=this,t.initialize&&t.initialize(),t},catch:null};var s=t.fastdom=t.fastdom||new r;e.exports=s}("undefined"!=typeof window?window:commonjsGlobal)});function domCall(e,t,n){return n||(n=e,e=document),e[t](n)}function getElementById(e,t){return domCall(e,"getElementById",t)}function find$1(e,t){return domCall(e,"querySelector",t)}function findAll(e,t){return Array.prototype.slice.call(domCall(e,"querySelectorAll",t))}function setStyle(e,t){for(var n=Object.keys(t),r=0;r<n.length;r++){var i=n[r];e.style[i]=t[i]}}function addClasses(e,t){for(var n=Object.keys(t),r=0;r<n.length;r++)e.classList.add(t[n[r]])}function setElementData(e,t){for(var n=Object.keys(t),r=0;r<n.length;r++){var i=n[r];e.setAttribute("data-"+i,t[i])}}function createElement(e,t){var n=document.createElement(e);return t&&Object.keys(t).forEach(function(e){n[e]=t[e]}),n}var defaultStyles='.cns-ads-stage {margin: 0 auto;padding: 0;width: 100%;}[data-slot-type="_out_of_page"] {position: absolute;z-index: -1;}.cns-ads-flex-sizer {display: none;}',flexStyles='.cns-ads-stage.cns-ads-flex {display: block;position: relative;}.cns-ads-flex .cns-ads-flex-sizer {display: block;width: 100%;}.cns-ads-flex .cns-ads-container,.cns-ads-flex iframe[id^="google_ads_iframe"],.cns-ads-flex div[id*="google_ads_iframe"] {position: absolute;left: 0;top: 0;right: 0;bottom: 0;height: 100% !important;width: 100% !important;}.full-screen .cns-ads-container,.full-screen iframe[id^="google_ads_iframe"],.full-screen div[id*="google_ads_iframe"] {height: 100vh !important;width: 100vw !important;}',versoStyles='iframe[id^="google_ads_iframe"],div[id*="google_ads_iframe"] {margin: 0 auto;padding: 0;}.cns-ads-slot-size-9x1 iframe[id^="google_ads_iframe"],.cns-ads-slot-size-9x1 div[id*="google_ads_iframe"] {height: 0;width: 100%;min-width: 100%;}',legacyStyles='iframe[id^="google_ads_iframe"],div[id*="google_ads_iframe"] {margin: 0 auto;padding: 0;height: 0;width: 100%;min-width: 100%;}',isCNSAdsSlotSizeClassRegex=new RegExp(/^cns-ads-slot-size-/);function ContainerStyler(e){var t=new EventEmitter("ContainerStyler").debug,n=["3x1","4x1","8x1","10x1","16x9"],r=["2x1"];function i(e,t){setStyle(e,{height:t[1]+"px",minHeight:t[1]+"px",width:t[0]+"px",minWidth:t[0]+"px"})}function o(e,t){return e&&2===e.length&&t.indexOf(e[0]+"x"+e[1])>-1}!function(){var t=createElement("style"),n=t.styleSheet;t.classList.add("cns-ads-iframe-styles"),t.type="text/css";var r=defaultStyles+flexStyles;r+=e?versoStyles:legacyStyles,n?n.cssText=r:t.appendChild(document.createTextNode(r)),fastdom.mutate(function(){document.head.appendChild(t)})}(),this.updateContainer=function(a,s){var c,u=s.isEmpty,l=s.size,f=s.slot,d=a.parentNode;t("ContainerStyler",{container:a,stage:d,isEmpty:u,size:l,id:f.getSlotElementId()}),function(e){var t=e.classList;t.remove("cns-ads-slot-state-empty");for(var n=0;n<t.length;n++)isCNSAdsSlotSizeClassRegex.test(t[n])&&t.remove(t[n])}(d),u?function(e,t){var n=t.classList;n.remove("cns-ads-slot-state-filled"),n.add("cns-ads-slot-state-empty"),setStyle(e,{height:"0px",width:"0px",minWidth:"0px",minHeight:"0px"})}(a,d):(function(e,t){addClasses(e,["cns-ads-slot-state-filled","cns-ads-slot-size-"+(t&&t[0]&&t[1]&&t[0]+"x"+t[1])])}(d,l),o(l,n)?function(e,t){var n=parseFloat(e[1])/parseFloat(e[0])*100,r=t.parentNode;r.classList.add("cns-ads-flex"),r.querySelector(".cns-ads-flex-sizer").style.paddingTop=n+"%"}(l,a):o(l,r)&&function(e){e.parentNode.classList.add("full-screen")}(a),e||(c=["height","width","padding","margin"],[a,d].forEach(function(e){c.forEach(function(t){e.removeAttribute(t)})}),function(e){return 9===e[0]}(l)||function(e,t,n){var r='[id^="google_ads_iframe"]:not([id$="to_be_removed__"]):not([id$="hidden__"])',o=find$1(t,"iframe"+r),a=find$1(t,"div"+r);i(e,n),i(o,n),i(a,n)}(a,d,l)))}}function getCookie(e,t){for(var n=(t=t||document.cookie).split(";"),r=RegExp("^\\s*"+e+"=\\s*(.*?)\\s*$"),i=0;i<n.length;i++){var o=n[i].match(r);if(o)return o[1]}}_fixReWks("replace",2,function(e,t,n){return[function(r,i){var o=e(this),a=void 0==r?void 0:r[t];return void 0!==a?a.call(r,o,i):n.call(String(o),r,i)},n]}),_fixReWks("match",1,function(e,t,n){return[function(n){var r=e(this),i=void 0==n?void 0:n[t];return void 0!==i?i.call(n,r):new RegExp(n)[t](String(r))},n]});var alphanumeric=new RegExp(/[^a-zA-Z0-9]/g),cookieKey="CN_xid",isValidLength=function(e){return e.length>=32&&e.length<=150};function getPPID(){var e=getCookie(cookieKey);if(!e)return!1;var t=e.replace(alphanumeric,"");return isValidLength(t)&&t}function setPPID(e){var t=getPPID();t&&e.setPublisherProvidedId(t)}function updateCorrelatorInterval(){set(window,"cns.flags.shouldCorrelatorUpdate",!0);var e=setInterval(function(){get(window,"cns.flags.shouldCorrelatorUpdate")?window.googletag.pubads().updateCorrelator():clearInterval(e)},3e4)}var dP$2=_objectDp.f,FProto=Function.prototype,nameRE=/^\s*function ([^ (]*)/,NAME="name";function pixel(e){var t=e.campaign,n=e.name,r=e.meta;window.sparrowQueue.push(function(){window.sparrow.track(t,n,r)})}NAME in FProto||_descriptors&&dP$2(FProto,NAME,{configurable:!0,get:function(){try{return(""+this).match(nameRE)[1]}catch(e){return""}}}),window.sparrowQueue=window.sparrowQueue||[];var version="6.32.14",eventMatcher={slotImpressionViewable:"slot_impression_viewable",slotRendered:"slot_rendered",slotImpression:"slot_loaded",slotRequested:"slot_requested"};function transformPayload(e){var t=e.slotTargeting,n=e.pageTargeting;return{dim1:JSON.stringify({adBlock:n.adblock&&n.adblock.join(),channel:e.channel,device:e.device,server:e.server,subChannel:e.subChannel,template:e.templateType,version:e.version}),dim2:JSON.stringify({adUnitPath:e.adUnitPath,advertiserId:e.advertiserId,campaignId:e.campaignId,creativeId:e.creativeId,elementId:e.slotElementId,instance:e.instance,isBackfill:e.isBackfill,isEmpty:e.isEmpty,isFirstImpression:e.isFirstImpression,isFirstImpressionViewable:e.isFirstImpressionViewable,isFirstRequested:e.isFirstRequested,isFirstMoneyImpression:e.isFirstMoneyImpression,isFirstMoneyImpressionViewable:e.isFirstMoneyImpressionViewable,isFirstMoneyRequested:e.isFirstMoneyRequested,isRefresh:e.requestNumber>0,keywords:e.keywords,lineItemId:e.lineItemId,name:t.ctx_slot_name&&t.ctx_slot_name.join(),outOfPage:e.outOfPage,requestNumber:e.requestNumber.toString(),size:e.size,sizes:e.sizes,slug:e.slug,suffix:e.suffix}),dim3:JSON.stringify({footerStart:e.footerStart,headerStart:e.headerStart,navigationStart:get(performance,"timing.navigationStart"),injected:e.injected,viewable:e.viewable,viewport:e.viewport,impression:e.impression}),dim4:JSON.stringify(Object.assign({},t,n))}}function transformName(e){var t=Object.keys(eventMatcher).filter(function(t){return t===e})[0];return eventMatcher[t]||e}function onPubadsReady$1(){var e={runtimeId:get(window,"cns.runtimeId"),pageContext:getPageContext(window),version:version};pixel({campaign:"ad_metrics",meta:{dim1:JSON.stringify(e)},name:"pubadsReady"})}function emitSparrowPixel(e,t){pixel({campaign:"cns_ads",name:transformName(e),meta:transformPayload(t)})}var sparrowCollector={emitSparrowPixel:emitSparrowPixel,onPubadsReady:onPubadsReady$1};function setPubadsReadyMetric(){performance.mark("GPT-Init")}function setAdsReadyMetric(){performance.mark("ATP-Init")}function setFirstRequestedMetric(){performance.mark("ATP-First-Request"),performance.measure("ATP-Init-To-First-Request","ATP-Init","ATP-First-Request")}function setFirstMoneyRequestedMetric(){performance.mark("ATP-First-Money-Request"),performance.measure("ATP-Init-To-First-Money-Request","ATP-Init","ATP-First-Money-Request")}function setFirstImpressionMetric(){performance.mark("ATP-First-Impression"),performance.measure("ATP-Init-To-First-Impression","ATP-Init","ATP-First-Impression")}function setFirstMoneyImpressionMetric(){performance.mark("ATP-First-Money-Impression"),performance.measure("ATP-Init-To-First-Money-Impression","ATP-Init","ATP-First-Money-Impression")}function setFirstViewableMetric(){performance.mark("ATP-First-Viewable-Impression"),performance.measure("ATP-Init-To-Viewable-Impression","ATP-Init","ATP-First-Viewable-Impression")}function setFirstMoneyViewableMetric(){performance.mark("ATP-First-Money-Viewable-Impression"),performance.measure("ATP-Init-To-Money-Viewable-Impression","ATP-Init","ATP-First-Money-Viewable-Impression")}window.BOOMR_mq=window.BOOMR_mq||[],window.BOOMR_mq.push(["addVar","cnsLib",version]);var events={adsReady:setAdsReadyMetric,pubadsReady:setPubadsReadyMetric,firstRequested:setFirstRequestedMetric,firstMoneyRequested:setFirstMoneyRequestedMetric,firstImpression:setFirstImpressionMetric,firstMoneyImpression:setFirstMoneyImpressionMetric,firstImpressionViewable:setFirstViewableMetric,firstMoneyImpressionViewable:setFirstMoneyViewableMetric};function emitBoomPixel(e){events[e]?events[e]():error("boomerang-rum-collector.eventNotDefined")}function getViewportTemplate(){var e=window.innerWidth;return e<768?"mobile":e<1024?"tablet":"desktop"}function PubadsCollector(){var e=getViewportTemplate(),t={},n={isFirstRequested:!1,isFirstImpression:!1,isImpressionViewable:!1},r=!0,i=!0,o=!0;function a(e,t,r,i){var o=t.slot,a=o.getOutOfPage(),s=o.getAdUnitPath().match(/\.cm\//),c=t.isEmpty;return a||s||c||(n[e]=n[e]?n[e]:r+i),n[e]&&n[e]===r+i}this.emitReady=function(){var e=get(window,"cns.timing.pubadsReady")||Date.now();set(window,"cns.timing.pubadsReady",e),wren.onPubadsReady(),sparrowCollector.onPubadsReady(),emitBoomPixel("pubadsReady")},this.onSlotRenderEnded=function(n){var i=n.slot.getSlotElementId(),o=t[i]||{},s=function(e){var n=new SlotMetricsReport(e),r=t[e.slot.getAdUnitPath()]||{},i=window.cns,o=getPageContext(window),a=getPageTargeting(),s=i.timing||{};return Object.assign({},r,n,o,{pageTargeting:a,version:version},s)}(n),c=o&&o.requestNumber>=0?o.requestNumber+1:0,u=a("isFirstRequested",n,i,c),l={device:e,adBlock:get(window,"cns.pageContext.adBlock")||!1,isRefresh:o&&o.requestNumber>=0,requestNumber:c,injected:Date.now(),isFirstMoneyRequested:u,isFirstRequested:r,viewport:"",impression:"",viewable:""},f=Object.assign(o,l,s);t[i]=f,sparrowCollector.emitSparrowPixel("slotRendered",f),wren.onSlotRenderEnded(n,l),r&&(emitBoomPixel("firstRequested"),r=!1),u&&emitBoomPixel("firstMoneyRequested")},this.onSlotOnload=function(e){var n=e.slot.getSlotElementId(),r=t[n];r&&(r.isFirstMoneyImpression=a("isFirstImpression",e,n,r.requestNumber),r.isFirstImpression=i,r.impression=r.impression||Date.now(),r.isFirstMoneyImpression&&emitBoomPixel("firstMoneyImpression"),i&&(emitBoomPixel("firstImpression"),i=!1))},this.onImpressionViewable=function(e){var n=e.slot.getSlotElementId(),r=t[n]||{};r.viewable=r.viewable||Date.now(),r.isFirstMoneyImpressionViewable=a("isImpressionViewable",e,n,r.requestNumber),r.isFirstImpressionViewable=o,sparrowCollector.emitSparrowPixel("slotImpressionViewable",r),wren.onImpressionViewable(e,r),r.isFirstMoneyImpressionViewable&&emitBoomPixel("firstMoneyImpressionViewable"),o&&(emitBoomPixel("firstImpressionViewable"),o=!1)}}var UNSCOPABLES=_wks("unscopables"),ArrayProto$1=Array.prototype;void 0==ArrayProto$1[UNSCOPABLES]&&_hide(ArrayProto$1,UNSCOPABLES,{});var _addToUnscopables=function(e){ArrayProto$1[UNSCOPABLES][e]=!0},$includes=_arrayIncludes(!0);_export(_export.P,"Array",{includes:function(e){return $includes(this,e,arguments.length>1?arguments[1]:void 0)}}),_addToUnscopables("includes");var stickySizes=["728x90","970x90","300x50","320x50","10x1","8x1","3x1"],stickyIsSize=function(e){return stickySizes.includes(e)};function stickyIsEligible(e,t,n){return"hero_0"===e&&!!t.isSticky&&Array.isArray(n)&&stickyIsSize(n.join("x"))}function isStickyDeviceEnabled(e,t){return!0===e||!!e&&!!e[t]}var es6_array_iterator=_iterDefine(Array,"Array",function(e,t){this._t=_toIobject(e),this._i=0,this._k=t},function(){var e=this._t,t=this._k,n=this._i++;return!e||n>=e.length?(this._t=void 0,_iterStep(1)):_iterStep(0,"keys"==t?n:"values"==t?e[n]:[n,e[n]])},"values");_iterators.Arguments=_iterators.Array,_addToUnscopables("keys"),_addToUnscopables("values"),_addToUnscopables("entries");for(var ITERATOR$4=_wks("iterator"),TO_STRING_TAG=_wks("toStringTag"),ArrayValues=_iterators.Array,DOMIterables={CSSRuleList:!0,CSSStyleDeclaration:!1,CSSValueList:!1,ClientRectList:!1,DOMRectList:!1,DOMStringList:!1,DOMTokenList:!0,DataTransferItemList:!1,FileList:!1,HTMLAllCollection:!1,HTMLCollection:!1,HTMLFormElement:!1,HTMLSelectElement:!1,MediaList:!0,MimeTypeArray:!1,NamedNodeMap:!1,NodeList:!0,PaintRequestList:!1,Plugin:!1,PluginArray:!1,SVGLengthList:!1,SVGNumberList:!1,SVGPathSegList:!1,SVGPointList:!1,SVGStringList:!1,SVGTransformList:!1,SourceBufferList:!1,StyleSheetList:!0,TextTrackCueList:!1,TextTrackList:!1,TouchList:!1},collections=_objectKeys(DOMIterables),i=0;i<collections.length;i++){var NAME$1=collections[i],explicit=DOMIterables[NAME$1],Collection=_global[NAME$1],proto=Collection&&Collection.prototype,key;if(proto&&(proto[ITERATOR$4]||_hide(proto,ITERATOR$4,ArrayValues),proto[TO_STRING_TAG]||_hide(proto,TO_STRING_TAG,NAME$1),_iterators[NAME$1]=ArrayValues,explicit))for(key in es6_array_iterator)proto[key]||_redefine(proto,key,es6_array_iterator[key],!0)}var _strictMethod=function(e,t){return!!e&&_fails(function(){t?e.call(null,function(){},1):e.call(null)})},$sort=[].sort,test=[1,2,3];_export(_export.P+_export.F*(_fails(function(){test.sort(void 0)})||!_fails(function(){test.sort(null)})||!_strictMethod($sort)),"Array",{sort:function(e){return void 0===e?$sort.call(_toObject(this)):$sort.call(_toObject(this),_aFunction(e))}});var SPECIES$1=_wks("species"),_speciesConstructor=function(e,t){var n,r=_anObject(e).constructor;return void 0===r||void 0==(n=_anObject(r)[SPECIES$1])?t:_aFunction(n)},_invoke=function(e,t,n){var r=void 0===n;switch(t.length){case 0:return r?e():e.call(n);case 1:return r?e(t[0]):e.call(n,t[0]);case 2:return r?e(t[0],t[1]):e.call(n,t[0],t[1]);case 3:return r?e(t[0],t[1],t[2]):e.call(n,t[0],t[1],t[2]);case 4:return r?e(t[0],t[1],t[2],t[3]):e.call(n,t[0],t[1],t[2],t[3])}return e.apply(n,t)},process$1=_global.process,setTask=_global.setImmediate,clearTask=_global.clearImmediate,MessageChannel=_global.MessageChannel,Dispatch=_global.Dispatch,counter=0,queue={},ONREADYSTATECHANGE="onreadystatechange",defer,channel,port,run=function(){var e=+this;if(queue.hasOwnProperty(e)){var t=queue[e];delete queue[e],t()}},listener=function(e){run.call(e.data)};setTask&&clearTask||(setTask=function(e){for(var t=[],n=1;arguments.length>n;)t.push(arguments[n++]);return queue[++counter]=function(){_invoke("function"==typeof e?e:Function(e),t)},defer(counter),counter},clearTask=function(e){delete queue[e]},"process"==_cof(process$1)?defer=function(e){process$1.nextTick(_ctx(run,e,1))}:Dispatch&&Dispatch.now?defer=function(e){Dispatch.now(_ctx(run,e,1))}:MessageChannel?(channel=new MessageChannel,port=channel.port2,channel.port1.onmessage=listener,defer=_ctx(port.postMessage,port,1)):_global.addEventListener&&"function"==typeof postMessage&&!_global.importScripts?(defer=function(e){_global.postMessage(e+"","*")},_global.addEventListener("message",listener,!1)):defer=ONREADYSTATECHANGE in _domCreate("script")?function(e){_html.appendChild(_domCreate("script"))[ONREADYSTATECHANGE]=function(){_html.removeChild(this),run.call(e)}}:function(e){setTimeout(_ctx(run,e,1),0)});var _task={set:setTask,clear:clearTask},macrotask=_task.set,Observer=_global.MutationObserver||_global.WebKitMutationObserver,process$2=_global.process,Promise$1=_global.Promise,isNode="process"==_cof(process$2),_microtask=function(){var e,t,n,r=function(){var r,i;for(isNode&&(r=process$2.domain)&&r.exit();e;){i=e.fn,e=e.next;try{i()}catch(r){throw e?n():t=void 0,r}}t=void 0,r&&r.enter()};if(isNode)n=function(){process$2.nextTick(r)};else if(!Observer||_global.navigator&&_global.navigator.standalone)if(Promise$1&&Promise$1.resolve){var i=Promise$1.resolve();n=function(){i.then(r)}}else n=function(){macrotask.call(_global,r)};else{var o=!0,a=document.createTextNode("");new Observer(r).observe(a,{characterData:!0}),n=function(){a.data=o=!o}}return function(r){var i={fn:r,next:void 0};t&&(t.next=i),e||(e=i,n()),t=i}};function PromiseCapability(e){var t,n;this.promise=new e(function(e,r){if(void 0!==t||void 0!==n)throw TypeError("Bad Promise constructor");t=e,n=r}),this.resolve=_aFunction(t),this.reject=_aFunction(n)}var f$4=function(e){return new PromiseCapability(e)},_newPromiseCapability={f:f$4},_perform=function(e){try{return{e:!1,v:e()}}catch(e){return{e:!0,v:e}}},_promiseResolve=function(e,t){if(_anObject(e),_isObject(t)&&t.constructor===e)return t;var n=_newPromiseCapability.f(e);return(0,n.resolve)(t),n.promise},task=_task.set,microtask=_microtask(),PROMISE="Promise",TypeError$1=_global.TypeError,process$3=_global.process,$Promise=_global[PROMISE],isNode$1="process"==_classof(process$3),empty=function(){},Internal,newGenericPromiseCapability,OwnPromiseCapability,Wrapper,newPromiseCapability=newGenericPromiseCapability=_newPromiseCapability.f,USE_NATIVE=!!function(){try{var e=$Promise.resolve(1),t=(e.constructor={})[_wks("species")]=function(e){e(empty,empty)};return(isNode$1||"function"==typeof PromiseRejectionEvent)&&e.then(empty)instanceof t}catch(e){}}(),isThenable=function(e){var t;return!(!_isObject(e)||"function"!=typeof(t=e.then))&&t},notify=function(e,t){if(!e._n){e._n=!0;var n=e._c;microtask(function(){for(var r=e._v,i=1==e._s,o=0,a=function(t){var n,o,a=i?t.ok:t.fail,s=t.resolve,c=t.reject,u=t.domain;try{a?(i||(2==e._h&&onHandleUnhandled(e),e._h=1),!0===a?n=r:(u&&u.enter(),n=a(r),u&&u.exit()),n===t.promise?c(TypeError$1("Promise-chain cycle")):(o=isThenable(n))?o.call(n,s,c):s(n)):c(r)}catch(e){c(e)}};n.length>o;)a(n[o++]);e._c=[],e._n=!1,t&&!e._h&&onUnhandled(e)})}},onUnhandled=function(e){task.call(_global,function(){var t,n,r,i=e._v,o=isUnhandled(e);if(o&&(t=_perform(function(){isNode$1?process$3.emit("unhandledRejection",i,e):(n=_global.onunhandledrejection)?n({promise:e,reason:i}):(r=_global.console)&&r.error&&r.error("Unhandled promise rejection",i)}),e._h=isNode$1||isUnhandled(e)?2:1),e._a=void 0,o&&t.e)throw t.v})},isUnhandled=function(e){return 1!==e._h&&0===(e._a||e._c).length},onHandleUnhandled=function(e){task.call(_global,function(){var t;isNode$1?process$3.emit("rejectionHandled",e):(t=_global.onrejectionhandled)&&t({promise:e,reason:e._v})})},$reject=function(e){var t=this;t._d||(t._d=!0,(t=t._w||t)._v=e,t._s=2,t._a||(t._a=t._c.slice()),notify(t,!0))},$resolve=function(e){var t,n=this;if(!n._d){n._d=!0,n=n._w||n;try{if(n===e)throw TypeError$1("Promise can't be resolved itself");(t=isThenable(e))?microtask(function(){var r={_w:n,_d:!1};try{t.call(e,_ctx($resolve,r,1),_ctx($reject,r,1))}catch(e){$reject.call(r,e)}}):(n._v=e,n._s=1,notify(n,!1))}catch(e){$reject.call({_w:n,_d:!1},e)}}};USE_NATIVE||($Promise=function(e){_anInstance(this,$Promise,PROMISE,"_h"),_aFunction(e),Internal.call(this);try{e(_ctx($resolve,this,1),_ctx($reject,this,1))}catch(e){$reject.call(this,e)}},Internal=function(e){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},Internal.prototype=_redefineAll($Promise.prototype,{then:function(e,t){var n=newPromiseCapability(_speciesConstructor(this,$Promise));return n.ok="function"!=typeof e||e,n.fail="function"==typeof t&&t,n.domain=isNode$1?process$3.domain:void 0,this._c.push(n),this._a&&this._a.push(n),this._s&&notify(this,!1),n.promise},catch:function(e){return this.then(void 0,e)}}),OwnPromiseCapability=function(){var e=new Internal;this.promise=e,this.resolve=_ctx($resolve,e,1),this.reject=_ctx($reject,e,1)},_newPromiseCapability.f=newPromiseCapability=function(e){return e===$Promise||e===Wrapper?new OwnPromiseCapability(e):newGenericPromiseCapability(e)}),_export(_export.G+_export.W+_export.F*!USE_NATIVE,{Promise:$Promise}),_setToStringTag($Promise,PROMISE),_setSpecies(PROMISE),Wrapper=_core[PROMISE],_export(_export.S+_export.F*!USE_NATIVE,PROMISE,{reject:function(e){var t=newPromiseCapability(this);return(0,t.reject)(e),t.promise}}),_export(_export.S+_export.F*(_library||!USE_NATIVE),PROMISE,{resolve:function(e){return _promiseResolve(_library&&this===Wrapper?$Promise:this,e)}}),_export(_export.S+_export.F*!(USE_NATIVE&&_iterDetect(function(e){$Promise.all(e).catch(empty)})),PROMISE,{all:function(e){var t=this,n=newPromiseCapability(t),r=n.resolve,i=n.reject,o=_perform(function(){var n=[],o=0,a=1;_forOf(e,!1,function(e){var s=o++,c=!1;n.push(void 0),a++,t.resolve(e).then(function(e){c||(c=!0,n[s]=e,--a||r(n))},i)}),--a||r(n)});return o.e&&i(o.v),n.promise},race:function(e){var t=this,n=newPromiseCapability(t),r=n.reject,i=_perform(function(){_forOf(e,!1,function(e){t.resolve(e).then(n.resolve,r)})});return i.e&&r(i.v),n.promise}});var validSizes=["300x250","300x600","320x50","300x50","728x90","970x250"],timeoutLength=1e3;function clearTargetingByKey(e,t){e.forEach(function(e){e.getTargetingKeys().forEach(function(n){n===t&&e.clearTargeting(n)})})}function clearTargetingByPrefix(e,t){e.getTargetingKeys().forEach(function(n){0===n.indexOf(t)&&e.clearTargeting(n)})}function intersect(e,t){return void 0===e&&(e=[]),void 0===t&&(t=[]),e.filter(function(e){return t.indexOf(e)>-1})}function getSizesFromSlot(e){return e.getSizes(window.innerWidth,window.innerHeight).map(function(e){return"fluid"!==e&&e.getWidth()+"x"+e.getHeight()})}function getValidSizesFromSlot(e,t){return intersect(getSizesFromSlot(e),t)}function hasValidSize(e,t){return e.getSizes&&getValidSizesFromSlot(e,t).length>0}function isSlotEligible(e){return hasValidSize(e,validSizes)}var marketName="index_exchange",positions={hero:["970x250","728x90","320x50","300x50"],footer:["970x250","728x90","320x50","300x50"],"mid-content":["970x250","728x90","320x50","300x250","300x50"],"mid-gallery":["300x250","300x600"],rail:["300x600","300x250"]},targetingKeysToClear=[],scriptLoaded=!1,scriptFailedToLoad=!1;function ixRenderEnded(e){targetingKeysToClear.forEach(function(t){clearTargetingByKey([e.slot],t)})}function IndexExchange(){var e=new EventEmitter(marketName).debug;function t(t){return new Promise(function(n){if(scriptFailedToLoad)n();else{var r=t.getTargeting("pos")[0],i=getValidSizesFromSlot(t,positions[r]).sort().join("_");if(i.length||(r="default",i=getValidSizesFromSlot(t,validSizes)[0]),i){var o;scriptLoaded||(o=setTimeout(function(){scriptFailedToLoad=!0,wren.add({type:"auction.ix.script",status:"delay"}),n()},2e3));var a=r+"_"+i;window.headertag.cmd.push(function(){e("retrieveDemand."+a),scriptLoaded||(scriptLoaded=!0,clearTimeout(o)),scriptFailedToLoad&&(scriptFailedToLoad=!1);var r=setTimeout(n,timeoutLength);window.headertag.retrieveDemand([{htSlotName:a}],function(i){if(clearTimeout(r),i.slot&&i.slot[a]){e("complete."+a,i.slot[a]);var o={};i.slot[a].forEach(function(e){var t=e.targeting;Object.keys(t).forEach(function(e){o[e]?o[e]=o[e].concat(t[e]):o[e]=t[e],-1===targetingKeysToClear.indexOf(e)&&targetingKeysToClear.push(e)})}),Object.keys(o).forEach(function(e){t.setTargeting(e,o[e])})}else e("noDemand."+t.getSlotElementId()),wren.add({type:"auction.ix",slotName:a});n()})})}else n()}})}window.headertag=window.headertag||{},window.headertag.cmd=window.headertag.cmd||[],this.startAuction=function(n){return e("startAuction",n.map(function(e){return e.getSlotElementId()})),Promise.all(n.map(t)).then(function(){return n.map(function(){return{}})})},this.isSlotEligible=isSlotEligible}var _flags=function(){var e=_anObject(this),t="";return e.global&&(t+="g"),e.ignoreCase&&(t+="i"),e.multiline&&(t+="m"),e.unicode&&(t+="u"),e.sticky&&(t+="y"),t};function decode(e){return decodeURIComponent(e.replace(/\+/g," "))}function querystring(e){for(var t,n=/([^=?&]+)=?([^&]*)/g,r={};t=n.exec(e);){var i=decode(t[1]),o=decode(t[2]);i in r||(r[i]=o)}return r}_descriptors&&"g"!=/./g.flags&&_objectDp.f(RegExp.prototype,"flags",{configurable:!0,get:_flags}),_fixReWks("search",1,function(e,t,n){return[function(n){var r=e(this),i=void 0==n?void 0:n[t];return void 0!==i?i.call(n,r):new RegExp(n)[t](String(r))},n]});var parse=querystring;function getFeatures(e){return e&&"string"==typeof e?e.split(",").reduce(function(e,t){return e[t]=!0,e},{}):{}}var queryParameters=parse(document.location.search)||{},featureFlags=getFeatures(queryParameters.feature_flags);function prebidRenderEnded(e){setTimeout(function(){clearTargetingByPrefix(e.slot,"hb_")},1e3)}function Prebid(e){var t=get(e,"config.domain"),n=["rubicon","ix","aol","criteo","audienceNetwork"],r=!1,i=!1,o=!1,a=new EventEmitter("prebid").debug,s={consentManagement:{cmpApi:"iab",timeout:1e4,allowAuctionWithoutConsent:!0}};function c(e,t){return n.indexOf(e.bidder)-n.indexOf(t.bidder)}function u(){var e=window.__cmp;e&&!o&&e("ping",{},function(t){t.cmpLoaded&&(o=!0,e("getConsentData",{},function(e){e.gdprApplies&&window.pbjs.setConfig(s)}))})}function l(e){return new Promise(function(t){if(i)t();else{var n,s=getValidSizesFromSlot(e,validSizes);s?(o||u(),r?n=setTimeout(function(){t()},timeoutLength):setTimeout(function(){r||(i=!0,t())},2e3),window.pbjs.que.push(function(){clearTimeout(n);var r=e.getTargeting("pos")[0],i=e.getSlotElementId(),o=r+"_"+s.sort().join("_");window.pbjs.adUnits.filter(function(e){return e.code===o}).length<1&&window.pbjs.addAdUnits(function(e,t,n){var r,i=getViewportTemplate(),o=get(window,"cns.prebid.adunits."+e+"."+i)||{bids:[],mediaType:"banner"},a=o.bids,s=o.mediaType;a.sort(c);var u=sizesToArray(t);return{code:n,mediaTypes:(r={},r[s]={sizes:u},r),bids:a}}(r,s,o));var u=function(e,t,n){return{timeout:timeoutLength,adUnitCodes:[e],bidsBackHandler:n,labels:t}}(o,s,function(e){a("complete."+i,e),window.pbjs.setTargetingForGPTAsync([o],function(e){return function(){return e.getSlotElementId()===i}}),t()});window.pbjs.requestBids(u)})):t()}})}function f(e){var n={adUnitCode:e.adUnitCodes,auctionStatus:e.auctionStatus,bidsReceived:e.bidsReceived.map(function(e){return{bidderCode:e.bidderCode,cpm:e.cpm,size:e.size,statusMessage:e.statusMessage,timeToRespond:e.timeToRespond}}),bidsRequested:e.bidderRequests.reduce(function(e,t){return t.bids.forEach(function(t){var n=t.bidder,r=t.params,i=t.labelAny,o=void 0===i?[""]:i;e.push({bidder:n,params:r,size:o[0]})}),e},[]),domain:t,duration:e.auctionEnd-e.timestamp,host:get(window,"location.host"),sizes:e.labels,type:"auction.prebid.auctionEnd",viewport:getViewportTemplate()};wren.sendEvent(n)}function d(e){var n={adUnitCode:e.adUnitCode,bidder:e.bidder,cpm:e.cpm,domain:t,params:e.params,size:e.size,timeToRespond:e.timeToRespond,type:"auction.prebid.bidWon",viewport:getViewportTemplate()};wren.sendEvent(n)}function g(e){var n={adUnitCode:e[0].adUnitCode,bids:e.map(function(e){return{bidder:e.bidder,params:e.params}}),domain:t,type:"auction.prebid.bidTimeout",viewport:getViewportTemplate()};wren.sendEvent(n)}window.pbjs=window.pbjs||{que:[]},window.pbjs.que.push(function(){var e,t;r=!0,i&&(i=!1),queryParameters.bidders&&(e=(get(window,"cns.prebid")||{}).adunits,t=queryParameters.bidders.split(","),Object.keys(e).forEach(function(n){Object.keys(e[n]).forEach(function(r){e[n][r].bids=e[n][r].bids.filter(function(e){return t.indexOf(e.bidder)>-1})})}));var n,o=get(window,"cns.prebid.config")||{};window.pbjs.setConfig(o),(n=get(window,"pbjs")).onEvent("auctionEnd",f),n.onEvent("bidWon",d),n.onEvent("bidTimeout",g),u()}),this.startAuction=function(e){return a("startAuction",e.map(function(e){return e.getSlotElementId()})),Promise.all(e.map(l)).then(function(){return e.map(function(){return{}})})},this.isSlotEligible=isSlotEligible}function shouldApplyGDPR(){var e=!1,t=window.__cmp;return t&&t("ping",{},function(n){n.cmpLoaded&&t("getConsentData",{},function(t){t.gdprApplies&&(e=!0)})}),e}function restrictDataProcessing(){window.googletag.pubads().setPrivacySettings({restrictDataProcessing:!0})}function setRequestNonPersonalizedAds(){window.googletag.pubads().setRequestNonPersonalizedAds(1)}function getPrivacyString(){return getCookie("usprivacy")||"1---"}function shouldRestrictDataProcessing(){var e=getPrivacyString();return e&&4===e.length&&"1"===e[0]&&"y"===getPrivacyString()[2].toLowerCase()}function shouldSetNonPersonalizedAds(){return shouldApplyGDPR()&&window.OnetrustActiveGroups&&-1===window.OnetrustActiveGroups.indexOf("C0004")}function checkPrivacySettings(){shouldRestrictDataProcessing()&&restrictDataProcessing(),shouldSetNonPersonalizedAds()&&setRequestNonPersonalizedAds()}function oneTrustGroupsUpdated(e){window.cnBus.on("onetrust.OneTrustGroupsUpdated",e)}featureFlags.ao_norefresh&&(window.cns.flags.shouldNotRefresh=!0);var pubadsCollector=new PubadsCollector;function GPTRouter(e,t,n,r){var i=new ContainerStyler(e.getSingleInstance().getPageDefinition().isVerso);window.googletag=window.googletag||{},window.googletag.cmd=window.googletag.cmd||[];var o=window.googletag,a={slotRenderEnded:[function(t){try{var n=t.slot.getSlotElementId(),a=e.getSingleInstance().getSlotDefinitionFromGPTSlot(t.slot),s=document.getElementById(n),c=t.size,u=t.isEmpty,l=t.slot;s&&i.updateContainer(s,t),shouldSetSlotSize(c,u,a)&&setSlotSize(o,l,c),stickyIsEligible(n,a,c)&&r.emit("ads.stickyBanner.hero.slotRenderEnded."+c.join("x")),u?r.emit("ads.slotRenderEnded."+n+".empty"):r.emit("ads.slotRenderEnded."+n+".filled")}catch(e){error("onSlotRenderEnded",{event:t,ex:e})}},t.onSlotRenderEnded,n.onSlotRenderEnded,pubadsCollector.onSlotRenderEnded],impressionViewable:[function(t){try{var n=t.slot.getSlotElementId(),i=e.getSingleInstance().getSlotDefinitionFromGPTSlot(t.slot);"hero_0"===n&&i.isSticky&&r.emit("ads.stickyBanner.hero.impressionViewable",t)}catch(e){error("onImpressionViewable",{event:t,ex:e})}},t.onImpressionViewable,pubadsCollector.onImpressionViewable],slotOnload:[ixRenderEnded,prebidRenderEnded,pubadsCollector.onSlotOnload]};o.cmd.push(function(){var t=o.pubads();setPPID(t),t.enableSingleRequest(),t.disableInitialLoad(),t.setCentering(!0),function(e,t){Object.keys(e).forEach(function(n){e[n].forEach(function(e){return t.addEventListener(n,e)})})}(a,t),e.getSingleInstance().getPageDefinition().forChildren&&t.setTagForChildDirectedTreatment(!0),updateCorrelatorInterval(),checkPrivacySettings(),oneTrustGroupsUpdated(checkPrivacySettings),o.enableServices(),pubadsCollector.emitReady(),r.emit("ads.pubadsReady")})}function hasEmail(e){return new RegExp("([a-zA-Z0-9._+-]+(@|%40|%2540)[a-zA-Z0-9._-]+.[a-zA-Z0-9._-]+)","gi").test(e)}function hasCreditCard(e){var t=e.match(/3(?:[47]\d([ -]?)\d{4}(?:\1\d{4}){2}|0[0-5]\d{11}|[68]\d{12})|4(?:\d\d\d)?([ -]?)\d{4}(?:\2\d{4}){2}$|^6011([ -]?)\d{4}(?:\3\d{4}){2}|5[1-5]\d\d([ -]?)\d{4}(?:\4\d{4}){2}|2014\d{11}$|^2149\d{11}|2131\d{11}$|^1800\d{11}$|^3\d{15}/);return!(null===t||!t.length)}function hasMacAddress(e){var t=e.match(/((\d|([a-f]|[A-F])){2}:){5}(\d|([a-f]|[A-F])){2}/);return!(null===t||!t.length)}function hasIP(e){var t=e.match(/((0|1[0-9]{0,2}|2[0-9]?|2[0-4][0-9]|25[0-5]|[3-9][0-9]?)\.){3}(0|1[0-9]{0,2}|2[0-9]?|2[0-4][0-9]|25[0-5]|[3-9][0-9]?)/);return!(null===t||!t.length)}function hasPII(){return any([document.referrer,document.location.href],function(e){return hasEmail(e)||hasCreditCard(e)||hasMacAddress(e)||hasIP(e)})}function detect(e){var t,n,r=!1,i=25,o={},a={},s=4e3,c="pub_300x250 pub_300x250m pub_728x90 text-ad textAd text_ad text_ads text-ads text-ad-links",u="width: 1px !important; height: 1px !important; position: absolute !important; left: -10000px !important; top: -1000px !important;";function l(){return function(t){r||(r=!0,Object.keys(a).forEach(function(e){clearTimeout(a[e])}),Object.keys(o).forEach(function(e){window.document.body.removeChild(o[e])}),e(t))}}function f(){setTimeout(function(){var e;e=l(),o.cosmetic=document.createElement("div"),o.cosmetic.setAttribute("class",c),o.cosmetic.setAttribute("style",u),window.document.body.appendChild(o.cosmetic),function e(t){var n=o.cosmetic;if(null!==window.document.body.getAttribute("abp")||null===n.offsetParent||0===n.offsetHeight||0===n.offsetLeft||0===n.offsetTop||0===n.offsetWidth||0===n.clientHeight||0===n.clientWidth)return t(!0);if(window.getComputedStyle){var r=window.getComputedStyle(n,null);if("none"===r.getPropertyValue("display")||"hidden"===r.getPropertyValue("visibility"))return t(!0)}a.cosmetic=setTimeout(function(){e(t)},i)}(e)},1)}function d(){setTimeout(function(){var e;e=l(),window.googletag&&window.googletag.getVersion?e(!1):e(!0)},s)}t=l(),(n=new XMLHttpRequest).open("GET","/hotzones/src/ads.js",!0),n.onreadystatechange=function(){4===n.readyState&&0===n.status&&t(!0)},n.send(),"complete"===document.readyState?(f(),d()):"interactive"===document.readyState?(f(),window.addEventListener("load",d,!1)):(window.addEventListener("DOMContentLoaded",f,!1),window.addEventListener("load",d,!1))}function AdBlockDetect(e){detect(function(t){t?e.emit("ads.environment.adblock.detected"):e.emit("ads.environment.adblock.notdetected"),set(window,"cns.pageContext.adBlock",t)})}var runtime=createCommonjsModule(function(e){!function(t){var n,r=Object.prototype,i=r.hasOwnProperty,o="function"==typeof Symbol?Symbol:{},a=o.iterator||"@@iterator",s=o.asyncIterator||"@@asyncIterator",c=o.toStringTag||"@@toStringTag",u=t.regeneratorRuntime;if(u)e.exports=u;else{(u=t.regeneratorRuntime=e.exports).wrap=_;var l="suspendedStart",f="suspendedYield",d="executing",g="completed",p={},h={};h[a]=function(){return this};var m=Object.getPrototypeOf,v=m&&m(m(O([])));v&&v!==r&&i.call(v,a)&&(h=v);var y=T.prototype=w.prototype=Object.create(h);S.prototype=y.constructor=T,T.constructor=S,T[c]=S.displayName="GeneratorFunction",u.isGeneratorFunction=function(e){var t="function"==typeof e&&e.constructor;return!!t&&(t===S||"GeneratorFunction"===(t.displayName||t.name))},u.mark=function(e){return Object.setPrototypeOf?Object.setPrototypeOf(e,T):(e.__proto__=T,c in e||(e[c]="GeneratorFunction")),e.prototype=Object.create(y),e},u.awrap=function(e){return{__await:e}},E(I.prototype),I.prototype[s]=function(){return this},u.AsyncIterator=I,u.async=function(e,t,n,r){var i=new I(_(e,t,n,r));return u.isGeneratorFunction(t)?i:i.next().then(function(e){return e.done?e.value:i.next()})},E(y),y[c]="Generator",y[a]=function(){return this},y.toString=function(){return"[object Generator]"},u.keys=function(e){var t=[];for(var n in e)t.push(n);return t.reverse(),function n(){for(;t.length;){var r=t.pop();if(r in e)return n.value=r,n.done=!1,n}return n.done=!0,n}},u.values=O,C.prototype={constructor:C,reset:function(e){if(this.prev=0,this.next=0,this.sent=this._sent=n,this.done=!1,this.delegate=null,this.method="next",this.arg=n,this.tryEntries.forEach(A),!e)for(var t in this)"t"===t.charAt(0)&&i.call(this,t)&&!isNaN(+t.slice(1))&&(this[t]=n)},stop:function(){this.done=!0;var e=this.tryEntries[0].completion;if("throw"===e.type)throw e.arg;return this.rval},dispatchException:function(e){if(this.done)throw e;var t=this;function r(r,i){return s.type="throw",s.arg=e,t.next=r,i&&(t.method="next",t.arg=n),!!i}for(var o=this.tryEntries.length-1;o>=0;--o){var a=this.tryEntries[o],s=a.completion;if("root"===a.tryLoc)return r("end");if(a.tryLoc<=this.prev){var c=i.call(a,"catchLoc"),u=i.call(a,"finallyLoc");if(c&&u){if(this.prev<a.catchLoc)return r(a.catchLoc,!0);if(this.prev<a.finallyLoc)return r(a.finallyLoc)}else if(c){if(this.prev<a.catchLoc)return r(a.catchLoc,!0)}else{if(!u)throw new Error("try statement without catch or finally");if(this.prev<a.finallyLoc)return r(a.finallyLoc)}}}},abrupt:function(e,t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc<=this.prev&&i.call(r,"finallyLoc")&&this.prev<r.finallyLoc){var o=r;break}}o&&("break"===e||"continue"===e)&&o.tryLoc<=t&&t<=o.finallyLoc&&(o=null);var a=o?o.completion:{};return a.type=e,a.arg=t,o?(this.method="next",this.next=o.finallyLoc,p):this.complete(a)},complete:function(e,t){if("throw"===e.type)throw e.arg;return"break"===e.type||"continue"===e.type?this.next=e.arg:"return"===e.type?(this.rval=this.arg=e.arg,this.method="return",this.next="end"):"normal"===e.type&&t&&(this.next=t),p},finish:function(e){for(var t=this.tryEntries.length-1;t>=0;--t){var n=this.tryEntries[t];if(n.finallyLoc===e)return this.complete(n.completion,n.afterLoc),A(n),p}},catch:function(e){for(var t=this.tryEntries.length-1;t>=0;--t){var n=this.tryEntries[t];if(n.tryLoc===e){var r=n.completion;if("throw"===r.type){var i=r.arg;A(n)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(e,t,r){return this.delegate={iterator:O(e),resultName:t,nextLoc:r},"next"===this.method&&(this.arg=n),p}}}function _(e,t,n,r){var i=t&&t.prototype instanceof w?t:w,o=Object.create(i.prototype),a=new C(r||[]);return o._invoke=function(e,t,n){var r=l;return function(i,o){if(r===d)throw new Error("Generator is already running");if(r===g){if("throw"===i)throw o;return R()}for(n.method=i,n.arg=o;;){var a=n.delegate;if(a){var s=x(a,n);if(s){if(s===p)continue;return s}}if("next"===n.method)n.sent=n._sent=n.arg;else if("throw"===n.method){if(r===l)throw r=g,n.arg;n.dispatchException(n.arg)}else"return"===n.method&&n.abrupt("return",n.arg);r=d;var c=b(e,t,n);if("normal"===c.type){if(r=n.done?g:f,c.arg===p)continue;return{value:c.arg,done:n.done}}"throw"===c.type&&(r=g,n.method="throw",n.arg=c.arg)}}}(e,n,a),o}function b(e,t,n){try{return{type:"normal",arg:e.call(t,n)}}catch(e){return{type:"throw",arg:e}}}function w(){}function S(){}function T(){}function E(e){["next","throw","return"].forEach(function(t){e[t]=function(e){return this._invoke(t,e)}})}function I(e){var t;this._invoke=function(n,r){function o(){return new Promise(function(t,o){!function t(n,r,o,a){var s=b(e[n],e,r);if("throw"!==s.type){var c=s.arg,u=c.value;return u&&"object"==typeof u&&i.call(u,"__await")?Promise.resolve(u.__await).then(function(e){t("next",e,o,a)},function(e){t("throw",e,o,a)}):Promise.resolve(u).then(function(e){c.value=e,o(c)},a)}a(s.arg)}(n,r,t,o)})}return t=t?t.then(o,o):o()}}function x(e,t){var r=e.iterator[t.method];if(r===n){if(t.delegate=null,"throw"===t.method){if(e.iterator.return&&(t.method="return",t.arg=n,x(e,t),"throw"===t.method))return p;t.method="throw",t.arg=new TypeError("The iterator does not provide a 'throw' method")}return p}var i=b(r,e.iterator,t.arg);if("throw"===i.type)return t.method="throw",t.arg=i.arg,t.delegate=null,p;var o=i.arg;return o?o.done?(t[e.resultName]=o.value,t.next=e.nextLoc,"return"!==t.method&&(t.method="next",t.arg=n),t.delegate=null,p):o:(t.method="throw",t.arg=new TypeError("iterator result is not an object"),t.delegate=null,p)}function P(e){var t={tryLoc:e[0]};1 in e&&(t.catchLoc=e[1]),2 in e&&(t.finallyLoc=e[2],t.afterLoc=e[3]),this.tryEntries.push(t)}function A(e){var t=e.completion||{};t.type="normal",delete t.arg,e.completion=t}function C(e){this.tryEntries=[{tryLoc:"root"}],e.forEach(P,this),this.reset(!0)}function O(e){if(e){var t=e[a];if(t)return t.call(e);if("function"==typeof e.next)return e;if(!isNaN(e.length)){var r=-1,o=function t(){for(;++r<e.length;)if(i.call(e,r))return t.value=e[r],t.done=!1,t;return t.value=n,t.done=!0,t};return o.next=o}}return{next:R}}function R(){return{value:n,done:!0}}}(function(){return this}()||Function("return this")())});function _asyncToGenerator(e){return function(){var t=this,n=arguments;return new Promise(function(r,i){var o=e.apply(t,n);function a(e,t){try{var n=o[e](t),a=n.value}catch(e){return void i(e)}n.done?r(a):Promise.resolve(a).then(s,c)}function s(e){a("next",e)}function c(e){a("throw",e)}s()})}}function detectChromeVersion(e){var t=e.toLowerCase().match(/chrome\/(.*)\s/);return t&&t[1]?parseInt(t[1],10):0}function isIncognito(e,t){var n="cd1394e6-3fd1-4a2d-ae60-c9ae01f7ee89";function r(t,n){var r=0,i=!1,o=e.setInterval(function(){t()&&(e.clearInterval(o),n(i)),r++>50&&(e.clearInterval(o),n(i=!0))},10)}return function(t){if(getCookie("CN_dev"))t(!1);else{var i;if(e.webkitRequestFileSystem)e.webkitRequestFileSystem(e.TEMPORARY,1,function(){i=!1},function(e){console.log(e),i=!0}),detectChromeVersion(e.navigator.appVersion)>=76&&_asyncToGenerator(regeneratorRuntime.mark(function t(){var n,r;return regeneratorRuntime.wrap(function(t){for(;;)switch(t.prev=t.next){case 0:if(!("storage"in navigator&&"estimate"in e.navigator.storage)){t.next=8;break}return t.next=3,e.navigator.storage.estimate();case 3:n=t.sent,r=n.quota,i=!!(r&&r<12e7),t.next=9;break;case 8:i=!1;case 9:case"end":return t.stop()}},t,this)}))();else if(e.indexedDB&&/Firefox/.test(e.navigator.userAgent)){var o;try{o=e.indexedDB.open("test")}catch(e){i=!0}void 0===i&&r(function(){return"done"===o.readyState},function(e){e||(i=!o.result)})}else if(/Edge/.test(e.navigator.userAgent))try{e.indexedDB||(i=!0)}catch(e){i=!0}else if(e.localStorage&&/Safari/.test(e.navigator.userAgent))if(/android/.test(e.navigator.userAgent.toLowerCase()))i=!1;else{try{localStorage[n]=n,localStorage.removeItem(n)}catch(e){i=!0}try{e.openDatabase(null,null,null,null)}catch(e){i=!0}}r(function(){return void 0!==i},function(){t(i)})}}(t)}var detectIncognito=function(e){isIncognito(window,function(t){e.emit("ads.environment.incognito."+(t?"":"not")+"detected"),set(window,"cns.pageContext.privateMode",t)})};function debugStyles(){var e=document.createElement("style"),t=document.createTextNode("");e.classList.add("ads-debug-styles"),e.appendChild(t),document.head.appendChild(e),e.sheet.insertRule(".cns-ads-stage {\n      box-sizing: border-box;\n      border: 5px solid black;\n      display: block !important;\n    }",e.sheet.cssRules.length),e.sheet.insertRule(".cns-ads-slot-state-empty {\n      border: 5px solid red;\n    }",e.sheet.cssRules.length),e.sheet.insertRule(".cns-ads-slot-state-filled {\n      border: 5px solid green;\n    }",e.sheet.cssRules.length)}var pollingTime=750,maxPollingTime=15e3;function getRaven(){var e=Date.now();return new Promise(function(t,n){!function r(){if(!1===window.shouldSentrySample)n(new Error("Raven is not enabled"));else{var i=window.Raven;i?t(i):Date.now()-e>=maxPollingTime?n(new Error("Raven has not loaded")):setTimeout(r,pollingTime)}}()})}function stringifyPayload(e){var t=e;try{t=JSON.stringify(e)}catch(e){t="Unable to stringify payload"}return t}function startSentry(e){var t=[],n=e.subscribe("#.warn",function(e,n){var r=n.topic;t.push({topic:r,payload:stringifyPayload(e),level:"warning"})}),r=e.subscribe("#.error",function(e,n){var r=n.topic;t.push({topic:r,payload:stringifyPayload(e),level:"error"})});getRaven().then(function(e){e.setTagsContext({adsLibVersion:version});for(var n=function(t){var n=t.topic,r=t.payload,i=t.level;e.captureMessage(n,{level:i,tags:{topic:n},extra:{payload:r}})};t.length;)n(t.shift());t.push=n}).catch(function(){n(),r(),t=null})}var isEnum=_objectPie.f,_objectToArray=function(e){return function(t){for(var n,r=_toIobject(t),i=_objectKeys(r),o=i.length,a=0,s=[];o>a;)isEnum.call(r,n=i[a++])&&s.push(e?[n,r[n]]:r[n]);return s}},$values=_objectToArray(!1);function isPlainObject(e){return!!e&&e.constructor===Object}function concatUniques(e){if(!(e=e.filter(Array.isArray)).length)return[];var t=e.shift();return Array.from(new Set(t.concat.apply(t,e)))}function mergeBase(e,t,n,r){var i;return isPlainObject(t)?i=e.filter(function(e){return isPlainObject(e[n])}):Array.isArray(t)&&(i=e.filter(function(e){return Array.isArray(e[n])})),i&&i.length&&(t=merge(i.map(function(e){return e[n]}),r)),t}function merge(e,t){var n=e.filter(function(e){return!!e});if(n<2)return e[0];var r=concatUniques(n.filter(function(e){return!!e}).map(Object.keys)),i=n[0];return r.reduce(function(e,r){var i=n.filter(function(e){return void 0!==e[r]});if(t){for(var o=!1,a=i[0][r],s=1;s<i.length;s++){var c=t(a,i[s][r],r);void 0!==c&&(a=c,o=!0)}if(o)return e[r]=a,e}for(var u=n.length-1;u>=0;u--){var l=n[u][r];if(void 0!==l)return e[r]=mergeBase(n,l,r,t),e}return e},i)}function mergeViewportSizes(e,t){var n={};return Object.keys(e).forEach(function(r){if(n[r]=e[r]||[],t&&void 0!==t[r])if(!1===t[r]||!t[r]&&!1===e[r])n[r]=!1;else{n[r]=concatUniques([e[r],t[r]]);var i=n[r].filter(function(e){return e&&"-"===e[0]}),o=i.map(function(e){return e.slice(1)}),a=i.concat(o);n[r]=difference(n[r],a)}}),n}function mergeObjectsOfArrays(e){return concatUniques(e.map(Object.keys)).reduce(function(t,n){var r=e.map(function(e){return e[n]}).filter(Array.isArray);return r.length&&(t[n]=concatUniques(r)),t},{})}_export(_export.S,"Object",{values:function(e){return $values(e)}});var isRunningOnClient="undefined"!=typeof window;function isObject(e){return"object"==typeof e&&e.constructor===Object}function getRender(e){return pick(e,["desktop","tablet","mobile","constellation","slot"])}function stringToFunction(string){return eval("("+string+")")}function slotComplexRenderPreProcessor(e){Object.values(e||{}).forEach(function(e){isObject(e)&&e.every&&e.el&&(e.when&&(e.when=isRunningOnClient&&stringToFunction(e.when)||e.when.toString()),e.in&&e.in.el&&e.in.when&&(e.in.when=isRunningOnClient&&stringToFunction(e.in.when)||e.in.when.toString()))})}function slotComplexRenderProcessor(e){e&&(e.slot?slotComplexRenderPreProcessor(e.slot):Object.values(e).forEach(function(e){slotComplexRenderPreProcessor(e.slot)}))}function mergePlugins(e,t){return Object.keys(t).reduce(function(n,r){var i=merge([{},e[r],t[r]],function(e,t){if(!1!==e&&!0===t)return e});return i&&(n[r]=i),n},{})}function mergeSlotTypeDefinitions(e,t){return Object.keys(t).reduce(function(n,r){var i=mergeAdTechConfigs(e[r],t[r]);return i&&(n[r]=i),n},{})}var specialKeys={types:function(e,t){if(isObject(e))return mergeSlotTypeDefinitions(e,t)},groups:function(e,t){return e?isObject(e)?concatUniques([e,t]):void 0:t},targeting:function(e,t){return e?isObject(e)?mergeObjectsOfArrays([e,t]):void 0:t},position:function(e,t){return e?isObject(e)?mergeObjectsOfArrays([e,t]):void 0:t},content_type:function(e,t){return e?isObject(e)?mergeObjectsOfArrays([e,t]):void 0:t},sizes:function(e,t){if(isObject(e))return mergeViewportSizes(e,t)},render:function(e,t){return slotComplexRenderProcessor(e),slotComplexRenderProcessor(t),getRender(e?t||e:t)},plugins:mergePlugins};function adConfigMerger(e,t,n){var r;return specialKeys[n]?r=specialKeys[n](e,t):Array.isArray(e)&&Array.isArray(t)&&(r=t),r}function mergeAdTechConfigs(e,t){return merge([{},e,t],adConfigMerger)}var _stringContext=function(e,t,n){if(_isRegexp(t))throw TypeError("String#"+n+" doesn't accept regex!");return String(_defined(e))},MATCH$1=_wks("match"),_failsIsRegexp=function(e){var t=/./;try{"/./"[e](t)}catch(n){try{return t[MATCH$1]=!1,!"/./"[e](t)}catch(e){}}return!0},STARTS_WITH="startsWith",$startsWith=""[STARTS_WITH];_export(_export.P+_export.F*_failsIsRegexp(STARTS_WITH),"String",{startsWith:function(e){var t=_stringContext(this,e,STARTS_WITH),n=_toLength(Math.min(arguments.length>1?arguments[1]:void 0,t.length)),r=String(e);return $startsWith?$startsWith.call(t,r,n):t.slice(n,n+r.length)===r}});var errorMessage$1="Ads -- Ad unit path generation error : ",matcher="[^A-Za-z0-9]";function dashSlugify(e){var t=new RegExp(matcher,"g");return e&&e.toString().toLowerCase().replace(t,"-").replace(/-+/g,"-").replace(/(^-|-$)/g,"")}function evalPath(fnString,options){try{var pathFn=eval("("+fnString+")");if("function"==typeof pathFn)return pathFn(options);error(errorMessage$1+" generation function is not a function")}catch(e){e(errorMessage$1+" generation function cannot be evaluated")}}function searchMap(e,t){return Object.keys(e).reduce(function(n,r){return find(e[r],function(e){return e===t})?r:n},!1)}function findCategory(e){var t=e.channel,n=t?dashSlugify(t):"misc";return"home"===n?"homepage":n}function findContentType(e){var t=get(e,"adUnit.map.contentType");t||error(errorMessage$1+" Content type map is missing in the config");var n=searchMap(t,e.templateType);return n||error(errorMessage$1+" contentType is undefined"),n}function matchAdUnitPathComponent(e,t,n){void 0===t&&(t=[]),void 0===n&&(n=""),t.sort(function(e,t){var n=Array.isArray(e)?e[0].length:e.length;return(Array.isArray(t)?t[0].length:t.length)-n});for(var r=0;r<t.length;r+=1){var i=Array.isArray(t[r]),o=i?t[r][0]:t[r];if(e.startsWith(o))return i?t[r][1]:o}return n||e}function buildMatchedAdUnitPath(e,t){var n=e.categoryMatch,r=void 0===n?[]:n,i=e.contentTypeMatch,o=void 0===i?[]:i,a=matchAdUnitPathComponent(t.category,r),s=matchAdUnitPathComponent(a,[matchAdUnitPathComponent(t.contentType,o)],t.contentType);return t.network+"/"+t.suffix+"/"+t.position+"/"+a+"/"+s+"/"+t.instance}function buildOrEvalPath(e,t){return Array.isArray(e.categoryMatch)?buildMatchedAdUnitPath(e,t):evalPath(e.generatePath,t)}function buildAdUnitPath(e){var t=e.position,n=e.network,r=e.positionCount,i=e.suffix,o=e.contentType||findContentType(e),a=findCategory(e),s={network:n,position:t,category:a,contentType:o,instance:r,suffix:i};return set(window,"cns.adUnit.contentType",o),set(window,"cns.adUnit.category",a),buildOrEvalPath({generatePath:get(e,"adUnit.generatePath"),categoryMatch:get(e,"adUnit.categoryMatch"),contentTypeMatch:get(e,"adUnit.contentTypeMatch")},s)}function buildLegacyPath(e){return evalPath(get(e,"adUnit.generateLegacyPath"),e)}function buildOverridePath(e){return e.network+"/"+e.override.replace(/,/g,"/")}function slugifyChannels(e){var t=e.channel,n=e.subChannel;return{channel:dashSlugify(t)||"",subChannel:dashSlugify(n)||""}}function generatePathOptions(e,t){var n=e.positionCount,r=e.network,i=e.override,o=e.suffix,a=e.templateType,s=e.slotName,c=e.shouldUseLegacyPath,u=e.position,l=slugifyChannels(e),f=l.channel,d=l.subChannel;return{adUnit:t.adUnit,network:r,override:i,templateType:a,positionCount:n,shouldUseLegacyPath:c,slotName:s,channel:f,subChannel:d,suffix:o,contentType:t.contentType,position:u}}function getAdUnitPath(e,t){var n,r=generatePathOptions(e,t);return(n=r.override?buildOverridePath(r):r.shouldUseLegacyPath?buildLegacyPath(r):buildAdUnitPath(r))||error(errorMessage$1),debug(e.slotName+".adUnitPathGenerated",n),n}var SlotCounter=function(){var e={};this.next=function(t){e[t]=e[t]||0;var n=e[t];return e[t]++,n}},PositionCounter=function(){var e={};this.next=function(t){e[t]=e[t]||1;var n=e[t];return e[t]++,n}};function defineReadOnlyProperties(e,t){for(var n=Object.keys(t),r={},i=0;i<n.length;i++){var o=n[i];r[o]={value:t[o],writable:!1,enumerable:!0}}return Object.defineProperties(e,r)}function freeze(e){try{return Object.freeze(e)}catch(e){throw new Error('Must use "new" keyword to instantiate, must support Object.freeze.')}}function matchVariantPattern(e,t){var n=!1;return t.forEach(function(t){!n&&e[t]&&(n=e[t])}),n||e._default||e.__default}function getSpecificityPattern(e){var t=e.slug,n=e.channel,r=e.subChannel,i=e.templateType;return[t,n+"_"+r+"_"+i,n+"_"+i,""+i]}function getSlotNamesForPage(e,t){var n=getSpecificityPattern(e);return matchVariantPattern(get(t,"slot.sets"),n)}function getConfig(){return get(window,"cns.config.config")}function getBrandAdUnitId(){return get(getConfig(),"slot.__auid_one")}function getAdUnit(){var e=get(window,"cns.config.config.ad_unit")||{};return{generatePath:e.generate_path,categoryMatch:e.category_match,contentTypeMatch:e.content_type_match,generateLegacyPath:e.generate_legacy_path,map:{contentType:get(e,"map.content_type")}}}function getNetwork(){return get(window,"cns.config.config.network")}function getViewportRange(e,t,n){var r=getConfig()[n],i=r&&matchVariantPattern(r,e);return i&&i[t]||i||0}function getPathOverride(){return queryParameters&&queryParameters.ao_iu}function getVersoFlag(e){var t=get(e,"keywords.platform")||[];return!(!t.length||"verso"!==t[0])}function getOverrideVpRange(e,t){return get(t,"request_vp_range."+e)}function CompleteDefiner(e,t,n){var r=new SlotCounter,i=new PositionCounter,o=getSpecificityPattern(e),a=getConfig(),s=a.slot.types,c=getSlotNamesForPage(e,a),u=s._default||{},l={forChildren:"for_children",hasStaticRefreshSize:"static_refresh_size",canBeHidden:"can_be_hidden",shouldWaitForReact:"insert_after_react_ready",requiredTargeting:"required_targeting",isSticky:"is_sticky"};function f(e){var t=e.render;return t&&(t.slot||t[n]&&t[n].slot)}function d(e,t,r,i){e||warn("Invalid sizes: unable to define '"+r+"' on "+n+".",{definition:i,slotName:r}),t||warn("Invalid render: unable to define: '"+r+"' on "+n,{definition:i,slotName:r})}var g=freeze(c.reduce(function(e,r){var i=mergeAdTechConfigs(mergeAdTechConfigs(u,s[r]._default),function(e){var n=matchVariantPattern(s[e],o);return t?mergeAdTechConfigs(n,t):n}(r));return function(e,t,n){var r=t.sizes,i=r&&r[n]&&r[n].length,o=r&&!1===r[n],a=f(t),s=i&&!o;return!!t.isOutOfPage||(d(s,a,e,t),i&&!o&&a)}(r,i,n)&&(e[r]=freeze(i)),e},{})),p=freeze(Object.keys(g)),h=new function(){defineReadOnlyProperties(this,{slug:e.slug,server:e.server,keywords:e.keywords,channel:e.channel||"misc",subChannel:e.subChannel,device:n,templateType:e.templateType,contentType:e.contentType,forChildren:e[l.forChildren],slotNames:p,network:getNetwork(),brand:getBrandAdUnitId(),requestViewportRange:getViewportRange(o,n,"request_vp_range"),adUnit:getAdUnit(),isVerso:getVersoFlag(e)}),freeze(this)};function m(t){var o=new RegExp(/cm/),a=g[t],s=o.test(a.suffix);function c(e,n){var o=this;e=void 0!==e?e:r.next(t),defineReadOnlyProperties(this,{id:t+"_"+e,slotCount:e,positionCount:n=void 0!==n?n:i.next(this.position)}),this.getAdUnitPath=function(){return getAdUnitPath(o,h)},freeze(this)}this.getRenderBlock=function(){return f(a)},this.getSizes=function(){return a.sizes[n]},this.getSizesArray=function(){return sizesToArray(a.sizes[n])},this.getSizeMapping=function(){return{desktop:sizesToArray(a.sizes.desktop),tablet:sizesToArray(a.sizes.tablet),mobile:sizesToArray(a.sizes.mobile)}},this.shouldWaitUntilVisibleBeforeDisplay=function(){var e=a[l.canBeHidden];return!s&&!e},this.getCustomData=function(){return a.data},c.prototype=this,this.getSlotDefinition=function(){return new c},this.getSlotDefinitionFromGPTSlot=function(e){var t=parseInt(e.getTargeting("pos_instance")[0],10);return new c(parseInt(e.getTargeting("ctx_slot_instance")[0],10),t)},this.getSlotRefreshTime=function(e,t){var n=e;return e&&e[t]&&(n=e[t]),n},defineReadOnlyProperties(this,{slotName:t,isCM:s,isOutOfPage:!!a.isOutOfPage,refresh:this.getSlotRefreshTime(a.refresh,n),isSticky:isStickyDeviceEnabled(a[l.isSticky],n),hasStaticRefreshSize:!!a[l.hasStaticRefreshSize],suffix:a.suffix,channel:e.channel,subChannel:e.subChannel,templateType:e.templateType,override:getPathOverride(),brand:getBrandAdUnitId(),network:getNetwork(),shouldUseLegacyPath:a.should_use_legacy_path,shouldWaitForReact:!!a[l.shouldWaitForReact],requiredTargeting:a[l.requiredTargeting]||[],position:a.position,overrideRequestViewportRange:getOverrideVpRange(n,a)}),freeze(this)}this.getSlotTypeDefinition=function(e){return new m(e)},this.getSlotDefinitionFromGPTSlot=function(e){var t=e.getSlotElementId().split("_");return t.pop(),new m(t.join("_")).getSlotDefinitionFromGPTSlot(e)},this.getPageDefinition=function(){return h},freeze(this)}var reactReadyEvent="react.ready";function onReactReady(){set(window,"_cne.pageCreated",!0)}function enableCNE(e){if(e.history(reactReadyEvent).length)return onReactReady();e.on(reactReadyEvent,onReactReady)}var eval2=eval;function getText(e){for(var t="",n=e.childNodes,r=0;r<n.length;r++){var i=n[r];8!==i.nodeType&&(t+=1!==i.nodeType?i.nodeValue:getText(i))}return t}function setMeta(e,t,n){var r=getText(n[t]);return{index:t,isOdd:!!(t%2),isEven:!(t%2),isFirst:0===t,isLast:t===e-1,characterCount:r.split("").length,wordCount:r.split(" ").length}}function isValidComplexInjection(e){return"string"==typeof e.el&&"number"==typeof e.every&&("object"==typeof e.in&&"string"==typeof e.in.el||"string"==typeof e.in)}var insertionMethodMap={top:"prepend",bottom:"append",after:"after"};function normalizeMethod(e){return insertionMethodMap[e]||e}var insertionMethods={before:function(e){return e.previousSibling},above:function(e){return e.previousSibling},after:function(e){return e.nextSibling},below:function(e){return e.nextSibling},prepend:function(e){return e.firstElementChild},append:function(e){return e.lastElementChild}};function getInsertionTarget(e,t){if(insertionMethods[t])return insertionMethods[t](e);console.error("unknown insertion method for getInsertionTarget",{el:e,method:t})}function alreadyExists(e,t){var n=getInsertionTarget(e,t),r=n&&n.classList&&n.classList.contains("cns-ads-stage"),i=n&&n.firstChild,o=i&&i.classList&&i.classList.contains("cns-ads-stage");return!(!r&&!o)}function checkEvery(e){var t=e.injectionBlock,n=e.index;return"number"==typeof t.every&&!!t.every&&"number"==typeof n}function checkCustomCondition(e){return"function"==typeof e.customConditionFn}var shouldAddSlotConditions=[{name:"every",check:checkEvery,fn:function(e){return(e.index+1)%e.injectionBlock.every==0}},{name:"custom condition",check:checkCustomCondition,fn:function(e){return(0,e.customConditionFn)(e.domNode,e.meta)}}];function shouldAddSlot(e){for(var t=0;t<shouldAddSlotConditions.length;t++){var n="shouldAddSlot."+shouldAddSlotConditions[t].name;if(shouldAddSlotConditions[t].check(e)){var r=void 0;try{r=shouldAddSlotConditions[t].fn(e)}catch(t){debug(n+".conditionThrew",{ex:t,facts:e})}if(!r)return debug(n+".conditionNotMet",e),r;debug(n+".conditionFalse",e)}else debug(n+".checkFailed",e)}return!0}function getParentSelector(e){return"string"==typeof e?e:e.el}function getEvalResult(e){if(e)try{return eval2("("+e+")")}catch(e){error("seriesInjection",e)}}function getDomNodesForInjectionBlock(e){var t=0,n=0,r=find$1(getParentSelector(e.in));if(!r)return[];for(var i=findAll(r,e.el),o=i.length,a=getEvalResult(e.when),s=[],c=0;c<o;c++){var u=i[c],l=setMeta(o,c,i);t+=l.characterCount,n+=l.wordCount,l.accumulatedCharacterCount=t,l.accumulatedWordCount=n,shouldAddSlot({index:c,domNode:u,meta:l,customConditionFn:a,injectionBlock:e})&&s.push(u)}return s}function getCandidateElementsFromRenderBlock(e){return Object.keys(e).reduce(function(t,n){var r,i=e[n];return"string"==typeof i?r=findAll(i):isValidComplexInjection(i)?r=getDomNodesForInjectionBlock(i):(r=[],error("invalid",i)),n=normalizeMethod(n),(r=r.filter(function(e){return!alreadyExists(e,n)}))&&r.length&&(t[n]=r),t},{})}var PromiseLock=function(){var e;return function(t){return function(){for(var n=arguments.length,r=new Array(n),i=0;i<n;i++)r[i]=arguments[i];if(e){var o=e.then(function(){return t.apply(void 0,r)});return e=o.then(function(){}),o}return e=t.apply(void 0,r)}}};function createContainerEl(e,t,n){var r=createElement("div",{id:e+"_"+t});return addClasses(r,["cns-ads-container"]),setStyle(r,{margin:"0px auto",boxSizing:"content-box"}),n&&setElementData(r,n),r}function createAdDivs(e,t,n,r){var i="cns-ads-slot-type-",o=e.replace(new RegExp("_","g"),"-").toLowerCase(),a=createElement("div",{id:""+i+o+"-"+t});addClasses(a,["cns-ads-stage",i+o,i+o+"-"+t]),setElementData(a,{name:e+"_"+t,"slot-type":e}),r||setStyle(a,{fontSize:0,lineHeight:0,overflow:"hidden"}),"_out_of_page"===e&&addClasses(a,["cns-ads-slot-type-out-of-page"]);var s=createElement("div");return addClasses(s,["cns-ads-flex-sizer"]),a.appendChild(s),a.appendChild(createContainerEl(e,t,n)),a}function InjectRefreshDisplayInjectionStrategy(e,t,n,r){window.googletag=window.googletag||{};var i=window.googletag,o={after:function(e,t){return e.parentNode.insertBefore(t,e.nextSibling)},prepend:function(e,t){return e.insertBefore(t,e.children[0])},append:function(e,t){return e.appendChild(t)},before:function(e,t){return e.parentNode.insertBefore(t,e)}};this.insertSlot=function(a,s,c,u,l){fastdom.mutate(function(){var f=createAdDivs(s.slotName,s.slotCount,s.getCustomData(),r);!function(e,t,n){o[t]?o[t](e,n):e[t](n)}(c,u,f),l(f,s,function(){!function(r,o){var a=t.getSingleInstance().getPageDefinition();e(["refreshLC-serviceLT"],{pageDefinition:a},function(t){return applyTargeting(i.pubads(),t),e(["refresh"],{slotDefinition:o,slot:r,pageDefinition:a},function(e){e?(applyTargeting(r,e),n.reset(o),i.pubads().refresh([r],{changeCorrelator:!1}),debug("refreshing."+r.getSlotElementId())):error("slot targeting is missing",a,o)})})}(a,s)})})}}var allowedIntersectionOptions=["threshold","rootMargin"],defaultIntersectionObserverOptions={threshold:0,rootMargin:"0px 0px"},_ref=new EventEmitter("VisibilityObserver"),debug$1=_ref.debug,error$1=_ref.error;function isIntersecting(e){return any(e,function(e){return e.isIntersecting})}function hasHigherIntersectionRatio(e,t){return void 0===e||any(t,function(t){return t.intersectionRatio>=(e||0)})}function getIntersectionObserverOptions(e){return Object.assign({},defaultIntersectionObserverOptions,pick(e,allowedIntersectionOptions))}function observeEvents(e,t,n,r){fastdom.measure(function(){try{var i=new IntersectionObserver(function(r){hasHigherIntersectionRatio(t.intersectionRatio,r)&&isIntersecting(r)?(debug$1("visible",{el:e,entries:r}),n(!0,i)):(debug$1("notVisible",{el:e,entries:r}),n(!1,i))},getIntersectionObserverOptions(t));i.observe(e)}catch(e){r(e)}})}function onIntersection(e,t,n){observeEvents(e,t,function(e){return n(e)},function(e){return error$1("onIntersection",e)})}function onceVisible(e,t){return new Promise(function(n,r){observeEvents(e,t,function(e,t){e&&(n(),t.disconnect())},r)})}function reactRule(e,t){return!e||t}function targetingRule(e,t,n){var r=Object.keys(n),i=Object.keys(t);return all(e,function(e){return find(r,function(t){return t===e})||find(i,function(t){return t===e})})}function canRequest(e){var t=e.slotTypeDefinition,n=e.pageTargeting,r=e.slotTargeting,i=e.reactReady,o=!!r,a=targetingRule(t.requiredTargeting,r,n),s=reactRule(t.shouldWaitForReact,i),c=o&&a&&s;return debug("canRequest."+t.slotName+"."+c,{slotTypeDefinition:t,pageTargeting:n,slotTargeting:r,reactReady:i}),c}function UnassumingInsert(e,t,n,r){window.googletag=window.googletag||{};var i=window.googletag,o=t.withTargeting,a=r.getSingleInstance().getPageDefinition().isVerso,s=new InjectRefreshDisplayInjectionStrategy(o,r,n,a),c=!1;var u,l=(new PromiseLock)(function(e){var t=e.getSingleInstance().getPageDefinition();return o(["service"],{pageDefinition:t},function(n){if(n)return applyTargeting(i.pubads(),n),Promise.all(t.slotNames.map(function(r){var a,u,l,f,d=e.getSingleInstance().getSlotTypeDefinition(r);return u=function(e,r){return o(["slot"],{pageTargeting:n,slotTypeDefinition:d,reactReady:c,el:e},function(o){if(o)if(canRequest({slotTypeDefinition:d,pageTargeting:n,slotTargeting:o,reactReady:c})){var a,u=d.getSlotDefinition(),l=(a=u).isOutOfPage?i.defineOutOfPageSlot(a.getAdUnitPath(),a.id):i.defineSlot(a.getAdUnitPath(),a.getSizesArray(),a.id).defineSizeMapping(getSizeMapping(a));l?(l.addService(window.googletag.pubads()),applyTargeting(l,o),s.insertSlot(l,u,e,r,function(e,t){return function(n,r,o){var a=function(e){if(e.shouldWaitUntilVisibleBeforeDisplay())return onceVisible}(r),s=function(){var e=r.id;debug("insert.display",e),i.display(e),o()},c=e.requestViewportRange,u=t.overrideRequestViewportRange;if(a)return a(n,{rootMargin:(void 0!==u?u:c)+"px 0px"}).then(s);s()}}(t,d))):error("the slot cannot be defined",u,l)}else debug(d.slotName+".notRequestable",d,c,n,o);else error("slot type targeting is missing",t,d)})},f=(a=d).getRenderBlock(),l=getCandidateElementsFromRenderBlock(f),Promise.all(Object.keys(l).map(function(e){return debug("candidatesByMethod."+a.slotName,{method:e,els:l[e],definition:a}),Promise.all(l[e].map(function(t){return u(t,e)}))}))}));error("page targeting is missing",t)}).catch(handlePromiseError("insert error")).then(function(){return new Promise(function(e){return fastdom.mutate(function(){return setTimeout(e,1e3)})})}).catch(handlePromiseError("impossible mutate error"))});u=function(){c=!0},e.history("react.ready").length?u():e.on("react.ready",u),this.insert=function(t){var n;n=function(){var n;l(t),n=debounce(function(){return l(t)},500),e.on("react.ready",n),e.on("#.componentDidMount.#",n),e.on("#.componentDidUpdate.#",n)},i.pubadsReady?n():e.on("ads.pubadsReady",n)}}var INCLUDES="includes";_export(_export.P+_export.F*_failsIsRegexp(INCLUDES),"String",{includes:function(e){return!!~_stringContext(this,e,INCLUDES).indexOf(e,arguments.length>1?arguments[1]:void 0)}});var always=function(){return!0};function LifecycleRegistrar(e){var t=new EventEmitter("LifecycleRegistrar").warn,n={};function r(e){return e&&"object"==typeof e&&"function"==typeof e.then}function i(e){var n={};e.unshift({});for(var r=0;r<e.length;r++){var i=e[r];"object"!=typeof i&&(t("Callback should return object, instead found "+typeof i),i={}),Object.assign(n,i)}return n}e.forEach(function(e){n[e]=[]}),this.register=function(t,r,i){if(i||(i=r,r=always),!e.includes(t))throw new Error(t+" not registered in LifeCycle");n[t].push({when:r,fn:i})},this.apply=function(e){for(var t=arguments.length,o=new Array(t>1?t-1:0),a=1;a<t;a++)o[a-1]=arguments[a];var s=[];e.forEach(function(e){n[e].forEach(function(e){var t=e.when,n=e.fn;t.apply(void 0,o)&&s.push(n)})});var c=s.map(function(e){return e.apply(void 0,o)});return any(c,r)?Promise.all(c).then(i):i(c)}}var marketName$1="amazon_match_buy",apstagConfig={pubID:"3035",adServer:"googletag",bidTimeout:1e3,deals:!0,params:{}},scriptLoaded$1=!1,scriptFailedToLoad$1=!1;function AmazonMatchBuy(){var e=new EventEmitter(marketName$1),t=e.debug,n=e.warn;function r(e){return{slotID:e.getSlotElementId(),slotName:function(e){return e.getTargeting("pos")[0]+"/"+getViewportTemplate()}(e),sizes:getValidSizesFromSlot(e,validSizes).map(function(e){return getSizeStringAsArray(e)})}}function i(e,t){window.apstag._Q.push([e,t])}window.apstag=window.apstag||{init:function(){i("i",arguments)},fetchBids:function(){i("f",arguments)},_Q:[]},apstagConfig.params.si_section=getPageContext(window).channel||"",apstagConfig.params.us_privacy=getPrivacyString(),window.apstag.init(apstagConfig),this.startAuction=function(e){return t("startAuction",e.map(function(e){return e.getSlotElementId()})),new Promise(function(i){var o;scriptFailedToLoad$1?i(e.map(function(){return{}})):(scriptLoaded$1||(o=setTimeout(function(){scriptFailedToLoad$1=!0,wren.add({type:"auction.amzn.script",status:"delay"}),i(e.map(function(){return{}}))},2e3)),window.apstag.fetchBids({slots:e.map(r),bidTimeout:timeoutLength},function(r){scriptLoaded$1||(scriptLoaded$1=!0,clearTimeout(o)),scriptFailedToLoad$1&&(scriptFailedToLoad$1=!1),t("complete",r);try{window.apstag.setDisplayBids(),i(e.map(function(){return{}}))}catch(t){n("cannotHandleBidsBack",t),i(e.map(function(){return{}}))}}))})},this.isSlotEligible=isSlotEligible}function collectPromises(e,t){var n=cumulativeArgumentDebounce(function(t){var n=[],r=[],i=[],o=function(e){return i.forEach(function(t){return t(e)})};t.forEach(function(e){r.push(e[0]),i.push(e[1]),n.push(e[2])}),e(n).then(function(e){return e?e.length!==n.length?o(new Error("collectPromises: Number of results must equal number of original items")):e.forEach(function(e,t){return r[t](e)}):r.forEach(function(e){return e()})}).catch(o)},t=t||0);return function(e){return new Promise(function(t,r){return n(function(e){t(e)},r,e)})}}function isHostWhitelisted(e){var t=get(e,"config.domain");return window.location.host.indexOf(t)>-1}function areAuctionsEnabled(e){return!!isHostWhitelisted(e)&&!featureFlags.ads_disable_auctions}function isAuctionEnabled(e,t){return!!(e&&e.plugins||{})[t]}function createSlotAuctionEligible(e){return function(t){var n=t.slotDefinition,r=t.slot;return!get(window,"cns.flags.shouldNotAuction")&&!n.isOutOfPage&&!n.isCM&&e.isSlotEligible(r)}}function createStartAuction(e){return collectPromises(function(t){return e.startAuction(t.map(function(e){return e.slot}))})}var auctioneer={areAuctionsEnabled:areAuctionsEnabled,isAuctionEnabled:isAuctionEnabled,createSlotAuctionEligible:createSlotAuctionEligible,createStartAuction:createStartAuction},cookieCacheName="cn_4dsgcache";function gather4dValues(e,t){var n=(get(window,e)||[]).map(function(e){return e[t]});return n.length&&n||""}function get4Dsg(e){var t=[],n="0";if(e){t=e;var r=new Date;r.setTime(r.getTime()+6048e5),document.cookie=cookieCacheName+"="+t.join(":")+"; expires="+r.toGMTString()+"; path=/;SameSite=Lax;Secure"}else{var i=getCookie(cookieCacheName);i&&(t=i.split(":"),n="1")}return{sgData:t,isCached:n}}function get4DTargeting(){var e=window,t="SparrowCache.event",n=get4Dsg(get(e,"_4d.user.sg"));return{vnd_4d_sg:n.sgData,vnd_4d_cached:n.isCached,vnd_4d_ctx_sg:get(e,"_4d.context.sg")||"",vnd_4d_ctx_topics:gather4dValues("_4d.context.entities","name"),vnd_4d_ctx_entities:gather4dValues("_4d.context.entities","name"),vnd_4d_ctx_keywords:gather4dValues("_4d.context.keywords.list","keyword"),vnd_4d_sid:get(e,t+".sID")||getCookie("sID"),vnd_4d_pid:get(e,t+".pID")||getCookie("pID"),vnd_4d_usr_topics:gather4dValues("_4d.user.topics","name"),vnd_4d_xid:getCookie("CN_xid")}}function getUserSegments(){var e=getCookie("CN_segments");return{usr_segments:e?e.split("|"):[]}}var chars="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";function InvalidCharacterError(e){this.message=e}function polyfill(e){var t=String(e).replace(/=+$/,"");if(t.length%4==1)throw new InvalidCharacterError("'atob' failed: The string to be decoded is not correctly encoded.");for(var n,r,i=0,o=0,a="";r=t.charAt(o++);~r&&(n=i%4?64*n+r:r,i++%4)?a+=String.fromCharCode(255&n>>(-2*i&6)):0)r=chars.indexOf(r);return a}InvalidCharacterError.prototype=new Error,InvalidCharacterError.prototype.name="InvalidCharacterError";var atob="undefined"!=typeof window&&window.atob&&window.atob.bind(window)||polyfill;function b64DecodeUnicode(e){return decodeURIComponent(atob(e).replace(/(.)/g,function(e,t){var n=t.charCodeAt(0).toString(16).toUpperCase();return n.length<2&&(n="0"+n),"%"+n}))}var base64_url_decode=function(e){var t=e.replace(/-/g,"+").replace(/_/g,"/");switch(t.length%4){case 0:break;case 2:t+="==";break;case 3:t+="=";break;default:throw"Illegal base64url string!"}try{return b64DecodeUnicode(t)}catch(e){return atob(t)}};function InvalidTokenError(e){this.message=e}InvalidTokenError.prototype=new Error,InvalidTokenError.prototype.name="InvalidTokenError";var lib=function(e,t){if("string"!=typeof e)throw new InvalidTokenError("Invalid token specified");var n=!0===(t=t||{}).header?0:1;try{return JSON.parse(base64_url_decode(e.split(".")[n]))}catch(e){throw new InvalidTokenError("Invalid token specified: "+e.message)}},InvalidTokenError_1=InvalidTokenError;function getReferrer(e){var t=null,n=null,r=sessionStorage.getItem("ctx_ses_soc"),i={fb:"facebook.com",tw:"t.co",rd:"reddit.com",pn:"pinterest.com",ig:"instagram.com",glp:"plus.url.google.com",tbl:"t.umblr.com",qq:"qzone.qq.com",we:"weibo.com",hb:"habbo.com",vk:"vk.com",rr:"renren.com",or:"orkut.google.com",sn:"snapchat.com"};return Object.keys(i).forEach(function(o){var a=i[o];null!==e.match(a)&&(t=a,n=o,r=r||sessionStorage.setItem("ctx_ses_soc",o))}),{ctx_ses_soc:r,ctx_ref_soc:n,ctx_ref_url:t}}lib.InvalidTokenError=InvalidTokenError_1;var crc32=createCommonjsModule(function(e,t){var n;n=function(e){e.version="1.2.0";var t=function(){for(var e=0,t=new Array(256),n=0;256!=n;++n)e=1&(e=1&(e=1&(e=1&(e=1&(e=1&(e=1&(e=1&(e=n)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1)?-306674912^e>>>1:e>>>1,t[n]=e;return"undefined"!=typeof Int32Array?new Int32Array(t):t}();e.table=t,e.bstr=function(e,n){for(var r=-1^n,i=e.length-1,o=0;o<i;)r=(r=r>>>8^t[255&(r^e.charCodeAt(o++))])>>>8^t[255&(r^e.charCodeAt(o++))];return o===i&&(r=r>>>8^t[255&(r^e.charCodeAt(o))]),-1^r},e.buf=function(e,n){if(e.length>1e4)return function(e,n){for(var r=-1^n,i=e.length-7,o=0;o<i;)r=(r=(r=(r=(r=(r=(r=(r=r>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])];for(;o<i+7;)r=r>>>8^t[255&(r^e[o++])];return-1^r}(e,n);for(var r=-1^n,i=e.length-3,o=0;o<i;)r=(r=(r=(r=r>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])])>>>8^t[255&(r^e[o++])];for(;o<i+3;)r=r>>>8^t[255&(r^e[o++])];return-1^r},e.str=function(e,n){for(var r,i,o=-1^n,a=0,s=e.length;a<s;)(r=e.charCodeAt(a++))<128?o=o>>>8^t[255&(o^r)]:r<2048?o=(o=o>>>8^t[255&(o^(192|r>>6&31))])>>>8^t[255&(o^(128|63&r))]:r>=55296&&r<57344?(r=64+(1023&r),i=1023&e.charCodeAt(a++),o=(o=(o=(o=o>>>8^t[255&(o^(240|r>>8&7))])>>>8^t[255&(o^(128|r>>2&63))])>>>8^t[255&(o^(128|i>>6&15|(3&r)<<4))])>>>8^t[255&(o^(128|63&i))]):o=(o=(o=o>>>8^t[255&(o^(224|r>>12&15))])>>>8^t[255&(o^(128|r>>6&63))])>>>8^t[255&(o^(128|63&r))];return-1^o}},"undefined"==typeof DO_NOT_EXPORT_CRC?n(t):n({})}),userData;function getBucket(e){void 0===e&&(e="1234567");var t=crc32.str(e).toString(16).match(/^\d+|\d+\b|\d+(?=\w)/g);if(t)return parseInt(t[t.length-1],10)%100+1}function isStorageEnabled(){try{return window.localStorage.setItem("testKey","1"),window.localStorage.removeItem("testKey"),!0}catch(e){return!1}}function checkDate(e,t){return t>e}function trimDate(e,t){return e?e.toString().split(",").filter(function(e){var n=parseInt(e,10);return checkDate(t,n)}):[]}function timeTravel(e,t){var n=new Date(e).getDate()-t;return new Date(e).setDate(n)}function getSessionData(){var e=(new Date).getTime(),t=timeTravel(e,1),n=timeTravel(e,30),r=parseInt(sessionStorage.getItem("session-visits"),10)||0;sessionStorage.setItem("session-visits",(r+1).toString());var i=sessionStorage.getItem("session-visits"),o=localStorage.getItem("session-visit-dates"),a=localStorage.getItem("total-visits");r||(o=o?o+","+e:e);var s=a?a+","+e:e,c=trimDate(s,t),u=trimDate(s,n),l=trimDate(o,n);return localStorage.setItem("total-visits",u.join(",")),localStorage.setItem("session-visit-dates",l.join(",")),{usr_pvc_bs:i,usr_pvc_24hr:c.length,usr_pvc_30d:u.length,usr_svc_30d:l.length}}function getUserBuckets(){var e=localStorage.getItem("usr_bkt_eva"),t=sessionStorage.getItem("usr_bkt_ses");if(!e){var n=getCookie("CN_xid"),r=getCookie("CN_userAuth");e=getBucket(r?get(lib(r,{complete:!0}),"sub"):n),localStorage.setItem("usr_bkt_eva",e)}return t||(t=Math.floor(100*Math.random())+1,sessionStorage.setItem("usr_bkt_ses",t)),{usr_bkt_eva:e,usr_bkt_ses:t,usr_bkt_pv:Math.floor(100*Math.random())+1}}function getMediaBuy(){return{mbid:(parse(document.location.search)||{}).mbid}}function getUserAuth(){return{usr_auth:(!!getCookie("pay_ent_sub")||!!getCookie("ee_status")).toString()}}function resetUserData(){userData=!1}function getUserGid(){var e,t=getCookie("_ga");return new RegExp(/^GA1.2./).test(t)&&(e=t.split("GA1.2.")[1]),{usr_gid:e}}function getUserDataPageTargeting(){if(!isStorageEnabled())return{};if(userData)return userData;var e=document.referrer;return userData=Object.assign({},getUserBuckets(),getSessionData(),getReferrer(e),getMediaBuy(),getUserAuth(),getUserGid())}function AdobeAudienceManager(){function e(e,t){var n=t[0],r=t[1],i="vnd_aam_"+n.toLowerCase(),o=e[i]||[];return o.push(r),e[i]=o,e}this.getTargeting=function(){var t=getCookie("aamconde"),n=getCookie("aam_uuid"),r=t&&function(t){return decodeURIComponent(t).split(";").map(function(e){return e.split("=")}).reduce(e,{})}(t),i=n&&{vnd_aam_uuid:[decodeURIComponent(n)]};return Object.assign({},i,r)}}function Proximic(){var e={vnd_prx_segments:[]},t="https://segment-data.zqtk.net/condenast-amp?url="+encodeURIComponent(window.location.href),n=new EventEmitter("Proximic").warn,r=new XMLHttpRequest;r.addEventListener("load",function(){if(200===this.status){var t=JSON.parse(this.response);e=t&&t.targeting}else n("serverError",this.status)}),r.open("GET",t),r.send(),this.getTargeting=function(){return e}}function fromCamelToSnake(e){return e.replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase()}function set$2(e,t,n){void 0===e[t]&&(e[t]=n)}function push(e,t,n){e[t]=e[t]||[],e[t].push(n)}function contains(e,t){return-1!==e.indexOf(t)}function startsWith(e,t){return e.slice(0,t.length)===t}function getTargeting(e,t,n,r){for(var i=r.el,o=e.length,a={},s=i;s;)1===s.nodeType&&function(){var r=s.dataset;Object.keys(r).forEach(function(i){var s=r[i];if(startsWith(i,e)&&"string"==typeof s){var c=fromCamelToSnake(i.slice(o)),u=contains(t,c)?s.split(","):s;contains(n,c)?push(a,c,u):set$2(a,c,u)}})}(),s=s.parentNode;return a}var invalidSpecialCharacters=new RegExp("[\"',=!#~;<>\\]+*^()[\\s]","g"),consecutiveUnderscores=/_+/g,consecutiveDashes=/-+/g,leadingTrailingUnderscores=/(^_|_$)/g,leadingTrailingDashes=/(^-|-$)/g,leadingNumbers=/^[0-9]/,allowedTypes=["string","number"],isAllowedType=function(e){return allowedTypes.indexOf(typeof e)>=0},isValidValue=function(e){return isAllowedType(e)};function toArray(e){return Array.isArray(e)?e:[e]}function isValidKey(e){return(e=e.toString().trim()).length&&!e.match(invalidSpecialCharacters)&&e.length<=20&&!e.match(leadingNumbers)}function applyGPTLimits(e){return e.toString().toLowerCase().replace(invalidSpecialCharacters,"_").replace(consecutiveUnderscores,"_").replace(leadingTrailingUnderscores,"")}function push$1(e,t,n){e[t]=e[t]||[],e[t].push(n)}function sanitizeWithDashes(e){return e.toString().toLowerCase().replace(invalidSpecialCharacters,"-").replace(consecutiveDashes,"-").replace(leadingTrailingDashes,"")}function sanitize(e){for(var t={},n={},r=Object.keys(e),i=0;i<r.length;i++){var o=r[i];if(isValidKey(o))for(var a=toArray(e[o]),s=0;s<a.length;s++){var c=a[s];isValidValue(c)?push$1(t,o,applyGPTLimits(c)):push$1(n,o,c)}else n[o]=e[o]}return{sanitized:t,errors:n}}function getAllKeywordTargeting(e){void 0===e&&(e={});var t={};return Object.keys(e).forEach(function(n){t["cnt_"+n]=e[n]}),t}function TargetingLifecycle(e,t){var n=new LifecycleRegistrar(["service","slot","refresh","refreshLC-serviceLT"]),r=new AdobeAudienceManager,i=new Proximic;function o(e){if(!1===e)return e;var t=sanitize(e),n=t.errors,r=t.sanitized;return n&&Object.keys(n).length&&debug("targetingSanitizationErrors",{errors:n,sanitized:r}),r}if(n.register("service",function(e){var t=e.pageDefinition;return Object.assign({env_device_type:t.device,ctx_template:t.templateType,ctx_page_channel:sanitizeWithDashes(t.channel),ctx_page_sub_channel:t.subChannel,env_server:t.server,ctx_cns_version:version,ctx_page_slug:t.slug},getAllKeywordTargeting(t.keywords))}),n.register("service",t.getTargeting),n.register("service",getUserDataPageTargeting),n.register("service",r.getTargeting),n.register("service",i.getTargeting),n.register("service",getUserSegments),n.register("refreshLC-serviceLT",get4DTargeting),Object.keys(queryParameters).length&&n.register("service",function(){var e=queryParameters.ao_test,t=queryParameters.service_targeting,n={};if(e&&(n.ao_test=e.split(",")),t){var r=JSON.parse(t);Object.keys(r).forEach(function(e){n[e]=r[e]})}return n}),n.register("slot",function(e){var t=e.slotTypeDefinition;return{pos:t.position,ctx_slot_type:t.slotName,ctx_slot_rn:0}}),n.register("slot",getTargeting.bind(null,"ads",["cnt_tags","cnt_cm"],[])),n.register("refresh",function(e){var t=e.slotDefinition;return{pos_instance:t.positionCount,ctx_slot_instance:t.slotCount,ctx_slot_name:t.id}}),auctioneer.areAuctionsEnabled(e)){if(auctioneer.isAuctionEnabled(e,"amazon_match_buy")){var a=new AmazonMatchBuy;n.register("refresh",auctioneer.createSlotAuctionEligible(a),auctioneer.createStartAuction(a))}if(auctioneer.isAuctionEnabled(e,"index_exchange")){var s=new IndexExchange;n.register("refresh",auctioneer.createSlotAuctionEligible(s),auctioneer.createStartAuction(s))}if(auctioneer.isAuctionEnabled(e,"prebid")){var c=new Prebid(e);n.register("refresh",auctioneer.createSlotAuctionEligible(c),auctioneer.createStartAuction(c))}}this.register=n.register,this.withTargeting=function(e,t,r){return Promise.resolve(n.apply(e,t)).then(o).then(r)}}function UniqueTimerStore(){var e={};function t(t){var n=e[t];n&&(clearTimeout(n),e[t]=null)}this.startTimer=function(n,r,i){t(n),e[n]=setTimeout(function(){t(n),r()},i)},this.endTimer=t}function KeyCounter(){var e={};this.increment=function(t){e[t]||(e[t]=0),e[t]+=1},this.remove=function(t){e[t]&&delete e[t]},this.getCount=function(t){return e[t]||0}}function RefreshControl(e,t){var n=t.withTargeting,r=new EventEmitter("RefreshControl").debug,i=new KeyCounter,o=new KeyCounter,a=new Set,s=new Set,c=new Set,u=new UniqueTimerStore,l=3e4,f=[["aged",function(e){return a.has(e)}],["impressions",function(e){return o.getCount(e)}],["visible",function(e){return c.has(e)}]],d=function(e){return!Number.isNaN(parseFloat(e))},g=function(e){return e+".refresh_"+i.getCount(e)},p=function(t){return e.getSingleInstance().getSlotDefinitionFromGPTSlot(t)},h=function(){return e.getSingleInstance().getPageDefinition()},m=cumulativeArgumentDebounce(function(e){var t=uniq(e.map(function(e){return e[0]}));window.cns.flags.shouldNotRefresh?r("window.cns.flags.shouldNotRefresh"):(r("refreshing."+t.map(function(e){return g(e)}).join(",")),t.forEach(function(e){return _(p(getSlotById(e)))}),window.googletag.pubads().refresh(t.map(getSlotById),{changeCorrelator:!1}))},100);function v(e){r("onChange."+e+".("+f.map(function(t){return t[0]+":"+t[1](e)}).join(",")+")"),all(f,function(t){return t[1](e)})&&function(e){var t=h(),o=getSlotById(e),a=p(o);return r("setTargeting."+g(e)),o.setTargeting("ctx_slot_rn",i.getCount(e)),n(["refreshLC-serviceLT"],{pageDefinition:t},function(e){return applyTargeting(window.googletag.pubads(),e),n(["refresh"],{pageDefinition:t,slotDefinition:a,slot:o},function(e){Object.keys(e).forEach(function(t){return o.setTargeting(t,e[t])})})})}(e).then(function(){m(e)})}function y(e,t){var n;n=t,n=parseInt(n,10),t=d(n)&&n>l?n:l,u.startTimer(e,function(){a.add(e),v(e)},t),r("willRefreshIn."+e+"."+t)}function _(e){var t=e.id;o.remove(t),a.delete(t),y(t,e.refresh)}function b(e){return!e.isCM&&!e.isOutOfPage&&!window.cns.flags.shouldNotRefresh&&!1!==e.refresh}function w(e){u.endTimer(e)}this.reset=function(e){b(e)?_(e):r("slotNotRefreshable."+e.id)},this.onSlotRenderEnded=function(e){var t=e.advertiserId,n=e.slot,r=p(n).id;i.getCount(r)&&4552798968===t&&w(n.getSlotElementId()),i.increment(r)},this.onImpressionViewable=function(e){var t=e.slot.getSlotElementId();o.increment(t),r(t+".impressionIncremented"),v(t),b(p(e.slot))&&function(e){if(!s.has(e)){var t=getElementById(e);s.add(e),onIntersection(t,{},function(t){t?(c.add(e),v(e)):c.delete(e)})}}(t)},this.disableRefresh=w,this.delayRefresh=y}function ShareOfVoice(){var e=[],t=[],n=[];function r(e,t){t&&-1===e.indexOf(t)&&e.push(t)}this.getTargeting=function(){return{ctx_advertisers:e,ctx_line_items:t,ctx_creatives:n}},this.onSlotRenderEnded=function(i){var o=i.advertiserId,a=i.lineItemId,s=i.creativeId;r(e,o),r(t,a),r(n,s)}}function setSheet(){var e=document.createElement("style");return e.id="cns_version",e.appendChild(document.createTextNode("")),document.head.appendChild(e),e.sheet}function addCSSRule(e,t,n){return e.insertRule&&e.insertRule(t+"{"+n+"}",0)||e.addRule&&e.addRule(t,n,0)}function renderVersion(){var e='content: "ADS V:'+version+'";color:#fff;background-color:#f00;position:fixed;top:0;right:0;padding:4px 8px;z-index:2147483647;';addCSSRule(setSheet(),"body::after",e)}function cnsMetricsApi(){return function(e){e({emit:pixel})}}_export(_export.S,"Number",{isNaN:function(e){return e!=e}});var updateRefresh=function(e){var t=e.refreshControl;return function(e){var n=e.slotName,r=e.refresh;"number"==typeof r&&r>0?t.delayRefresh(n,r):t.disableRefresh(n)}};function CNSAdsAPI(e,t,n,r){function i(e){var t=e.device,n=void 0===t?"desktop":t,r=e.server,i=void 0===r?"staging":r;return new Promise(function(e,t){i&&n||t(),e()})}function o(){return!0===get(window,"cns.pageContext.adBlock")}var a=updateRefresh({refreshControl:t});function s(e,t){var n=e.frameElement.parentElement.parentElement.id;a({slotName:n,refresh:t})}function c(e){var t=window.cns.pageContext,i=new CompleteDefiner(Object.assign({},t,e),null,getViewportTemplate());n.reset(function(){return i}),r.insert(n)}function u(){resetUserData(),window.googletag.cmd.push(function(){window.googletag.pubads().clear(),window.googletag.destroySlots()}),fastdom.mutate(function(){for(var e=document.querySelectorAll(".cns-ads-stage"),t=0;t<e.length;t++)e[t].remove()})}function l(e){console.warn("AddSlot is deprecated. To render this slot "+e+" add it to the config's set using pageContext: "+window.cns.pageContext),r.insert(n)}this.executeCallback=function(e){e({environment:i,setRefreshFor:s,adBlock:{installed:deprecated(function(){},"adblock.installed"),blocked:deprecated(o,"adblock.blocked")},pages:{create:c,destroy:u,get:function(){return{slots:{add:deprecated(l,"slots.add"),get:deprecated(function(){},"slots.get"),refresh:deprecated(function(){},"slots.refresh"),destroy:deprecated(function(){},"slots.destroy")}}}}})}}function CNSShim(e,t,n,r){var i,o=new CNSAdsAPI(e,t,n,r);i={ads:o.executeCallback,metrics:cnsMetricsApi()},window.cns.async=function(e,t){i[e](t)},window.cns.queue.forEach(function(e){var t=e.service,n=e.callback;window.cns.async(t,n)}),delete window.cns.queue}var MAP="Map",es6_map=_collection(MAP,function(e){return function(){return e(this,arguments.length>0?arguments[0]:void 0)}},{get:function(e){var t=_collectionStrong.getEntry(_validateCollection(this,MAP),e);return t&&t.v},set:function(e,t){return _collectionStrong.def(_validateCollection(this,MAP),0===e?0:e,t)}},_collectionStrong,!0);function SafeFrameMessageListener(e){var t,n,r=e.refreshControl,i=(t={updateRefresh:updateRefresh},n=new Map(Object.keys(t).map(function(e){return[e,t[e]({refreshControl:r})]})),function(e){var t=e.data,r=e.origin,i=t.cnsAdEvent,o=t.payload;if(/^https?:\/\/tpc.googlesyndication\.com$/.test(r)&&"object"==typeof t&&n.has(i))return n.get(i)(o,e)});window.addEventListener("message",i)}function getConfig$1(e){return e.cns&&e.cns.config}function SourceOfTruth(e){var t;this.getSingleInstance=function(){return t||(t=e()),t},this.reset=function(n){t=n?n():e()}}for(var TYPED=_uid("typed_array"),VIEW=_uid("view"),ABV=!(!_global.ArrayBuffer||!_global.DataView),CONSTR=ABV,i$1=0,l=9,Typed,TypedArrayConstructors="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");i$1<l;)(Typed=_global[TypedArrayConstructors[i$1++]])?(_hide(Typed.prototype,TYPED,!0),_hide(Typed.prototype,VIEW,!0)):CONSTR=!1;var _typed={ABV:ABV,CONSTR:CONSTR,TYPED:TYPED,VIEW:VIEW},_toIndex=function(e){if(void 0===e)return 0;var t=_toInteger(e),n=_toLength(t);if(t!==n)throw RangeError("Wrong length!");return n},hiddenKeys=_enumBugKeys.concat("length","prototype"),f$5=Object.getOwnPropertyNames||function(e){return _objectKeysInternal(e,hiddenKeys)},_objectGopn={f:f$5},_arrayFill=function(e){for(var t=_toObject(this),n=_toLength(t.length),r=arguments.length,i=_toAbsoluteIndex(r>1?arguments[1]:void 0,n),o=r>2?arguments[2]:void 0,a=void 0===o?n:_toAbsoluteIndex(o,n);a>i;)t[i++]=e;return t},_typedBuffer=createCommonjsModule(function(e,t){var n=_objectGopn.f,r=_objectDp.f,i="prototype",o="Wrong index!",a=_global.ArrayBuffer,s=_global.DataView,c=_global.Math,u=_global.RangeError,l=_global.Infinity,f=a,d=c.abs,g=c.pow,p=c.floor,h=c.log,m=c.LN2,v=_descriptors?"_b":"buffer",y=_descriptors?"_l":"byteLength",_=_descriptors?"_o":"byteOffset";function b(e,t,n){var r,i,o,a=new Array(n),s=8*n-t-1,c=(1<<s)-1,u=c>>1,f=23===t?g(2,-24)-g(2,-77):0,v=0,y=e<0||0===e&&1/e<0?1:0;for((e=d(e))!=e||e===l?(i=e!=e?1:0,r=c):(r=p(h(e)/m),e*(o=g(2,-r))<1&&(r--,o*=2),(e+=r+u>=1?f/o:f*g(2,1-u))*o>=2&&(r++,o/=2),r+u>=c?(i=0,r=c):r+u>=1?(i=(e*o-1)*g(2,t),r+=u):(i=e*g(2,u-1)*g(2,t),r=0));t>=8;a[v++]=255&i,i/=256,t-=8);for(r=r<<t|i,s+=t;s>0;a[v++]=255&r,r/=256,s-=8);return a[--v]|=128*y,a}function w(e,t,n){var r,i=8*n-t-1,o=(1<<i)-1,a=o>>1,s=i-7,c=n-1,u=e[c--],f=127&u;for(u>>=7;s>0;f=256*f+e[c],c--,s-=8);for(r=f&(1<<-s)-1,f>>=-s,s+=t;s>0;r=256*r+e[c],c--,s-=8);if(0===f)f=1-a;else{if(f===o)return r?NaN:u?-l:l;r+=g(2,t),f-=a}return(u?-1:1)*r*g(2,f-t)}function S(e){return e[3]<<24|e[2]<<16|e[1]<<8|e[0]}function T(e){return[255&e]}function E(e){return[255&e,e>>8&255]}function I(e){return[255&e,e>>8&255,e>>16&255,e>>24&255]}function x(e){return b(e,52,8)}function P(e){return b(e,23,4)}function A(e,t,n){r(e[i],t,{get:function(){return this[n]}})}function C(e,t,n,r){var i=_toIndex(+n);if(i+t>e[y])throw u(o);var a=e[v]._b,s=i+e[_],c=a.slice(s,s+t);return r?c:c.reverse()}function O(e,t,n,r,i,a){var s=_toIndex(+n);if(s+t>e[y])throw u(o);for(var c=e[v]._b,l=s+e[_],f=r(+i),d=0;d<t;d++)c[l+d]=f[a?d:t-d-1]}if(_typed.ABV){if(!_fails(function(){a(1)})||!_fails(function(){new a(-1)})||_fails(function(){return new a,new a(1.5),new a(NaN),"ArrayBuffer"!=a.name})){for(var R,k=(a=function(e){return _anInstance(this,a),new f(_toIndex(e))})[i]=f[i],j=n(f),M=0;j.length>M;)(R=j[M++])in a||_hide(a,R,f[R]);_library||(k.constructor=a)}var D=new s(new a(2)),F=s[i].setInt8;D.setInt8(0,2147483648),D.setInt8(1,2147483649),!D.getInt8(0)&&D.getInt8(1)||_redefineAll(s[i],{setInt8:function(e,t){F.call(this,e,t<<24>>24)},setUint8:function(e,t){F.call(this,e,t<<24>>24)}},!0)}else a=function(e){_anInstance(this,a,"ArrayBuffer");var t=_toIndex(e);this._b=_arrayFill.call(new Array(t),0),this[y]=t},s=function(e,t,n){_anInstance(this,s,"DataView"),_anInstance(e,a,"DataView");var r=e[y],i=_toInteger(t);if(i<0||i>r)throw u("Wrong offset!");if(i+(n=void 0===n?r-i:_toLength(n))>r)throw u("Wrong length!");this[v]=e,this[_]=i,this[y]=n},_descriptors&&(A(a,"byteLength","_l"),A(s,"buffer","_b"),A(s,"byteLength","_l"),A(s,"byteOffset","_o")),_redefineAll(s[i],{getInt8:function(e){return C(this,1,e)[0]<<24>>24},getUint8:function(e){return C(this,1,e)[0]},getInt16:function(e){var t=C(this,2,e,arguments[1]);return(t[1]<<8|t[0])<<16>>16},getUint16:function(e){var t=C(this,2,e,arguments[1]);return t[1]<<8|t[0]},getInt32:function(e){return S(C(this,4,e,arguments[1]))},getUint32:function(e){return S(C(this,4,e,arguments[1]))>>>0},getFloat32:function(e){return w(C(this,4,e,arguments[1]),23,4)},getFloat64:function(e){return w(C(this,8,e,arguments[1]),52,8)},setInt8:function(e,t){O(this,1,e,T,t)},setUint8:function(e,t){O(this,1,e,T,t)},setInt16:function(e,t){O(this,2,e,E,t,arguments[2])},setUint16:function(e,t){O(this,2,e,E,t,arguments[2])},setInt32:function(e,t){O(this,4,e,I,t,arguments[2])},setUint32:function(e,t){O(this,4,e,I,t,arguments[2])},setFloat32:function(e,t){O(this,4,e,P,t,arguments[2])},setFloat64:function(e,t){O(this,8,e,x,t,arguments[2])}});_setToStringTag(a,"ArrayBuffer"),_setToStringTag(s,"DataView"),_hide(s[i],_typed.VIEW,!0),t.ArrayBuffer=a,t.DataView=s}),_isArray=Array.isArray||function(e){return"Array"==_cof(e)},SPECIES$2=_wks("species"),_arraySpeciesConstructor=function(e){var t;return _isArray(e)&&("function"!=typeof(t=e.constructor)||t!==Array&&!_isArray(t.prototype)||(t=void 0),_isObject(t)&&null===(t=t[SPECIES$2])&&(t=void 0)),void 0===t?Array:t},_arraySpeciesCreate=function(e,t){return new(_arraySpeciesConstructor(e))(t)},_arrayMethods=function(e,t){var n=1==e,r=2==e,i=3==e,o=4==e,a=6==e,s=5==e||a,c=t||_arraySpeciesCreate;return function(t,u,l){for(var f,d,g=_toObject(t),p=_iobject(g),h=_ctx(u,l,3),m=_toLength(p.length),v=0,y=n?c(t,m):r?c(t,0):void 0;m>v;v++)if((s||v in p)&&(d=h(f=p[v],v,g),e))if(n)y[v]=d;else if(d)switch(e){case 3:return!0;case 5:return f;case 6:return v;case 2:y.push(f)}else if(o)return!1;return a?-1:i||o?o:y}},_arrayCopyWithin=[].copyWithin||function(e,t){var n=_toObject(this),r=_toLength(n.length),i=_toAbsoluteIndex(e,r),o=_toAbsoluteIndex(t,r),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?r:_toAbsoluteIndex(a,r))-o,r-i),c=1;for(o<i&&i<o+s&&(c=-1,o+=s-1,i+=s-1);s-- >0;)o in n?n[i]=n[o]:delete n[i],i+=c,o+=c;return n},_typedArray=createCommonjsModule(function(e){if(_descriptors){var t=_library,n=_global,r=_fails,i=_export,o=_typed,a=_typedBuffer,s=_ctx,c=_anInstance,u=_propertyDesc,l=_hide,f=_redefineAll,d=_toInteger,g=_toLength,p=_toIndex,h=_toAbsoluteIndex,m=_toPrimitive,v=_has,y=_classof,_=_isObject,b=_toObject,w=_isArrayIter,S=_objectCreate,T=_objectGpo,E=_objectGopn.f,I=core_getIteratorMethod,x=_uid,P=_wks,A=_arrayMethods,C=_arrayIncludes,O=_speciesConstructor,R=es6_array_iterator,k=_iterators,j=_iterDetect,M=_setSpecies,D=_arrayFill,F=_arrayCopyWithin,L=_objectDp,N=_objectGopd,$=L.f,V=N.f,U=n.RangeError,z=n.TypeError,B=n.Uint8Array,q=Array.prototype,G=a.ArrayBuffer,W=a.DataView,K=A(0),H=A(2),Y=A(3),J=A(4),Z=A(5),Q=A(6),X=C(!0),ee=C(!1),te=R.values,ne=R.keys,re=R.entries,ie=q.lastIndexOf,oe=q.reduce,ae=q.reduceRight,se=q.join,ce=q.sort,ue=q.slice,le=q.toString,fe=q.toLocaleString,de=P("iterator"),ge=P("toStringTag"),pe=x("typed_constructor"),he=x("def_constructor"),me=o.CONSTR,ve=o.TYPED,ye=o.VIEW,_e=A(1,function(e,t){return Ee(O(e,e[he]),t)}),be=r(function(){return 1===new B(new Uint16Array([1]).buffer)[0]}),we=!!B&&!!B.prototype.set&&r(function(){new B(1).set({})}),Se=function(e,t){var n=d(e);if(n<0||n%t)throw U("Wrong offset!");return n},Te=function(e){if(_(e)&&ve in e)return e;throw z(e+" is not a typed array!")},Ee=function(e,t){if(!(_(e)&&pe in e))throw z("It is not a typed array constructor!");return new e(t)},Ie=function(e,t){return xe(O(e,e[he]),t)},xe=function(e,t){for(var n=0,r=t.length,i=Ee(e,r);r>n;)i[n]=t[n++];return i},Pe=function(e,t,n){$(e,t,{get:function(){return this._d[n]}})},Ae=function(e){var t,n,r,i,o,a,c=b(e),u=arguments.length,l=u>1?arguments[1]:void 0,f=void 0!==l,d=I(c);if(void 0!=d&&!w(d)){for(a=d.call(c),r=[],t=0;!(o=a.next()).done;t++)r.push(o.value);c=r}for(f&&u>2&&(l=s(l,arguments[2],2)),t=0,n=g(c.length),i=Ee(this,n);n>t;t++)i[t]=f?l(c[t],t):c[t];return i},Ce=function(){for(var e=0,t=arguments.length,n=Ee(this,t);t>e;)n[e]=arguments[e++];return n},Oe=!!B&&r(function(){fe.call(new B(1))}),Re=function(){return fe.apply(Oe?ue.call(Te(this)):Te(this),arguments)},ke={copyWithin:function(e,t){return F.call(Te(this),e,t,arguments.length>2?arguments[2]:void 0)},every:function(e){return J(Te(this),e,arguments.length>1?arguments[1]:void 0)},fill:function(e){return D.apply(Te(this),arguments)},filter:function(e){return Ie(this,H(Te(this),e,arguments.length>1?arguments[1]:void 0))},find:function(e){return Z(Te(this),e,arguments.length>1?arguments[1]:void 0)},findIndex:function(e){return Q(Te(this),e,arguments.length>1?arguments[1]:void 0)},forEach:function(e){K(Te(this),e,arguments.length>1?arguments[1]:void 0)},indexOf:function(e){return ee(Te(this),e,arguments.length>1?arguments[1]:void 0)},includes:function(e){return X(Te(this),e,arguments.length>1?arguments[1]:void 0)},join:function(e){return se.apply(Te(this),arguments)},lastIndexOf:function(e){return ie.apply(Te(this),arguments)},map:function(e){return _e(Te(this),e,arguments.length>1?arguments[1]:void 0)},reduce:function(e){return oe.apply(Te(this),arguments)},reduceRight:function(e){return ae.apply(Te(this),arguments)},reverse:function(){for(var e,t=Te(this).length,n=Math.floor(t/2),r=0;r<n;)e=this[r],this[r++]=this[--t],this[t]=e;return this},some:function(e){return Y(Te(this),e,arguments.length>1?arguments[1]:void 0)},sort:function(e){return ce.call(Te(this),e)},subarray:function(e,t){var n=Te(this),r=n.length,i=h(e,r);return new(O(n,n[he]))(n.buffer,n.byteOffset+i*n.BYTES_PER_ELEMENT,g((void 0===t?r:h(t,r))-i))}},je=function(e,t){return Ie(this,ue.call(Te(this),e,t))},Me=function(e){Te(this);var t=Se(arguments[1],1),n=this.length,r=b(e),i=g(r.length),o=0;if(i+t>n)throw U("Wrong length!");for(;o<i;)this[t+o]=r[o++]},De={entries:function(){return re.call(Te(this))},keys:function(){return ne.call(Te(this))},values:function(){return te.call(Te(this))}},Fe=function(e,t){return _(e)&&e[ve]&&"symbol"!=typeof t&&t in e&&String(+t)==String(t)},Le=function(e,t){return Fe(e,t=m(t,!0))?u(2,e[t]):V(e,t)},Ne=function(e,t,n){return!(Fe(e,t=m(t,!0))&&_(n)&&v(n,"value"))||v(n,"get")||v(n,"set")||n.configurable||v(n,"writable")&&!n.writable||v(n,"enumerable")&&!n.enumerable?$(e,t,n):(e[t]=n.value,e)};me||(N.f=Le,L.f=Ne),i(i.S+i.F*!me,"Object",{getOwnPropertyDescriptor:Le,defineProperty:Ne}),r(function(){le.call({})})&&(le=fe=function(){return se.call(this)});var $e=f({},ke);f($e,De),l($e,de,De.values),f($e,{slice:je,set:Me,constructor:function(){},toString:le,toLocaleString:Re}),Pe($e,"buffer","b"),Pe($e,"byteOffset","o"),Pe($e,"byteLength","l"),Pe($e,"length","e"),$($e,ge,{get:function(){return this[ve]}}),e.exports=function(e,a,s,u){var f=e+((u=!!u)?"Clamped":"")+"Array",d="get"+e,h="set"+e,m=n[f],v=m||{},b=m&&T(m),w=!m||!o.ABV,I={},x=m&&m.prototype,P=function(e,t){$(e,t,{get:function(){return function(e,t){var n=e._d;return n.v[d](t*a+n.o,be)}(this,t)},set:function(e){return function(e,t,n){var r=e._d;u&&(n=(n=Math.round(n))<0?0:n>255?255:255&n),r.v[h](t*a+r.o,n,be)}(this,t,e)},enumerable:!0})};w?(m=s(function(e,t,n,r){c(e,m,f,"_d");var i,o,s,u,d=0,h=0;if(_(t)){if(!(t instanceof G||"ArrayBuffer"==(u=y(t))||"SharedArrayBuffer"==u))return ve in t?xe(m,t):Ae.call(m,t);i=t,h=Se(n,a);var v=t.byteLength;if(void 0===r){if(v%a)throw U("Wrong length!");if((o=v-h)<0)throw U("Wrong length!")}else if((o=g(r)*a)+h>v)throw U("Wrong length!");s=o/a}else s=p(t),i=new G(o=s*a);for(l(e,"_d",{b:i,o:h,l:o,e:s,v:new W(i)});d<s;)P(e,d++)}),x=m.prototype=S($e),l(x,"constructor",m)):r(function(){m(1)})&&r(function(){new m(-1)})&&j(function(e){new m,new m(null),new m(1.5),new m(e)},!0)||(m=s(function(e,t,n,r){var i;return c(e,m,f),_(t)?t instanceof G||"ArrayBuffer"==(i=y(t))||"SharedArrayBuffer"==i?void 0!==r?new v(t,Se(n,a),r):void 0!==n?new v(t,Se(n,a)):new v(t):ve in t?xe(m,t):Ae.call(m,t):new v(p(t))}),K(b!==Function.prototype?E(v).concat(E(b)):E(v),function(e){e in m||l(m,e,v[e])}),m.prototype=x,t||(x.constructor=m));var A=x[de],C=!!A&&("values"==A.name||void 0==A.name),O=De.values;l(m,pe,!0),l(x,ve,f),l(x,ye,!0),l(x,he,m),(u?new m(1)[ge]==f:ge in x)||$(x,ge,{get:function(){return f}}),I[f]=m,i(i.G+i.W+i.F*(m!=v),I),i(i.S,f,{BYTES_PER_ELEMENT:a}),i(i.S+i.F*r(function(){v.of.call(m,1)}),f,{from:Ae,of:Ce}),"BYTES_PER_ELEMENT"in x||l(x,"BYTES_PER_ELEMENT",a),i(i.P,f,ke),M(f),i(i.P+i.F*we,f,{set:Me}),i(i.P+i.F*!C,f,De),t||x.toString==le||(x.toString=le),i(i.P+i.F*r(function(){new m(1).slice()}),f,{slice:je}),i(i.P+i.F*(r(function(){return[1,2].toLocaleString()!=new m([1,2]).toLocaleString()})||!r(function(){x.toLocaleString.call([1,2])})),f,{toLocaleString:Re}),k[f]=C?A:O,t||C||l(x,de,O)}}else e.exports=function(){}});function generate(e,t){var n,r=window.crypto||window.msCrypto;n=r?function(e){return r.getRandomValues(new Uint8Array(e))}:function(e){for(var t=[],n=0;n<e;n++)t.push(Math.floor(254*Math.random()));return t};for(var i=(2<<Math.log(e.length-1)/Math.LN2)-1,o=Math.ceil(1.6*i*t/e.length),a="";a.length<t;)for(var s=n(o),c=0;c<o;c++){var u=s[c]&i;if(e[u]&&(a+=e[u]).length===t)return a}}_typedArray("Uint8",1,function(e){return function(t,n,r){return e(this,t,n,r)}});var runtimeId=generate("123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz",13);function append(e){return new Promise(function(t,n){var r=document.createElement("script");["src","targ"].forEach(function(t){return!e[t]&&n(new Error("Missing required parameter: "+t))}),["src","targ","async","defer"].forEach(function(t){r[t]=e[t]}),r.onload=function(){t()},r.onerror=function(e){n(e)},e.targ.appendChild(r)})}var cns=window.cns;function about(){return{buildDate:cns.buildDate,fastAdsHead:cns.fastAdsHead,fastAdsFooter:cns.fastAdsFooter,runtimeId:queryParameters.runtimeId||runtimeId}}function notSetup(e){var t=e+" function is not setup";return console.warn.bind(null,t)}function attachListeners(e,t){var n=getConfig$1(window),r=new ShareOfVoice,i=new TargetingLifecycle(n,r),o=new RefreshControl(t,i),a=new UnassumingInsert(e,i,o,t);new CNSShim(e,o,t,a),new GPTRouter(t,o,r,e),new SafeFrameMessageListener({refreshControl:o}),emitBoomPixel("adsReady"),cns.addTargeting=i.register,detectIncognito(e),AdBlockDetect(e),featureFlags.ads_debug_outline&&debugStyles(),startSentry(e),a.insert(t)}function startFooter(){var e=window.cnBus;featureFlags.show_version&&renderVersion(),addDefaultSubscriptions(e,featureFlags.bus_log),"info"===queryParameters.ao_tools&&append({src:"https://ad-tools.condenastdigital.com/ads-"+queryParameters.ao_tools+"/prod/index.js",targ:document.head}),queryParameters.ap_noads||hasPII()||til(function(){return cns.pageContext},function(){var t=new SourceOfTruth(function(){var e=getViewportTemplate();return new CompleteDefiner(getPageContext(window),null,e)});attachListeners(e,t),enableCNE(e)})}set(window,"cns.buildDate",getConfig$1(window).buildDate),set(window,"cns.fastAdsFooter",version),set(window,"cns.runtimeId",queryParameters.runtimeId||runtimeId),set(window,"cns.about",about),set(window,"cns.timing.footerStart",Date.now()),set(window,"cns.addTargeting",notSetup("cns.addTargeting")),startFooter()}();
</script><script>
  (function(){
    var w = window;
    w.CN = w.CN || {};
    w.CN.ad = w.CN.ad || {};
    w.CN.ad.proximic = {};

    var s = document.createElement('script');
    s.src = 'https://segment-data.zqtk.net/conde-nast?url=' + encodeURIComponent(window.location.href);
    s.defer = true;
    document.head.appendChild(s);
  })();
</script>
<script src="/hotzones/src/pixelpropagate.js?cb=10120" async></script><script>
(function userSegments(doc) {
  const paymentForm = (window.__PRELOADED_STATE__.transformed.payment || {}).form;
  const pageLocation = encodeURIComponent(window.location.href);
  function addScript(src) {
    var s = document.createElement('script');
    s.src = src;
    s.async = true;
    document.body.appendChild(s);
  }
  addScript('/user-context?referrer=' + encodeURIComponent(document.referrer) + '&verso=true' + (typeof paymentForm !== 'undefined' ? '&paymentForm=' + paymentForm : '') + '&location=' + pageLocation);
})(document)
</script><script id="cne-interlude-script">(function insertInterlude(brand, domain) {
    if (window.CN_STACK_TEMP === 'verso') {
      return;
    }

    var src = 'https://' + domain + '/interlude/' + brand + '.js';

    var s = document.createElement('script');
    s.src = src;
    s.async = true;
    document.head.appendChild(s);
  })('newyorker', 'player.cnevids.com');</script><script>(function() {
function DQ() {
  var queue = window.sparrowQueue;
  this.push = fn => fn();
  window.sparrowQueue = this;
  while (queue.length) {
    queue.shift()();
  }
}
function e(t, e) {
  var n, a, o;
  a = !1, n = document.createElement("script"), n.type = "text/javascript", n.src = t, n.onload = n.onreadystatechange = function() {
    a || this.readyState && "complete" != this.readyState || (a = !0, e ? e() : !0)
  }, o = document.getElementsByTagName("script")[0], o.parentNode.insertBefore(n, o)
}
if(location.search.indexOf('no_sparrow')<0){
e("https://pixel.condenastdigital.com/config/v2/production/the-new-yorker.config.js", function() {
  e("https://pixel.condenastdigital.com/sparrow.min.js", function() { 
    if (window.SparrowConfigV2) {
      window.sparrow = new window.Sparrow(window.SparrowConfigV2); 
      new DQ();
    }
  })
})}
})()</script><script></script></body></html>